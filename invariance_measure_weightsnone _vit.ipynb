{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f830fa-650b-48e8-8d35-79f78525e87a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "##import libraries\n",
    "from tinyimagenet import TinyImageNet\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torchvision import models\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.utils.data as data\n",
    "#from torchvision.models._api import WeightsEnum\n",
    "#from torch.hub import load_state_dict_from_url\n",
    "import numpy as np\n",
    "import tmeasures as tm\n",
    "### para mostrar la trasnformacion\n",
    "from tinyimagenet import TinyImageNet\n",
    "from torchvision import transforms as T\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import *\n",
    "import sys\n",
    "\n",
    "sns.set()\n",
    "#%%\n",
    "\n",
    "#sys.path.append('./Notebooks/')\n",
    "#torch.cuda.set_per_process_memory_fraction(0.5, device=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f8dbbd-7844-441a-ae8d-a7e888c1f5b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import transformations\n"
     ]
    }
   ],
   "source": [
    "# load transformations\n",
    "import transformaciones as tr\n",
    "\n",
    "rotation_transforms = tr.rotation_transforms()\n",
    "translation_transforms = tr.translation_transforms()\n",
    "scale_transforms = tr.scale_transforms()\n",
    "perspective_transforms = tr.perspective_transforms()\n",
    "brightness_transforms = [tr.brightness_transforms(factor) for factor in tr.brightness_parameters]\n",
    "contrast_transformations = [tr.contrast_transforms(alpha) for alpha in tr.contrast_list]\n",
    "grayscale_transformations = [tr.grayscale_transforms(alpha) for alpha in tr.grey_list]\n",
    "solarize_transformations = [tr.solarize_transforms(threshold) for threshold in tr.solarization_thresholds]\n",
    "posterize_transformations = [tr.posterize_transforms(alpha) for alpha in tr.posterize_list]\n",
    "invertion_transformations = [tr.invertion_transforms(alpha) for alpha in tr.invertion_list]\n",
    "\n",
    "\n",
    "transformation_afin = [rotation_transforms,\n",
    "                       translation_transforms,\n",
    "                       scale_transforms,\n",
    "                       perspective_transforms,\n",
    "                       brightness_transforms,\n",
    "                       contrast_transformations,\n",
    "                       grayscale_transformations,\n",
    "                       solarize_transformations,\n",
    "                       posterize_transformations,\n",
    "                       invertion_transformations]\n",
    "\n",
    "\n",
    "transformaciones = ['rotacion','traslacion','escala','proyeccion','brillo','contraste','escala_grises','solarizacion','posterizacion','inversion_colores']\n",
    "\n",
    "print('import transformations')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37da5de0",
   "metadata": {},
   "source": [
    "# Calcula la invarianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49da6785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tatibada/Documents/Tesis_Maestria_DM/servidor_facu/models/ViT/weights_none\n"
     ]
    }
   ],
   "source": [
    "main_directory = os.path.join(os.getcwd(),'models', 'ViT','weights_none')\n",
    "print(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5302f447-9e9c-4485-8324-4cbfcf5d2808",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "class TinyImageNet(TinyImageNet):\n",
    "    def __getitem__(self, index):\n",
    "        x, y = super().__getitem__(index)\n",
    "        return x\n",
    "\n",
    "normalize_transform = T.Compose(\n",
    "    [\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(TinyImageNet.mean,TinyImageNet.std),\n",
    "    #random_ts\n",
    "    ])\n",
    "\n",
    "\n",
    "dataset_nolabels = TinyImageNet(root=\"~/.datasets/tinyimagenet/\",split=\"train\", transform=normalize_transform)\n",
    "\n",
    "# Subsample \n",
    "N = 1000\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "indices, _ = train_test_split(np.arange(len(dataset_nolabels)), train_size=N, stratify=dataset_nolabels.targets,random_state=24)\n",
    "test_inv = Subset(dataset_nolabels, indices)\n",
    "\n",
    "print(len(test_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d076856f-1855-4054-b632-ee3e4adc55df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from timm.models import _builder\n",
    "\n",
    "_builder._update_default_kwargs = _builder._update_default_model_kwargs\n",
    "\n",
    "## fastervit\n",
    "from fastervit import create_model\n",
    "# Define fastervit-0 model with 224 x 224 resolution\n",
    "\n",
    "model = create_model('faster_vit_0_224', \n",
    "                          pretrained=False,\n",
    "                          model_path=\"/home/tbadaracco//faster_vit_0.pth.tar\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89e9ea60",
   "metadata": {},
   "source": [
    "## Para todas las transformaciones excepto identidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "162a4415-28f8-40cf-89f9-3d577a7e6f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none\n",
      "Model Path: /home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/Without_transformation/checkpoint_last.ckpt\n",
      "Transformacion con la que se entreno:  Without_transformation\n",
      "cuda\n",
      "Directorio donde se guardan las medidas de invarianza para  Without_transformation :  Invariance_Results/vit/from_scratch/Without_transformation\n",
      "Se ha creado el directorio 'Invariance_Results/vit/from_scratch/Without_transformation/imagenes'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38962/2683005125.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformacion con la que se va evaluar:  rotacion\n",
      "Se definio la medida\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e19bcc958845fc99c26aa05c56a75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b8165f08a4646baa14e9e1d7f06c084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52be54cb98394a4ca825dec9268de51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardo el csv en Invariance_Results/vit/from_scratch/Without_transformation/rotacion.csv\n",
      "Transformacion con la que se va evaluar:  traslacion\n",
      "Se definio la medida\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37de2ff01d5a4ff1970e288cb490e982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32c98bb18624b6baab2e46443ebe397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2ae4feffb54e8e8b218a57457acb7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardo el csv en Invariance_Results/vit/from_scratch/Without_transformation/traslacion.csv\n",
      "Transformacion con la que se va evaluar:  escala\n",
      "Se definio la medida\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc0b532e10e42c1bb674b4f0de1f397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7145ed65b64e4fc6835b08c54375c47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86def0ea4fb24d1fbeb4c15f69499b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardo el csv en Invariance_Results/vit/from_scratch/Without_transformation/escala.csv\n",
      "Transformacion con la que se va evaluar:  proyeccion\n",
      "Se definio la medida\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e9ab908b8049a68f0e6a8c64b74dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0561cfd821d45a8979f12629c23006f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164eefc9398b4e14ad421a76c96d96a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardo el csv en Invariance_Results/vit/from_scratch/Without_transformation/proyeccion.csv\n",
      "Transformacion con la que se va evaluar:  brillo\n",
      "Se definio la medida\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa98c1e623f748828ea09353696be50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eec1483e42c4a368727a3949375a838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dddc07beb8949f499a23efbfc84e8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardo el csv en Invariance_Results/vit/from_scratch/Without_transformation/brillo.csv\n",
      "Transformacion con la que se va evaluar:  contraste\n",
      "Se definio la medida\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25b063179994114a7b2495bc8f238e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea9b6707a2f4fcba82917bfeab0c220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b55565bfe394cb2a38bc9811f94bbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardo el csv en Invariance_Results/vit/from_scratch/Without_transformation/contraste.csv\n",
      "Transformacion con la que se va evaluar:  escala_grises\n",
      "Se definio la medida\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54a4ddf103b4c4da45c118f9a9091c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932a253480c84a65a4784501e70c9af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e80b095ca144ff0a86ec8ce0c67646a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardo el csv en Invariance_Results/vit/from_scratch/Without_transformation/escala_grises.csv\n",
      "Transformacion con la que se va evaluar:  solarizacion\n",
      "Se definio la medida\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a083dc8587b043f59f00009638fc9183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a7ab38e98a4ceb83e4c774f38bcc2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d1bb90985648b89c10a97d41ed8087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardo el csv en Invariance_Results/vit/from_scratch/Without_transformation/solarizacion.csv\n",
      "Transformacion con la que se va evaluar:  posterizacion\n",
      "Se definio la medida\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49836b3966f4f6a8166d8746e3fbeaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b268616dad467fa79c2221bce5e980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12722bfd455d46a29f37fe749e7492f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardo el csv en Invariance_Results/vit/from_scratch/Without_transformation/posterizacion.csv\n",
      "Transformacion con la que se va evaluar:  inversion_colores\n",
      "Se definio la medida\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e5542d7f434a5f8b1ca2f478722f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad90397668b4bf38c37c60d7708ea26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd665f3ebd047f79afc7d6f7edc1b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardo el csv en Invariance_Results/vit/from_scratch/Without_transformation/inversion_colores.csv\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/proyeccion\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/traslacion\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/brillo\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/escala\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/inversion_colores\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/escala_grises\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/rotacion\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/Without_transformation\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/solarizacion\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/contraste\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/posterizacion\n"
     ]
    }
   ],
   "source": [
    "# Recorrer las carpetas\n",
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Si el directorio .ipynb_checkpoints está en la lista de directorios, elimínalo\n",
    "    if '.ipynb_checkpoints' in dirs:\n",
    "        dirs.remove('.ipynb_checkpoints')\n",
    "    print(root)\n",
    "    # Verificar si hay un archivo 'checkpoint_last.ckpt' en la lista de archivos de la carpeta actual\n",
    "    for dir in dirs:\n",
    "        ## tsin trasnformacion elmodelo se entreno con la capa head modificada\n",
    "        #if 'transformation' in dir:\n",
    "        #    continue\n",
    "        #else:\n",
    "        if 'transformation'in dir:\n",
    "\n",
    "            dir_path = os.path.join(root, dir)\n",
    "            model_path = os.path.join(dir_path, 'checkpoint_last.ckpt')\n",
    "            print(\"Model Path:\", model_path)\n",
    "\n",
    "            # Definir el folder de resultados para cada combinación de modelo e imagen\n",
    "            results_folder_original = os.path.join(root, 'Invariance_Results')\n",
    "\n",
    "            # obtain transformation from directory\n",
    "            directorio_padre = os.path.dirname(model_path)\n",
    "            nombre_directorio = os.path.basename(directorio_padre)\n",
    "\n",
    "            print(\"Transformacion con la que se entreno: \",nombre_directorio)\n",
    "\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            print(device)\n",
    "            #results_path = Path(\"~/tm_example_pytorch/\").expanduser()\n",
    "            #results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # es para cando se entreno con transofmrciones\n",
    "\n",
    "            tinyimagenet_classes = 200\n",
    "            # model.classifier = torch.nn.Sequential(\n",
    "            #     torch.nn.Dropout(p=0.2, inplace=True),\n",
    "            #     torch.nn.Linear(1280, tinyimagenet_classes),\n",
    "            # )\n",
    "\n",
    "            model.head = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.2, inplace=True),\n",
    "            torch.nn.Linear(512, tinyimagenet_classes),  # Ajustar el tamaño según la salida de la capa anterior\n",
    "            )\n",
    "\n",
    "            # Load the model state dictionary\n",
    "            checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "\n",
    "\n",
    "            # If the checkpoint is a state dictionary directly, use it; otherwise, look for the 'state_dict' key\n",
    "            if 'state_dict' in checkpoint:\n",
    "                model_state_dict = checkpoint['state_dict']\n",
    "            else:\n",
    "                model_state_dict = checkpoint\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "            # Load the model state dictionary\n",
    "            model.load_state_dict(model_state_dict)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            results_folder = os.path.join('Invariance_Results/vit/from_scratch/' , nombre_directorio)\n",
    "            \n",
    "            image_path = os.path.join(results_folder,'imagenes')\n",
    "            print(\"Directorio donde se guardan las medidas de invarianza para \", nombre_directorio,\": \",results_folder)\n",
    "            \n",
    "\n",
    "            # Verificar si el directorio existee\n",
    "            if not os.path.exists(image_path):\n",
    "                # Si no existe, crearlo\n",
    "                os.makedirs(image_path)\n",
    "                print(f\"Se ha creado el directorio '{image_path}'.\")\n",
    "\n",
    "        \n",
    "            model = model.to(device)\n",
    "            model.eval()\n",
    "\n",
    "\n",
    "            for transformacion,transf_vector in zip(transformaciones,transformation_afin):\n",
    "                print(\"Transformacion con la que se va evaluar: \",transformacion)\n",
    "                transformations = [  transf_vector[i] for i in range(len(transf_vector))]\n",
    "                \n",
    "                ## results path\n",
    "                #results_folder = 'Resultados de medida de invarianza'\n",
    "                csv_path = os.path.join(results_folder, transformacion + '.csv')\n",
    "                \n",
    "                # Verificar si el archivo CSV ya existe\n",
    "                if os.path.exists(csv_path):\n",
    "                    print(f\"El archivo CSV '{csv_path}' ya existe. Se pasará al siguiente proceso.\")\n",
    "                    continue  # Pasa al siguiente proceso sin guardar el archivo CSV\n",
    "                \n",
    "\n",
    "\n",
    "                # Create an ActivationsModule from the vanilla model\n",
    "                # def filter_stochastic(a):\n",
    "                #     return not str(a).startswith(\"StochasticDepth\")\n",
    "                def filter_activations(layer):\n",
    "                    # Ajusta este filtro según las necesidades específicas de tu modelo\n",
    "                    return not str(layer).startswith(\"StochasticDepth\") and not str(layer).startswith(\"Upsample\")\n",
    "                \n",
    "                def remove_classifier(model):\n",
    "                    if hasattr(model, 'classifier'):\n",
    "                        print(\"Removing 'classifier' layer...\")\n",
    "                        delattr(model, 'classifier') \n",
    "                    return model\n",
    "\n",
    "                model = remove_classifier(model)\n",
    "\n",
    "\n",
    "                activations_module = tm.pytorch.AutoActivationsModule(model,filter=filter_activations)\n",
    "\n",
    "\n",
    "                # Define options for computing the measure\n",
    "                options = tm.pytorch.PyTorchMeasureOptions(batch_size=2, num_workers=0,model_device=device,measure_device=device,data_device = 'cpu') #,data_device=\"cpu\"\n",
    "\n",
    "                # Define the measure and evaluate it\n",
    "                measure = tm.pytorch.NormalizedVarianceInvariance()\n",
    "\n",
    "                print('Se definio la medida')\n",
    "\n",
    "                measure_result:tm.pytorch.PyTorchMeasureResult = measure.eval(test_inv,transformations,activations_module,options)  ## lista de invarianzas de cada capa\n",
    "\n",
    "                measure_result = measure_result.numpy()\n",
    "            \n",
    "\n",
    "                vec_inv = tm.pytorch.PyTorchMeasureResult.per_layer_average(measure_result)\n",
    "\n",
    "                vec_layer = measure_result.layer_names\n",
    "\n",
    "                df_act = pd.DataFrame({'layer_name' : vec_layer,'inv_avg':vec_inv})\n",
    "\n",
    "                df_act.to_csv(csv_path,index= False)\n",
    "                print(f'Se guardo el csv en {csv_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a23c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5d694ca",
   "metadata": {},
   "source": [
    "## Para transformacion Identidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eee7e397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none\n",
      "Model Path: /home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/Without_transformation/checkpoint_last.ckpt\n",
      "Transformacion con la que se entreno:  Without_transformation\n",
      "cuda\n",
      "Directorio donde se guardan las medidas de invarianza para  Without_transformation :  /home/tbadaracco/tb_env/servidor_facu/Invariance_Results/vit/from_scratch/Without_transformation\n",
      "Transformacion con la que se va evaluar:  Identidad\n",
      "Se definio la medida\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38962/4154077270.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41604a73007141f2b4f38e5a66d6a440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97263f7de0f441a1a686d6b50caf033c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce22b8ca25c4d4ba56a9933e5712cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardo el csv en /home/tbadaracco/tb_env/servidor_facu/Invariance_Results/vit/from_scratch/Without_transformation/Identidad.csv\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/proyeccion\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/traslacion\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/brillo\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/escala\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/inversion_colores\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/escala_grises\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/rotacion\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/Without_transformation\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/solarizacion\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/contraste\n",
      "/home/tbadaracco/tb_env/servidor_facu/models/ViT/weights_none/posterizacion\n"
     ]
    }
   ],
   "source": [
    "# Recorrer las carpetas\n",
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Si el directorio .ipynb_checkpoints está en la lista de directorios, elimínalo\n",
    "    if '.ipynb_checkpoints' in dirs:\n",
    "        dirs.remove('.ipynb_checkpoints')\n",
    "    print(root)\n",
    "    # Verificar si hay un archivo 'checkpoint_last.ckpt' en la lista de archivos de la carpeta actual\n",
    "    for dir in dirs:\n",
    "       ## tsin trasnformacion elmodelo se entreno con la capa head modificada\n",
    "        if 'transformation' in dir:\n",
    "            #continue\n",
    "        #else:\n",
    "            dir_path = os.path.join(root, dir)\n",
    "            model_path = os.path.join(dir_path, 'checkpoint_last.ckpt')\n",
    "            print(\"Model Path:\", model_path)\n",
    "\n",
    "            # Definir el folder de resultados para cada combinación de modelo e imagen\n",
    "            results_folder_original = os.path.join(root, 'Invariance_Results')\n",
    "\n",
    "            # obtain transformation from directory\n",
    "            directorio_padre = os.path.dirname(model_path)\n",
    "            nombre_directorio = os.path.basename(directorio_padre)\n",
    "\n",
    "            print(\"Transformacion con la que se entreno: \",nombre_directorio)\n",
    "\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            print(device)\n",
    "            #results_path = Path(\"~/tm_example_pytorch/\").expanduser()\n",
    "            #results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            tinyimagenet_classes = 200\n",
    "            # model.classifier = torch.nn.Sequential(\n",
    "            # torch.nn.Dropout(p=0.2, inplace=True),\n",
    "            #         torch.nn.Linear(1280, tinyimagenet_classes),\n",
    "            #     )\n",
    "\n",
    "            model.head = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.2, inplace=True),\n",
    "            torch.nn.Linear(512, tinyimagenet_classes),  # Ajustar el tamaño según la salida de la capa anterior\n",
    "            )\n",
    "            # Load the model state dictionary\n",
    "            checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "\n",
    "            # If the checkpoint is a state dictionary directly, use it; otherwise, look for the 'state_dict' key\n",
    "            if 'state_dict' in checkpoint:\n",
    "                model_state_dict = checkpoint['state_dict']\n",
    "            else:\n",
    "                model_state_dict = checkpoint\n",
    "\n",
    "            # Load the model state dictionary\n",
    "            model.load_state_dict(model_state_dict)\n",
    "\n",
    "            model = model.to(device)\n",
    "            model.eval()\n",
    "\n",
    "\n",
    "            results_folder = os.path.join(os.getcwd(),'Invariance_Results/vit/from_scratch/' , nombre_directorio)\n",
    "            \n",
    "            image_path = os.path.join(results_folder,'imagenes')\n",
    "            print(\"Directorio donde se guardan las medidas de invarianza para \", nombre_directorio,\": \",results_folder)\n",
    "            \n",
    "\n",
    "            # Verificar si el directorio existee\n",
    "            if not os.path.exists(image_path):\n",
    "                # Si no existe, crearlo\n",
    "                os.makedirs(image_path)\n",
    "                print(f\"Se ha creado el directorio '{image_path}'.\")\n",
    "\n",
    "\n",
    "            \n",
    "            transformacion = 'Identidad'\n",
    "            print(\"Transformacion con la que se va evaluar: \",transformacion)\n",
    "            def identity_transform(x):\n",
    "                return x\n",
    "\n",
    "            transformations = [identity_transform]\n",
    "            \n",
    "            ## results path\n",
    "            #results_folder = 'Resultados de medida de invarianza'\n",
    "            csv_path = os.path.join(results_folder, transformacion + '.csv')\n",
    "            \n",
    "            # Verificar si el archivo CSV ya existe\n",
    "            if os.path.exists(csv_path):\n",
    "                print(f\"El archivo CSV '{csv_path}' ya existe. Se pasará al siguiente proceso.\")\n",
    "                continue  # Pasa al siguiente proceso sin guardar el archivo CSV\n",
    "\n",
    "\n",
    "            def filter_activations(layer):\n",
    "                # Ajusta este filtro según las necesidades específicas de tu modelo\n",
    "                return not str(layer).startswith(\"StochasticDepth\") and not str(layer).startswith(\"Upsample\")\n",
    "            \n",
    "            def remove_classifier(model):\n",
    "                if hasattr(model, 'classifier'):\n",
    "                    print(\"Removing 'classifier' layer...\")\n",
    "                    delattr(model, 'classifier') \n",
    "                return model\n",
    "\n",
    "            model = remove_classifier(model)\n",
    "\n",
    "\n",
    "            activations_module = tm.pytorch.AutoActivationsModule(model,filter=filter_activations)\n",
    "\n",
    "\n",
    "            # Define options for computing the measure\n",
    "            options = tm.pytorch.PyTorchMeasureOptions(batch_size=2, num_workers=0,model_device=device,measure_device=device,data_device = 'cpu') #,data_device=\"cpu\"\n",
    "\n",
    "            # Define the measure and evaluate it\n",
    "            measure = tm.pytorch.NormalizedVarianceInvariance()\n",
    "\n",
    "            print('Se definio la medida')\n",
    "\n",
    "            measure_result:tm.pytorch.PyTorchMeasureResult = measure.eval(test_inv,transformations,activations_module,options)  ## lista de invarianzas de cada capa\n",
    "\n",
    "            measure_result = measure_result.numpy()\n",
    "        \n",
    "\n",
    "            vec_inv = tm.pytorch.PyTorchMeasureResult.per_layer_average(measure_result)\n",
    "\n",
    "            vec_layer = measure_result.layer_names\n",
    "\n",
    "            df_act = pd.DataFrame({'layer_name' : vec_layer,'inv_avg':vec_inv})\n",
    "\n",
    "            df_act.to_csv(csv_path,index= False)\n",
    "            print(f'Se guardo el csv en {csv_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0935b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "## estudiar las layers para crear los graficos\n",
    "csv = '/home/tbadaracco/tb_env/servidor_facu/Invariance_Results/vit/transfer_learning/posterizacion/Identidad.csv'\n",
    "df = pd.read_csv(csv)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8d23c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep='/'\n",
    "s=df.layer_name.str.count(sep)\n",
    "df_layer_split=((s.max()-s).map(lambda x : x*sep)+df.layer_name).str.split(sep,expand=True)\n",
    "df_layer_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd1eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layer_split[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layer_split.iloc[21:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layer_split.loc[df_layer_split[5] == 'levels',5] = df_layer_split[6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f829c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layer_split.loc[df_layer_split[5] == 'attn',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b10a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que busca el término 'FasterViTLayer_n' en las columnas y extrae el valor\n",
    "def find_layer(row):\n",
    "    # Combinar los valores de todas las columnas en una sola cadena\n",
    "    combined = ' '.join(row.values.astype(str))\n",
    "    # Buscar por el patrón 'FasterViTLayer_' y extraer el valor\n",
    "    for value in combined.split():\n",
    "        if \"FasterViTLayer_\" in value:\n",
    "            return value\n",
    "    return np.nan  # Devolver NaN si el patrón no se encuentra\n",
    "\n",
    "# Aplicar la función a cada fila del DataFrame\n",
    "df_layer_split['stage'] = df_layer_split.apply(find_layer, axis=1)\n",
    "\n",
    "# Función para transformar el valor de 'FasterViTLayer_n' a 'Stage n+1'\n",
    "def transform_stage(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    if 'FasterViTLayer_' in value:\n",
    "        # Extraer el número n de la cadena 'FasterViTLayer_n'\n",
    "        number = int(value.split('_')[-1])\n",
    "        # Incrementar el número en 1 y formatear a 'Stage n+1'\n",
    "        return f'Stage {number + 1}'\n",
    "    return value\n",
    "\n",
    "# Aplicar la función a la columna 'stage'\n",
    "df_layer_split['stage'] = df_layer_split['stage'].apply(transform_stage)\n",
    "df_layer_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3ed9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layer_split.iloc[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Encontrar el primer índice donde 'stage' es 'Stage 1'\n",
    "first_stage_1_index = df_layer_split[df_layer_split['stage'] == 'Stage 1'].index.min()\n",
    "\n",
    "# Si hay un 'Stage 1' en el DataFrame\n",
    "if pd.notna(first_stage_1_index):\n",
    "    # Establecer 'Stage 0' para todos los índices anteriores a 'Stage 1'\n",
    "    df_layer_split.loc[:first_stage_1_index - 1, 'stage'] = 'Stage 0'\n",
    "\n",
    "df_layer_split.loc[df_layer_split['stage'].isna(), 'stage'] = 'Head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225bb77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b07402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_layer_split.loc[df_layer_split.stage == 'Stage 3',8]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42ba1dce",
   "metadata": {},
   "source": [
    "# Crea los graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d3a0599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones necesarias\n",
    "\n",
    "# Función que busca el término 'FasterViTLayer_n' en las columnas y extrae el valor\n",
    "def find_layer(row):\n",
    "    # Combinar los valores de todas las columnas en una sola cadena\n",
    "    combined = ' '.join(row.values.astype(str))\n",
    "    # Buscar por el patrón 'FasterViTLayer_' y extraer el valor\n",
    "    for value in combined.split():\n",
    "        if \"FasterViTLayer_\" in value:\n",
    "            return value\n",
    "    return np.nan  # Devolver NaN si el patrón no se encuentra\n",
    "\n",
    "\n",
    "\n",
    "# Función para transformar el valor de 'FasterViTLayer_n' a 'Stage n+1'\n",
    "def transform_stage(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    if 'FasterViTLayer_' in value:\n",
    "        # Extraer el número n de la cadena 'FasterViTLayer_n'\n",
    "        number = int(value.split('_')[-1])\n",
    "        # Incrementar el número en 1 y formatear a 'Stage n+1'\n",
    "        return f'Stage {number + 1}'\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e51b2755-336b-4d1b-86b0-547884ca02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "\n",
    "    sep='/'\n",
    "    s=df.layer_name.str.count(sep)\n",
    "    df_layer_split=((s.max()-s).map(lambda x : x*sep)+df.layer_name).str.split(sep,expand=True)\n",
    "\n",
    "    # Aplicar la función a cada fila del DataFrame\n",
    "    df_layer_split['stage'] = df_layer_split.apply(find_layer, axis=1)\n",
    "\n",
    "    # Aplicar la función a la columna 'stage'\n",
    "    df_layer_split['stage'] = df_layer_split['stage'].apply(transform_stage)\n",
    "    \n",
    "    #Encontrar el primer índice donde 'stage' es 'Stage 1'\n",
    "    first_stage_1_index = df_layer_split[df_layer_split['stage'] == 'Stage 1'].index.min()\n",
    "\n",
    "    # Si hay un 'Stage 1' en el DataFrame\n",
    "    if pd.notna(first_stage_1_index):\n",
    "        # Establecer 'Stage 0' para todos los índices anteriores a 'Stage 1'\n",
    "        df_layer_split.loc[:first_stage_1_index - 1, 'stage'] = 'Stage 0'\n",
    "\n",
    "    df_layer_split.loc[df_layer_split['stage'].isna(), 'stage'] = 'Head'        \n",
    "\n",
    "    # cat_layer_order = CategoricalDtype(\n",
    "    #     ['Normalize_0','Conv2d_0', 'BatchNorm2d_1', 'SiLU_2', 'avgpool', 'fc1','activation', 'fc2', 'scale_activation', 'Dropout_0', 'Linear_1'],\n",
    "    # ordered=True\n",
    "    # )\n",
    "\n",
    "    # cat_layer_order_2 = CategoricalDtype(\n",
    "    #     ['Normalization', 'Conv2dNormActivation_0', 'Conv2dNormActivation_1', 'SqueezeExcitation_1', 'SqueezeExcitation_2', 'Conv2dNormActivation_2', 'Conv2dNormActivation_3', 'Conv2dNormActivation_8', 'pre-classifier', 'classifier'],\n",
    "    #     ordered=True\n",
    "    # )\n",
    "\n",
    "    # # Convertir columnas al tipo categórico\n",
    "    # df_layer_split[4] = df_layer_split[4].astype(cat_layer_order)\n",
    "    # df_layer_split[3] = df_layer_split[3].astype(cat_layer_order_2)\n",
    "    \n",
    "    #df_layer_split.sort_values(by = [0,1,2,3,4], inplace = True)\n",
    "\n",
    "    #df_layer_split.rename(columns={0:'Sequential'},inplace=True)\n",
    "\n",
    "    df_layer_split.reset_index(inplace=True)\n",
    "    df_join = pd.concat([df.loc[:,['layer_name', 'inv_avg']], df_layer_split], axis=1)\n",
    "\n",
    "\n",
    "    df_join.sort_values(by = 'index', inplace = True)\n",
    "    df_join.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    # df_join['layer'] = df_join[4].str.split('_').str[0]\n",
    "    # df_join['layer'] = df_join['layer'] + '_' + df_join.index.astype(str)\n",
    "    # df_join = df_join.loc[~df_join.Sequential.isna()]\n",
    "    # df_join.reset_index(inplace=True,drop=True)\n",
    "    #print(df_join.shape)\n",
    "    \n",
    "    return df_join\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d06a7853",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_clean \u001b[39m=\u001b[39m clean_df(df)\n\u001b[1;32m      2\u001b[0m df_clean\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_clean = clean_df(df)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952da3e1-a2ba-4965-b00e-b95e058bc851",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_directory = '/home/tbadaracco/tb_env/servidor_facu/Invariance_Results/vit/from_scratch'\n",
    "for root, dirs, files in os.walk(main_directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\") and 'clean' not in file:\n",
    "            file_path = os.path.join(root, file)\n",
    "            print(file_path)\n",
    "            # Leer el archivo CSV\n",
    "            df = pd.read_csv(file_path)\n",
    "            #print(df.head())\n",
    "            # Limpiar el DataFrame\n",
    "            df_clean = clean_df(df)\n",
    "            # Obtener el nombre del archivo sin la extensión\n",
    "            file_name, file_ext = os.path.splitext(file)\n",
    "            # Construir el nuevo nombre de archivo con \"_clean\" añadido antes de la extensión\n",
    "            new_file_name = f\"{file_name}_clean{file_ext}\"\n",
    "            # Construir la ruta de destino para guardar el archivo CSV limpio\n",
    "            csv_path = os.path.join(root, new_file_name)\n",
    "            # Guardar el DataFrame limpio como un nuevo archivo CSV\n",
    "            df_clean.to_csv(csv_path, index=False)\n",
    "            print(f'Se guardó el archivo CSV limpio en {csv_path}')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26afbaae-d207-42ad-abd6-e1f761a23647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grafico_completo(df_join,entrenado_transformacion,transformacion):\n",
    "    \n",
    "    #cmap = plt.cm.get_cmap('plasma', 9)    # PiYG\n",
    "    cmap = plt.colormaps['plasma'].resampled(9)\n",
    "    color = []\n",
    "    for i in range(cmap.N):\n",
    "        rgba = cmap(i)\n",
    "        # rgb2hex accepts rgb or rgba\n",
    "\n",
    "        color.append(matplotlib.colors.rgb2hex(rgba))\n",
    "\n",
    "    df_join = df_join.iloc[1:,:]\n",
    "    df_join.reset_index(inplace = True,drop=True)\n",
    "    keys = df_join['stage'].unique()\n",
    "    colours =  dict(zip(keys, color))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(35,8))\n",
    "    for i in range(len(df_join)-1):\n",
    "        x = df_join['layer_name'][i], df_join['layer_name'][i+1]\n",
    "        y = df_join['inv_avg'][i], df_join['inv_avg'][i+1]\n",
    "        c = colours[df_join['stage'][i]]\n",
    "        ax = sns.lineplot(x=x, y=y,color = c,linewidth = 5)\n",
    "        mod_layer = df_join['layer_name'].str.split('_').str[0]\n",
    "        ax.set(xlim=(0, 15))\n",
    "        ax.set_xticks(range(len(df_join)), labels=mod_layer)\n",
    "        ax.tick_params(axis='x', rotation=90 ,which='major', pad=15)\n",
    "        ax.set_xlabel(\"Capas\")\n",
    "        ax.set_ylabel(\"Varianza Normalizada\")\n",
    "        ax.set_title(f'Invarianza por Stage FasterViT re-entrenado con {entrenado_transformacion} y evaluado en {transformacion}')\n",
    "\n",
    "    # Obtener la figura actual y guardarla en una variable\n",
    "    fig = plt.gcf()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd13e2-e856-433b-87be-003cfc7a0d2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_directory = '/home/tbadaracco/tb_env/servidor_facu/Invariance_Results/vit/from_scratch'\n",
    "print(main_directory)\n",
    "## Aplico primer gráfico\n",
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Filtrar solo carpetas, ignorar archivos CSV en esta iteración\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        \n",
    "        # Recorrer los archivos dentro de cada carpeta\n",
    "        for sub_root, sub_dirs, sub_files in os.walk(dir_path):\n",
    "            for file in sub_files:\n",
    "                if file.endswith(\"_clean.csv\") and 'checkpoint' not in file:\n",
    "                    file_path = os.path.join(sub_root, file)\n",
    "\n",
    "                    # Leer el archivo clean CSV\n",
    "                    df = pd.read_csv(file_path)\n",
    "\n",
    "                    # Obtener el nombre del archivo sin la extensión\n",
    "                    file_name, file_ext = os.path.splitext(file)\n",
    "                    file_name = file_name[:-len(\"_clean\")]\n",
    "                    directorio_padre = os.path.dirname(file_path)\n",
    "                    nombre_directorio = os.path.basename(directorio_padre)\n",
    "\n",
    "                    # Verificar si el gráfico ya ha sido guardado\n",
    "                    imagenes_dir = os.path.join(sub_root, 'imagenes')\n",
    "                    imagen_path = os.path.join(imagenes_dir, f'{file_name}_plot_1.png')\n",
    "                    if os.path.exists(imagen_path):\n",
    "                        print(\"El gráfico ya existe, paso al siguiente\")\n",
    "                        continue\n",
    "\n",
    "                    # Crear gráfico\n",
    "                    fig = grafico_completo(df, nombre_directorio, file_name)\n",
    "                    fig.savefig(imagen_path)\n",
    "                    print(f'Se guardó el gráfico en {imagen_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2842d-3ca0-44e7-9d1e-4d63c7dab749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = plt.colormaps['plasma'].resampled(9)    # PiYG\n",
    "color = []\n",
    "for i in range(cmap.N):\n",
    "    rgba = cmap(i)\n",
    "    # rgb2hex accepts rgb or rgba\n",
    "    color.append(matplotlib.colors.rgb2hex(rgba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a2aa5-813d-43d8-85dd-2830a676f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafico_por_estados(df_join,entrenado_transformacion,transformacion):\n",
    "    \n",
    "    df_join = df_join.iloc[1:,:]\n",
    "    df_join.reset_index(inplace = True,drop=True)\n",
    "    keys = df_join['Sequential'].unique()\n",
    "    colours =  dict(zip(keys, color))\n",
    "    #  Categorical Data\n",
    "    a = 3  # number of rows\n",
    "    b = 3  # number of columns\n",
    "    c = 1  # initialize plot counter\n",
    "\n",
    "    fig = plt.figure(figsize=(20,8))\n",
    "\n",
    "    for seq in df_join.Sequential.unique():\n",
    "        plt.subplot(a, b, c)\n",
    "        df = df_join.loc[df_join.Sequential == seq,]\n",
    "        col = colours[seq]\n",
    "        g = sns.lineplot(data = df, x='layer', y='inv_avg',color = col,linewidth = 2,marker = 'o')\n",
    "        mod_layer = df['layer'].str.split('_').str[0]\n",
    "        #g.set(xlim=(0, 15))\n",
    "        g.set_xticks(range(len(df)), labels=mod_layer)\n",
    "        g.tick_params(axis='x', rotation=90 )\n",
    "        c = c + 1\n",
    "        plt.xticks(df['layer'][::1])\n",
    "        g.set_xlabel(\"Capas\")\n",
    "        g.set_ylabel(\"Varianza Normalizada\")\n",
    "        titulo = 'Estado ' + str(c - 1)\n",
    "        plt.title(titulo)\n",
    "        titulo_general = f'Invarianza por capa con transformación re-entrenado con {entrenado_transformacion} y evaluado en {transformacion}'\n",
    "        plt.suptitle(titulo_general, fontsize=16)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f2225-9190-4951-a452-6a5c36f9e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Filtrar solo carpetas, ignorar archivos CSV en esta iteración\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        #print(dir_path)\n",
    "        for sub_root, sub_dirs, sub_files in os.walk(dir_path):\n",
    "            for file in sub_files:\n",
    "                #print(file)\n",
    "                if file.endswith(\"_clean.csv\") and 'checkpoint' not in file:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "\n",
    "                    # Leer el archivo clean CSV\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    # Obtener el nombre del archivo sin la extensión\n",
    "                    file_name, file_ext = os.path.splitext(file)\n",
    "                    file_name = file_name[:-len(\"_clean\")]\n",
    "                    directorio_padre = os.path.dirname(file_path)\n",
    "                    nombre_directorio = os.path.basename(directorio_padre)\n",
    "                    # Verificar si el gráfico ya ha sido guardado\n",
    "                    imagenes_dir = os.path.join(dir_path,'imagenes')\n",
    "                    imagen_path = os.path.join(imagenes_dir, f'{file_name}_plot_2.png')\n",
    "                    if os.path.exists(imagen_path):\n",
    "                        print(\"el grafico ya existe paso al sgte\")\n",
    "                        continue\n",
    "                        # Saltar este archivo si ya ha sido procesado\n",
    "                    #creo grafico\n",
    "                    fig = grafico_por_estados(df,nombre_directorio,file_name)\n",
    "                    fig.savefig(imagen_path)\n",
    "                    print(f'Se guardó el gráfico en {imagen_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4207c8a9-2aee-4a46-bea5-a47d5b580e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  quito los bloques SE para analizar la varianza sin esos bloques xq no son secuenciales\n",
    "bloque_se = ['avgpool',\n",
    "'fc1',\n",
    "'activation',\n",
    "'fc2',\n",
    "'scale_activation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e569e855-acc2-4a7c-b7d1-9d13ddaa53e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafico_sinbloqueSE_completo(df_join,entrenado_transformacion,transformacion):\n",
    "    df1 = df_join.loc[~(df_join['4'].isin(bloque_se))]\n",
    "    df2 = df_join.loc[(df_join['4'].isin(bloque_se)) & (df_join.Sequential == 'Sequential_8')]\n",
    "    df = pd.concat([df1,df2],axis = 0)\n",
    "    df = df.loc[df.Sequential != 'Normalization',]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    print(df.shape)\n",
    "\n",
    "    keys = df['Sequential'].unique()\n",
    "    colours =  dict(zip(keys, color))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(35,8))\n",
    "    for i in range(len(df)-1):\n",
    "        x = df['layer'][i], df['layer'][i+1]\n",
    "        y = df['inv_avg'][i], df['inv_avg'][i+1]\n",
    "        c = colours[df['Sequential'][i]]\n",
    "        ax = sns.lineplot(x=x, y=y,color = c,linewidth = 5,marker = 'o')\n",
    "        mod_layer = df['layer'].str.split('_').str[0]\n",
    "        ax.set(xlim=(0, 15))\n",
    "        ax.set_xticks(range(len(df)), labels=mod_layer)\n",
    "        ax.tick_params(axis='x', rotation=90 ,which='major', pad=15)\n",
    "        ax.set_xlabel(\"Capas\")\n",
    "        ax.set_ylabel(\"Varianza Normalizada\")\n",
    "        ax.set_title(f'Invarianza por capa EfficientNetB0 sin bloques SE y re-entrenado con {entrenado_transformacion} y evaluado en {transformacion}')\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    return fig\n",
    "        #plt.savefig(os.path.join(image_path , 'invarianza sin bloque SE-' + transformacion + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e760c-f283-4c74-8bc5-6e1df5d7dfc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Filtrar solo carpetas, ignorar archivos CSV en esta iteración\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        \n",
    "        # Recorrer los archivos dentro de cada carpeta\n",
    "        for sub_root, sub_dirs, sub_files in os.walk(dir_path):\n",
    "            for file in sub_files:\n",
    "                #print(files)\n",
    "        \n",
    "                if file.endswith(\"_clean.csv\") and 'checkpoint' not in file:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "\n",
    "                    # Leer el archivo clean CSV\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    # Obtener el nombre del archivo sin la extensión\n",
    "                    file_name, file_ext = os.path.splitext(file)\n",
    "                    file_name = file_name[:-len(\"_clean\")]\n",
    "                    directorio_padre = os.path.dirname(file_path)\n",
    "                    nombre_directorio = os.path.basename(directorio_padre)\n",
    "                    # Verificar si el gráfico ya ha sido guardado\n",
    "                    imagenes_dir = os.path.join(dir_path,'imagenes')\n",
    "                    imagen_path = os.path.join(imagenes_dir, f'{file_name}_plot_3.png')\n",
    "                    if os.path.exists(imagen_path):\n",
    "                        print(\"el grafico ya existe paso al sgte\")\n",
    "                        continue\n",
    "                        # Saltar este archivo si ya ha sido procesado\n",
    "                    #creo grafico\n",
    "                    fig = grafico_sinbloqueSE_completo(df,nombre_directorio,file_name)\n",
    "                    fig.savefig(imagen_path)\n",
    "                    print(f'Se guardó el gráfico en {imagen_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7edfb99-f903-4e3b-945f-d640367d3886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grafico_sinbloqueSE_estado(df_join,entrenado_transformacion,transformacion):\n",
    "    df1 = df_join.loc[~(df_join['4'].isin(bloque_se))]\n",
    "    df2 = df_join.loc[(df_join['4'].isin(bloque_se)) & (df_join.Sequential == 'Sequential_8')]\n",
    "    df = pd.concat([df1,df2],axis = 0)\n",
    "    df = df.loc[df.Sequential != 'Normalization',]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    print(df.shape)\n",
    "\n",
    "\n",
    "    keys = df['Sequential'].unique()\n",
    "    colours =  dict(zip(keys, color))\n",
    "        #  Categorical Data\n",
    "    a = 3  # number of rows\n",
    "    b = 3  # number of columns\n",
    "    c = 1  # initialize plot counter\n",
    "\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "    for seq in df.Sequential.unique():\n",
    "        plt.subplot(a, b, c)\n",
    "        df_fil = df.loc[df.Sequential == seq,]\n",
    "        col = colours[seq]\n",
    "        g = sns.lineplot(data = df_fil, x='layer', y='inv_avg',color = col,linewidth = 2,marker = 'o')\n",
    "        mod_layer = df_fil['layer'].str.split('_').str[0]\n",
    "        #g.set(xlim=(0, 15))\n",
    "        g.set_xticks(range(len(df_fil)), labels=mod_layer)\n",
    "        g.tick_params(axis='x', rotation=90 )\n",
    "        c = c + 1\n",
    "        plt.xticks(df_fil['layer'][::1])\n",
    "        g.set_xlabel(\"Capas\")\n",
    "        g.set_ylabel(\"Varianza Normalizada\")\n",
    "        titulo = 'Estado ' + str(c - 1)\n",
    "        plt.title(titulo)\n",
    "        titulo_general = f'Invarianza por capa EfficienNetB0 sin bloques SE re-entrenado con transformación {entrenado_transformacion} y evaluado con {transformacion}'\n",
    "        plt.suptitle(titulo_general, fontsize=16)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9ac465-9640-43d5-b060-3a75ef9cbd2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Filtrar solo carpetas, ignorar archivos CSV en esta iteración\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        \n",
    "        # Recorrer los archivos dentro de cada carpeta\n",
    "        for sub_root, sub_dirs, sub_files in os.walk(dir_path):\n",
    "            for file in sub_files:\n",
    "                if file.endswith(\"_clean.csv\") and 'checkpoint' not in file:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "\n",
    "                    # Leer el archivo clean CSV\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    # Obtener el nombre del archivo sin la extensión\n",
    "                    file_name, file_ext = os.path.splitext(file)\n",
    "                    file_name = file_name[:-len(\"_clean\")]\n",
    "                    directorio_padre = os.path.dirname(file_path)\n",
    "                    nombre_directorio = os.path.basename(directorio_padre)\n",
    "                    # Verificar si el gráfico ya ha sido guardado\n",
    "                    imagenes_dir = os.path.join(dir_path,'imagenes')\n",
    "                    imagen_path = os.path.join(imagenes_dir, f'{file_name}_plot_4.png')\n",
    "                    fig = grafico_sinbloqueSE_estado(df,nombre_directorio,file_name)\n",
    "                    fig.savefig(imagen_path)\n",
    "                    print(f'Se guardó el gráfico en {imagen_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74afb16f-4da9-452a-a2e9-8a35606efdef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grafico_boxplot(df_join,entrenado_transformacion,transformacion):\n",
    "    df1 = df_join.loc[~(df_join['4'].isin(bloque_se))]\n",
    "    df2 = df_join.loc[(df_join['4'].isin(bloque_se)) & (df_join.Sequential == 'Sequential_8')]\n",
    "    df = pd.concat([df1,df2],axis = 0)\n",
    "    df = df.loc[df.Sequential != 'Normalization',]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ##boxplot\n",
    "    df['Estado'] = df['Sequential'].replace({\n",
    "        'Sequential_0': 'Estado 1',\n",
    "        'Sequential_1': 'Estado 2',\n",
    "        'Sequential_2': 'Estado 3',\n",
    "        'Sequential_3': 'Estado 4',\n",
    "        'Sequential_4': 'Estado 5',\n",
    "        'Sequential_5': 'Estado 6',\n",
    "        'Sequential_6': 'Estado 7',\n",
    "        'Sequential_7': 'Estado 8',\n",
    "        'Sequential_8': 'Estado 9'\n",
    "    })\n",
    "\n",
    "    keys = df['Sequential'].unique()\n",
    "    colours =  dict(zip(keys, color))\n",
    "    \n",
    "    # Crear una paleta de colores personalizada basada en el diccionario de colores\n",
    "    custom_palette = sns.color_palette([colours[val] for val in df['Sequential'].unique()])\n",
    "\n",
    "    # Crear un gráfico de caja utilizando seaborn con el parámetro \"hue\" y sin leyenda\n",
    "    g = sns.boxplot(data=df, x='inv_avg', y='Estado', palette=custom_palette, dodge=False)\n",
    "\n",
    "    # Establecer etiquetas de los ejes x e y\n",
    "    g.set_xlabel(\"Varianza Normalizada\")\n",
    "    g.set_ylabel(\"Estado\")\n",
    "\n",
    "    # Establecer el título del gráfico\n",
    "    titulo = f'Invarianza por capa EfficienNetB0 sin bloques SE re-entrenado con transformación {entrenado_transformacion} y evaluado con {transformacion}'\n",
    "    plt.title(titulo)\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7895b-e7c2-4abe-8f90-741d68cdbe55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Filtrar solo carpetas, ignorar archivos CSV en esta iteración\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        \n",
    "        # Recorrer los archivos dentro de cada carpeta\n",
    "        for sub_root, sub_dirs, sub_files in os.walk(dir_path):\n",
    "            for file in sub_files:\n",
    "                if file.endswith(\"_clean.csv\") and 'checkpoint' not in file:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "\n",
    "                    # Leer el archivo clean CSV\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    # Obtener el nombre del archivo sin la extensión\n",
    "                    file_name, file_ext = os.path.splitext(file)\n",
    "                    file_name = file_name[:-len(\"_clean\")]\n",
    "                    directorio_padre = os.path.dirname(file_path)\n",
    "                    nombre_directorio = os.path.basename(directorio_padre)\n",
    "                    # Verificar si el gráfico ya ha sido guardado\n",
    "                    imagenes_dir = os.path.join(dir_path,'imagenes')\n",
    "                    imagen_path = os.path.join(imagenes_dir, f'{file_name}_plot_5.png')\n",
    "                    if os.path.exists(imagen_path):\n",
    "                        print(\"el grafico ya existe paso al sgte\")\n",
    "                        continue\n",
    "                        # Saltar este archivo si ya ha sido procesado\n",
    "                    fig = grafico_boxplot(df,nombre_directorio,file_name)\n",
    "                    fig.savefig(imagen_path)\n",
    "                    print(f'Se guardó el gráfico en {imagen_path}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "376f765f",
   "metadata": {},
   "source": [
    "# Junto todos los csv para poder sacar metricas de la invarianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecbc1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_directory = '/Users/tatibada/Documents/Tesis_Maestria_DM/servidor_facu/Invariance_Results/vit/from_scratch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "826b3622-0398-4154-a1f1-2d28e574975b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_complete = pd.DataFrame()\n",
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Filtrar solo carpetas, ignorar archivos CSV en esta iteración\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        \n",
    "        # Recorrer los archivos dentro de cada carpeta\n",
    "        for sub_root, sub_dirs, sub_files in os.walk(dir_path):\n",
    "            for file in sub_files:\n",
    "                if file.endswith(\"_clean.csv\") and 'checkpoint' not in file:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "\n",
    "                    # Leer el archivo clean CSV\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    # Obtener el nombre del archivo sin la extensión\n",
    "                    file_name, file_ext = os.path.splitext(file)\n",
    "                    file_name = file_name[:-len(\"_clean\")]\n",
    "                    directorio_padre = os.path.dirname(file_path)\n",
    "                    nombre_directorio = os.path.basename(directorio_padre)\n",
    "                    \n",
    "                    ## agrego columnas entrenado e invarianza\n",
    "                    df['Training'] = nombre_directorio\n",
    "                    df['Eval'] = file_name\n",
    "                    ## concateno\n",
    "                    df_complete = pd.concat([df_complete,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "225715bd-959a-4023-9959-5dbe446b2776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tatibada/Documents/Tesis_Maestria_DM/servidor_facu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c7e1cd6-15b8-46f3-a62d-9b635dd78547",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 39895 entries, 0 to 338\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   layer_name  39895 non-null  object \n",
      " 1   inv_avg     39895 non-null  float64\n",
      " 2   index       39895 non-null  int64  \n",
      " 3   0           0 non-null      float64\n",
      " 4   1           6018 non-null   object \n",
      " 5   2           12036 non-null  object \n",
      " 6   3           28084 non-null  object \n",
      " 7   4           38232 non-null  object \n",
      " 8   5           38704 non-null  object \n",
      " 9   6           39412 non-null  object \n",
      " 10  7           39552 non-null  object \n",
      " 11  8           39895 non-null  object \n",
      " 12  stage       39895 non-null  object \n",
      " 13  Training    39895 non-null  object \n",
      " 14  Eval        39895 non-null  object \n",
      "dtypes: float64(2), int64(1), object(12)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_complete.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f568a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_name</th>\n",
       "      <th>inv_avg</th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>stage</th>\n",
       "      <th>Training</th>\n",
       "      <th>Eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/patch_embed/proj</td>\n",
       "      <td>0.765733</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patch_embed</td>\n",
       "      <td>proj</td>\n",
       "      <td>Stage 0</td>\n",
       "      <td>inversion_colores</td>\n",
       "      <td>posterizacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/patch_embed/conv_down/Conv2d_0</td>\n",
       "      <td>0.646632</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patch_embed</td>\n",
       "      <td>conv_down</td>\n",
       "      <td>Conv2d_0</td>\n",
       "      <td>Stage 0</td>\n",
       "      <td>inversion_colores</td>\n",
       "      <td>posterizacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/patch_embed/conv_down/BatchNorm2d_1</td>\n",
       "      <td>0.646632</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patch_embed</td>\n",
       "      <td>conv_down</td>\n",
       "      <td>BatchNorm2d_1</td>\n",
       "      <td>Stage 0</td>\n",
       "      <td>inversion_colores</td>\n",
       "      <td>posterizacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/patch_embed/conv_down/ReLU_2</td>\n",
       "      <td>0.627872</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patch_embed</td>\n",
       "      <td>conv_down</td>\n",
       "      <td>ReLU_2</td>\n",
       "      <td>Stage 0</td>\n",
       "      <td>inversion_colores</td>\n",
       "      <td>posterizacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/patch_embed/conv_down/Conv2d_3</td>\n",
       "      <td>0.651827</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patch_embed</td>\n",
       "      <td>conv_down</td>\n",
       "      <td>Conv2d_3</td>\n",
       "      <td>Stage 0</td>\n",
       "      <td>inversion_colores</td>\n",
       "      <td>posterizacion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             layer_name   inv_avg  index   0    1    2    3  \\\n",
       "0                     /patch_embed/proj  0.765733      0 NaN  NaN  NaN  NaN   \n",
       "1       /patch_embed/conv_down/Conv2d_0  0.646632      1 NaN  NaN  NaN  NaN   \n",
       "2  /patch_embed/conv_down/BatchNorm2d_1  0.646632      2 NaN  NaN  NaN  NaN   \n",
       "3         /patch_embed/conv_down/ReLU_2  0.627872      3 NaN  NaN  NaN  NaN   \n",
       "4       /patch_embed/conv_down/Conv2d_3  0.651827      4 NaN  NaN  NaN  NaN   \n",
       "\n",
       "     4    5            6            7              8    stage  \\\n",
       "0  NaN  NaN          NaN  patch_embed           proj  Stage 0   \n",
       "1  NaN  NaN  patch_embed    conv_down       Conv2d_0  Stage 0   \n",
       "2  NaN  NaN  patch_embed    conv_down  BatchNorm2d_1  Stage 0   \n",
       "3  NaN  NaN  patch_embed    conv_down         ReLU_2  Stage 0   \n",
       "4  NaN  NaN  patch_embed    conv_down       Conv2d_3  Stage 0   \n",
       "\n",
       "            Training           Eval  \n",
       "0  inversion_colores  posterizacion  \n",
       "1  inversion_colores  posterizacion  \n",
       "2  inversion_colores  posterizacion  \n",
       "3  inversion_colores  posterizacion  \n",
       "4  inversion_colores  posterizacion  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b0879a2-a652-4f6a-b2a4-5836f7f2a8f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tatibada/Documents/Tesis_Maestria_DM/servidor_facu/Invariance_Results/vit/from_scratch/df_complete.csv\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(main_directory,'df_complete.csv')\n",
    "print(path)\n",
    "df_complete.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfde34d-0672-4c17-a686-ca48069593c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1caeee56-1a16-4608-a488-6bb0f7b1358b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Without_transformation    3729\n",
       "proyeccion                3718\n",
       "posterizacion             3718\n",
       "escala_grises             3718\n",
       "brillo                    3718\n",
       "rotacion                  3718\n",
       "escala                    3718\n",
       "traslacion                3718\n",
       "inversion_colores         3380\n",
       "contraste                 3380\n",
       "solarizacion              3380\n",
       "Name: Training, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.Training.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2135db2-e12b-4b3a-bdfd-fe6110159f06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "posterizacion        3719\n",
       "contraste            3719\n",
       "escala               3719\n",
       "proyeccion           3719\n",
       "escala_grises        3719\n",
       "rotacion             3719\n",
       "inversion_colores    3719\n",
       "solarizacion         3719\n",
       "brillo               3719\n",
       "traslacion           3719\n",
       "Identidad            2705\n",
       "Name: Eval, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.Eval.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2aaf8c23-49e9-43eb-8859-10e2bb912278",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_name</th>\n",
       "      <th>inv_avg</th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>stage</th>\n",
       "      <th>Training</th>\n",
       "      <th>Eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/patch_embed/proj</td>\n",
       "      <td>0.765733</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patch_embed</td>\n",
       "      <td>proj</td>\n",
       "      <td>Stage 0</td>\n",
       "      <td>inversion_colores</td>\n",
       "      <td>posterizacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/patch_embed/conv_down/Conv2d_0</td>\n",
       "      <td>0.646632</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patch_embed</td>\n",
       "      <td>conv_down</td>\n",
       "      <td>Conv2d_0</td>\n",
       "      <td>Stage 0</td>\n",
       "      <td>inversion_colores</td>\n",
       "      <td>posterizacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/patch_embed/conv_down/BatchNorm2d_1</td>\n",
       "      <td>0.646632</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patch_embed</td>\n",
       "      <td>conv_down</td>\n",
       "      <td>BatchNorm2d_1</td>\n",
       "      <td>Stage 0</td>\n",
       "      <td>inversion_colores</td>\n",
       "      <td>posterizacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/patch_embed/conv_down/ReLU_2</td>\n",
       "      <td>0.627872</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patch_embed</td>\n",
       "      <td>conv_down</td>\n",
       "      <td>ReLU_2</td>\n",
       "      <td>Stage 0</td>\n",
       "      <td>inversion_colores</td>\n",
       "      <td>posterizacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/patch_embed/conv_down/Conv2d_3</td>\n",
       "      <td>0.651827</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patch_embed</td>\n",
       "      <td>conv_down</td>\n",
       "      <td>Conv2d_3</td>\n",
       "      <td>Stage 0</td>\n",
       "      <td>inversion_colores</td>\n",
       "      <td>posterizacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39890</th>\n",
       "      <td>/levels/FasterViTLayer_3/blocks/HAT_4/mlp/drop</td>\n",
       "      <td>0.782639</td>\n",
       "      <td>334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>levels</td>\n",
       "      <td>FasterViTLayer_3</td>\n",
       "      <td>blocks</td>\n",
       "      <td>HAT_4</td>\n",
       "      <td>mlp</td>\n",
       "      <td>drop</td>\n",
       "      <td>Stage 4</td>\n",
       "      <td>Without_transformation</td>\n",
       "      <td>traslacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39891</th>\n",
       "      <td>/norm</td>\n",
       "      <td>0.407935</td>\n",
       "      <td>335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>norm</td>\n",
       "      <td>Head</td>\n",
       "      <td>Without_transformation</td>\n",
       "      <td>traslacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39892</th>\n",
       "      <td>/avgpool</td>\n",
       "      <td>0.272076</td>\n",
       "      <td>336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avgpool</td>\n",
       "      <td>Head</td>\n",
       "      <td>Without_transformation</td>\n",
       "      <td>traslacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39893</th>\n",
       "      <td>/head/Dropout_0</td>\n",
       "      <td>0.272076</td>\n",
       "      <td>337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>head</td>\n",
       "      <td>Dropout_0</td>\n",
       "      <td>Head</td>\n",
       "      <td>Without_transformation</td>\n",
       "      <td>traslacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39894</th>\n",
       "      <td>/head/Linear_1</td>\n",
       "      <td>0.232988</td>\n",
       "      <td>338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>head</td>\n",
       "      <td>Linear_1</td>\n",
       "      <td>Head</td>\n",
       "      <td>Without_transformation</td>\n",
       "      <td>traslacion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39895 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           layer_name   inv_avg  index   0  \\\n",
       "0                                   /patch_embed/proj  0.765733      0 NaN   \n",
       "1                     /patch_embed/conv_down/Conv2d_0  0.646632      1 NaN   \n",
       "2                /patch_embed/conv_down/BatchNorm2d_1  0.646632      2 NaN   \n",
       "3                       /patch_embed/conv_down/ReLU_2  0.627872      3 NaN   \n",
       "4                     /patch_embed/conv_down/Conv2d_3  0.651827      4 NaN   \n",
       "...                                               ...       ...    ...  ..   \n",
       "39890  /levels/FasterViTLayer_3/blocks/HAT_4/mlp/drop  0.782639    334 NaN   \n",
       "39891                                           /norm  0.407935    335 NaN   \n",
       "39892                                        /avgpool  0.272076    336 NaN   \n",
       "39893                                 /head/Dropout_0  0.272076    337 NaN   \n",
       "39894                                  /head/Linear_1  0.232988    338 NaN   \n",
       "\n",
       "         1    2       3                 4       5            6            7  \\\n",
       "0      NaN  NaN     NaN               NaN     NaN          NaN  patch_embed   \n",
       "1      NaN  NaN     NaN               NaN     NaN  patch_embed    conv_down   \n",
       "2      NaN  NaN     NaN               NaN     NaN  patch_embed    conv_down   \n",
       "3      NaN  NaN     NaN               NaN     NaN  patch_embed    conv_down   \n",
       "4      NaN  NaN     NaN               NaN     NaN  patch_embed    conv_down   \n",
       "...    ...  ...     ...               ...     ...          ...          ...   \n",
       "39890  NaN  NaN  levels  FasterViTLayer_3  blocks        HAT_4          mlp   \n",
       "39891  NaN  NaN     NaN               NaN     NaN          NaN          NaN   \n",
       "39892  NaN  NaN     NaN               NaN     NaN          NaN          NaN   \n",
       "39893  NaN  NaN     NaN               NaN     NaN          NaN         head   \n",
       "39894  NaN  NaN     NaN               NaN     NaN          NaN         head   \n",
       "\n",
       "                   8    stage                Training           Eval  \n",
       "0               proj  Stage 0       inversion_colores  posterizacion  \n",
       "1           Conv2d_0  Stage 0       inversion_colores  posterizacion  \n",
       "2      BatchNorm2d_1  Stage 0       inversion_colores  posterizacion  \n",
       "3             ReLU_2  Stage 0       inversion_colores  posterizacion  \n",
       "4           Conv2d_3  Stage 0       inversion_colores  posterizacion  \n",
       "...              ...      ...                     ...            ...  \n",
       "39890           drop  Stage 4  Without_transformation     traslacion  \n",
       "39891           norm     Head  Without_transformation     traslacion  \n",
       "39892        avgpool     Head  Without_transformation     traslacion  \n",
       "39893      Dropout_0     Head  Without_transformation     traslacion  \n",
       "39894       Linear_1     Head  Without_transformation     traslacion  \n",
       "\n",
       "[39895 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.reset_index(inplace=True,drop=True)\n",
    "df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11d4a3d5-712a-4670-b4ef-a5ac7e49786e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['inversion_colores', 'proyeccion', 'posterizacion', 'contraste',\n",
       "       'escala_grises', 'solarizacion', 'brillo', 'rotacion', 'escala',\n",
       "       'traslacion', 'Without_transformation'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.Training.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44970afc-f52c-4700-b824-006d89286775",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# Función para extraer el sufijo numérico\n",
    "def extract_numeric_suffix(layer):\n",
    "    match = re.search(r'_(\\d+)$', layer)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "# Crear una nueva columna con el sufijo numérico\n",
    "df_complete['layer_num'] = df_complete['layer'].apply(extract_numeric_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a21d96c-3aa6-4d7a-9e8e-643e8eb6fe2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "order_transformation = CategoricalDtype(\n",
    "    ['without_transformation','brillo', 'contraste', 'escala_grises','inversion_colores', 'posterizacion','solarizacion', 'escala','proyeccion', 'rotacion', 'traslacion'],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Convertir columnas al tipo categórico\n",
    "df_complete['Training'] = df_complete['Training'].astype(order_transformation)\n",
    "df_complete['Eval'] = df_complete['Eval'].astype(order_transformation)\n",
    "df_complete.sort_values(by = ['Training','Eval','Sequential', 'layer_num'], ascending=[True, True, True, True],inplace=True)\n",
    "df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c59a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.loc[df_complete.Sequential == 'Sequential_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437cf2a-59f7-47b7-9ff5-223c8f91aea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_complete.groupby(['Training','Eval']).inv_avg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f228a4-7584-4789-9a95-0b5bef97052c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_complete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152267db-da78-47ca-a19e-bb7950a6a155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mean = df_complete.groupby(['Training', 'Eval','Sequential']).agg({'inv_avg':'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b7b50-26b3-4108-8919-2b9658518d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08875673-9950-4c2b-a887-64e648773d46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pivot = df_mean.pivot(index=['Training', 'Sequential'], columns=[\"Eval\"], values=\"inv_avg\")\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517a04a-0a2f-42be-8f11-e9f61cd45b68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear el mapa de colores\n",
    "plt.figure(figsize=(10, 25))\n",
    "sns.heatmap(df_pivot, annot=False, cbar=True)\n",
    "\n",
    "plt.title('Heatmap de promedio de Invarianza por Estado')\n",
    "plt.xlabel('Eval')\n",
    "plt.ylabel('Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a3e0e-caff-4036-97cf-d2d24e311529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pivot2 = df_mean.pivot_table(index=['Training'], columns='Eval', values='inv_avg', aggfunc='mean')\n",
    "df_pivot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a8165-4074-4c0b-bd6e-794cf7100d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear el mapa de colores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_pivot2, annot=True, cbar=True)\n",
    "\n",
    "plt.title('Heatmap de promedio de Invarianza por Estado')\n",
    "plt.xlabel('Eval')\n",
    "plt.ylabel('Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776a0455-445e-4bb0-86e4-791e45e031bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8213457-8ac8-42bd-b162-b6faca1ab81b",
   "metadata": {},
   "source": [
    "### Mismo analisis sin bloque SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6135a-5244-4a81-8eaf-9e76ae69c0cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  quito los bloques SE para analizar la invarianza sin esos bloques xq no son secuenciales\n",
    "bloque_se = ['avgpool',\n",
    "'fc1',\n",
    "'activation',\n",
    "'fc2',\n",
    "'scale_activation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc28fd-9d3f-40b6-a5a2-803e9f7c9ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_complete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1358a-1022-4622-bae4-0963b50cda6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_without_se = df_complete.loc[~df_complete['4'].isin(bloque_se)]\n",
    "df_without_se.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90774f05-3aa9-459a-ae71-8a94f27755a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean2 = df_without_se.groupby(['Training', 'Eval','Sequential']).agg({'inv_avg':'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ad481-3397-4bb8-b162-43954b362b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pivot3 = df_mean2.pivot(index=['Training', 'Sequential'], columns=[\"Eval\"], values=\"inv_avg\")\n",
    "df_pivot3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd756664-0814-4ab0-a0f1-b10367cf5fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear el mapa de colores\n",
    "plt.figure(figsize=(10, 25))\n",
    "sns.heatmap(df_pivot3, annot=False, cbar=True)\n",
    "\n",
    "plt.title('Heatmap de promedio de Invarianza por Estado')\n",
    "plt.xlabel('Eval')\n",
    "plt.ylabel('Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efb6b5-32d5-4148-9217-30104aa65a64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pivot4 = df_mean2.pivot_table(index=['Training'], columns='Eval', values='inv_avg', aggfunc='mean')\n",
    "df_pivot4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ffad09-ef03-4c38-8360-5620a7ddb5b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear el mapa de colores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_pivot4, annot=True, cbar=True)\n",
    "\n",
    "plt.title('Heatmap de promedio de Invarianza por Estado')\n",
    "plt.xlabel('Eval')\n",
    "plt.ylabel('Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bf9eac-572c-4a7c-9c5d-d288c4c973d6",
   "metadata": {},
   "source": [
    "### Mismo analisis de la salida de cada bloque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58700436-0fe1-42ae-9229-88cde631c701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Función para extraer el sufijo numérico\n",
    "def extract_numeric_suffix(layer):\n",
    "    match = re.search(r'_(\\d+)$', layer)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "# Crear una nueva columna con el sufijo numérico\n",
    "df_complete['layer_num'] = df_complete['layer'].apply(extract_numeric_suffix)\n",
    "\n",
    "# Ordenar el DataFrame por 'Training', 'Eval', 'Sequential' y 'layer_num'\n",
    "df_sorted = df_complete.sort_values(by=['Training', 'Eval', 'Sequential', 'layer_num'], ascending=[True, True, True, False])\n",
    "\n",
    "# Obtener la capa con el valor más grande en el sufijo dentro de cada grupo\n",
    "df_max_layer = df_sorted.groupby(['Training', 'Eval', 'Sequential']).first().reset_index()\n",
    "\n",
    "# Eliminar la columna auxiliar 'layer_num' si ya no es necesaria\n",
    "df_max_layer = df_max_layer.drop(columns=['layer_num'])\n",
    "\n",
    "# Mostrar el DataFrame con la capa de mayor valor en el sufijo por grupo\n",
    "df_max_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a45ab5-6595-4c7e-ac97-0d6ac8f2d9cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_max_layer.loc[(df_max_layer.Training == 'brillo') & (df_max_layer.Eval == 'brillo') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be10eab-b72d-4aae-ab16-61844b9c2b50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pivot5 = df_max_layer.pivot(index=['Training', 'Sequential'], columns=[\"Eval\"], values=\"inv_avg\")\n",
    "df_pivot5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32012fef-9cfe-4590-b691-e4c11ed8aaca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear el mapa de colores\n",
    "plt.figure(figsize=(10, 25))\n",
    "sns.heatmap(df_pivot5, annot=False, cbar=True)\n",
    "\n",
    "plt.title('Heatmap de Invarianza de la salida de cada Estado')\n",
    "plt.xlabel('Eval')\n",
    "plt.ylabel('Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3a962-6bac-4f82-a615-229227fb73cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pivot6 = df_max_layer.pivot_table(index=['Training'], columns='Eval', values='inv_avg', aggfunc='mean')\n",
    "df_pivot6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d6a6eb-8768-43a5-890e-bbb2615dbf42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear el mapa de colores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_pivot6, annot=True, cbar=True)\n",
    "\n",
    "plt.title('Heatmap de promedio de Invarianza de las salidas de cada estado')\n",
    "plt.xlabel('Eval')\n",
    "plt.ylabel('Training')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f99fd7f",
   "metadata": {},
   "source": [
    "# Accuracy Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6911fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = pd.read_csv('/home/tbadaracco/models/efficientnet_b0/transfer_learning/performance_metrics_final_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc8b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385fdda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_transformation = CategoricalDtype(\n",
    "    ['without_transformation','brillo', 'contraste', 'escala_grises','inversion_colores', 'posterizacion','solarizacion', 'escala','proyeccion', 'rotacion', 'traslacion'],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Convertir columnas al tipo categórico\n",
    "df_complete['Training'] = df_complete['Training'].astype(order_transformation)\n",
    "df_complete['Eval'] = df_complete['Eval'].astype(order_transformation)\n",
    "df_complete.sort_values(by = ['Training','Eval','Sequential', 'layer_num'], ascending=[True, True, True, True],inplace=True)\n",
    "df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada8e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f62f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_pivot = df_acc.pivot(index=['Transformation_training'], columns=[\"Transformation_eval\"], values=\"Accuracy_Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el mapa de colores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_acc_pivot, annot=True, cbar=True)\n",
    "\n",
    "plt.title('Heatmap de Accuracy de training set')\n",
    "plt.xlabel('Eval')\n",
    "plt.ylabel('Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d21f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
