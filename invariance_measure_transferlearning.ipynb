{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2f830fa-650b-48e8-8d35-79f78525e87a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "##import libraries\n",
    "from tinyimagenet import TinyImageNet\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torchvision import models\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.utils.data as data\n",
    "#from torchvision.models._api import WeightsEnum\n",
    "#from torch.hub import load_state_dict_from_url\n",
    "import numpy as np\n",
    "import tmeasures as tm\n",
    "### para mostrar la trasnformacion\n",
    "from tinyimagenet import TinyImageNet\n",
    "from torchvision import transforms as T\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import *\n",
    "import sys\n",
    "\n",
    "sns.set()\n",
    "#%%\n",
    "\n",
    "#sys.path.append('./Notebooks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f8dbbd-7844-441a-ae8d-a7e888c1f5b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import transformations\n"
     ]
    }
   ],
   "source": [
    "# load transformations\n",
    "import transformaciones as tr\n",
    "\n",
    "rotation_transforms = tr.rotation_transforms()\n",
    "translation_transforms = tr.translation_transforms()\n",
    "scale_transforms = tr.scale_transforms()\n",
    "perspective_transforms = tr.perspective_transforms()\n",
    "brightness_transforms = [tr.brightness_transforms(factor) for factor in tr.brightness_parameters]\n",
    "contrast_transformations = [tr.contrast_transforms(alpha) for alpha in tr.contrast_list]\n",
    "grayscale_transformations = [tr.grayscale_transforms(alpha) for alpha in tr.grey_list]\n",
    "solarize_transformations = [tr.solarize_transforms(threshold) for threshold in tr.solarization_thresholds]\n",
    "posterize_transformations = [tr.posterize_transforms(alpha) for alpha in tr.posterize_list]\n",
    "invertion_transformations = [tr.invertion_transforms(alpha) for alpha in tr.invertion_list]\n",
    "\n",
    "\n",
    "transformation_afin = [rotation_transforms,\n",
    "                       translation_transforms,\n",
    "                       scale_transforms,\n",
    "                       perspective_transforms,\n",
    "                       brightness_transforms,\n",
    "                       contrast_transformations,\n",
    "                       grayscale_transformations,\n",
    "                       solarize_transformations,\n",
    "                       posterize_transformations,\n",
    "                       invertion_transformations]\n",
    "\n",
    "\n",
    "transformaciones = ['rotacion','traslacion','escala','proyeccion','brillo','contraste','escala_grises','solarizacion','posterizacion','inversion_colores']\n",
    "\n",
    "print('import transformations')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37da5de0",
   "metadata": {},
   "source": [
    "# Calcula la invarianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49da6785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tbadaracco/servidor_facu/models/efficientnet_b0/transfer_learning\n"
     ]
    }
   ],
   "source": [
    "main_directory = os.path.join(os.getcwd(),'models', 'efficientnet_b0','transfer_learning')\n",
    "print(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5302f447-9e9c-4485-8324-4cbfcf5d2808",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "class TinyImageNet(TinyImageNet):\n",
    "    def __getitem__(self, index):\n",
    "        x, y = super().__getitem__(index)\n",
    "        return x\n",
    "\n",
    "normalize_transform = T.Compose(\n",
    "    [\n",
    "    #T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    #T.Normalize(TinyImageNet.mean,TinyImageNet.std),\n",
    "    #random_ts\n",
    "    ])\n",
    "\n",
    "\n",
    "dataset_nolabels = TinyImageNet(root=\"~/.datasets/tinyimagenet/\",split=\"train\", transform=normalize_transform)\n",
    "\n",
    "# Subsample \n",
    "N = 1000\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "indices, _ = train_test_split(np.arange(len(dataset_nolabels)), train_size=N, stratify=dataset_nolabels.targets,random_state=24)\n",
    "test_inv = Subset(dataset_nolabels, indices)\n",
    "\n",
    "print(len(test_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d076856f-1855-4054-b632-ee3e4adc55df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# Definir el modelo y checkpoint\n",
    "weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "base_model = models.efficientnet_b0(weights=weights)\n",
    "\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Descongelar los parámetros del último bloque de \"features\" (bloque 8)\n",
    "for param in base_model.features[6:9].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Descongelar los parámetros de la capa de clasificación\n",
    "for param in base_model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "tinyimagenet_classes = 200\n",
    "\n",
    "base_model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True),\n",
    "    torch.nn.Linear(1280, tinyimagenet_classes),\n",
    ")\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "   #T.Normalize(TinyImageNet.mean,TinyImageNet.std),\n",
    "    weights.transforms(),\n",
    "    base_model,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89e9ea60",
   "metadata": {},
   "source": [
    "## Para todas las transformaciones excepto identidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162a4415-28f8-40cf-89f9-3d577a7e6f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recorrer las carpetas\n",
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Si el directorio .ipynb_checkpoints está en la lista de directorios, elimínalo\n",
    "    if '.ipynb_checkpoints' in dirs:\n",
    "        dirs.remove('.ipynb_checkpoints')\n",
    "    print(root)\n",
    "    # Verificar si hay un archivo 'checkpoint_last.ckpt' en la lista de archivos de la carpeta actual\n",
    "    for dir in dirs:\n",
    "        dir_path = os.path.join(root, dir)\n",
    "        model_path = os.path.join(dir_path, 'checkpoint_last.ckpt')\n",
    "        print(\"Model Path:\", model_path)\n",
    "\n",
    "        # Definir el folder de resultados para cada combinación de modelo e imagen\n",
    "        results_folder_original = os.path.join(root, 'Invariance_Results')\n",
    "\n",
    "        # obtain transformation from directory\n",
    "        directorio_padre = os.path.dirname(model_path)\n",
    "        nombre_directorio = os.path.basename(directorio_padre)\n",
    "\n",
    "        print(\"Transformacion con la que se entreno: \",nombre_directorio)\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(device)\n",
    "        #results_path = Path(\"~/tm_example_pytorch/\").expanduser()\n",
    "        #results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "        # Load the model state dictionary\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "\n",
    "        # If the checkpoint is a state dictionary directly, use it; otherwise, look for the 'state_dict' key\n",
    "        if 'state_dict' in checkpoint:\n",
    "            model_state_dict = checkpoint['state_dict']\n",
    "        else:\n",
    "            model_state_dict = checkpoint\n",
    "\n",
    "        # Load the model state dictionary\n",
    "        model.load_state_dict(model_state_dict)\n",
    "\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "\n",
    "        results_folder = os.path.join('Invariance_Results/efficientNet_B0/transfer_learning/' , nombre_directorio)\n",
    "        \n",
    "        image_path = os.path.join(results_folder,'imagenes')\n",
    "        print(\"Directorio donde se guardan las medidas de invarianza para \", nombre_directorio,\": \",results_folder)\n",
    "        \n",
    "\n",
    "        # Verificar si el directorio existee\n",
    "        if not os.path.exists(image_path):\n",
    "            # Si no existe, crearlo\n",
    "            os.makedirs(image_path)\n",
    "            print(f\"Se ha creado el directorio '{image_path}'.\")\n",
    "\n",
    "\n",
    "        for transformacion,transf_vector in zip(transformaciones,transformation_afin):\n",
    "            print(\"Transformacion con la que se va evaluar: \",transformacion)\n",
    "            transformations = [  transf_vector[i] for i in range(len(transf_vector))]\n",
    "            \n",
    "            ## results path\n",
    "            #results_folder = 'Resultados de medida de invarianza'\n",
    "            csv_path = os.path.join(results_folder, transformacion + '.csv')\n",
    "            \n",
    "            # Verificar si el archivo CSV ya existe\n",
    "            if os.path.exists(csv_path):\n",
    "                print(f\"El archivo CSV '{csv_path}' ya existe. Se pasará al siguiente proceso.\")\n",
    "                continue  # Pasa al siguiente proceso sin guardar el archivo CSV\n",
    "\n",
    "\n",
    "            # Create an ActivationsModule from the vanilla model\n",
    "            def filter_stochastic(a):\n",
    "                return not str(a).startswith(\"StochasticDepth\")\n",
    "\n",
    "            activations_module = tm.pytorch.AutoActivationsModule(model,filter=filter_stochastic)\n",
    "\n",
    "\n",
    "            # Define options for computing the measure\n",
    "            options = tm.pytorch.PyTorchMeasureOptions(batch_size=2, num_workers=0,model_device=device,measure_device=device,data_device = 'cpu') #,data_device=\"cpu\"\n",
    "\n",
    "            # Define the measure and evaluate it\n",
    "            measure = tm.pytorch.NormalizedVarianceInvariance()\n",
    "\n",
    "            print('Se definio la medida')\n",
    "\n",
    "            measure_result:tm.pytorch.PyTorchMeasureResult = measure.eval(test_inv,transformations,activations_module,options)  ## lista de invarianzas de cada capa\n",
    "\n",
    "            measure_result = measure_result.numpy()\n",
    "        \n",
    "\n",
    "            vec_inv = tm.pytorch.PyTorchMeasureResult.per_layer_average(measure_result)\n",
    "\n",
    "            vec_layer = measure_result.layer_names\n",
    "\n",
    "            df_act = pd.DataFrame({'layer_name' : vec_layer,'inv_avg':vec_inv})\n",
    "\n",
    "            df_act.to_csv(csv_path,index= False)\n",
    "            print(f'Se guardo el csv en {csv_path}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5d694ca",
   "metadata": {},
   "source": [
    "## Para transformacion Identidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee7e397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_130863/2073423991.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tbadaracco/servidor_facu/models/efficientnet_b0/transfer_learning\n",
      "Model Path: /home/tbadaracco/servidor_facu/models/efficientnet_b0/transfer_learning/proyeccion/checkpoint_last.ckpt\n",
      "Transformacion con la que se entreno:  proyeccion\n",
      "cuda\n",
      "Directorio donde se guardan las medidas de invarianza para  proyeccion :  /home/tbadaracco/servidor_facu/Invariance_Results/efficientNet_B0/transfer_learning/proyeccion\n",
      "Transformacion con la que se va evaluar:  Identidad\n",
      "Se definio la medida\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:46, 35.63s/it]                       0.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardo el csv en /home/tbadaracco/servidor_facu/Invariance_Results/efficientNet_B0/transfer_learning/proyeccion/Identidad.csv\n",
      "Model Path: /home/tbadaracco/servidor_facu/models/efficientnet_b0/transfer_learning/traslacion/checkpoint_last.ckpt\n",
      "Transformacion con la que se entreno:  traslacion\n",
      "cuda\n",
      "Directorio donde se guardan las medidas de invarianza para  traslacion :  /home/tbadaracco/servidor_facu/Invariance_Results/efficientNet_B0/transfer_learning/traslacion\n",
      "Transformacion con la que se va evaluar:  Identidad\n",
      "Se definio la medida\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:47, 35.83s/it]                       0.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardo el csv en /home/tbadaracco/servidor_facu/Invariance_Results/efficientNet_B0/transfer_learning/traslacion/Identidad.csv\n",
      "Model Path: /home/tbadaracco/servidor_facu/models/efficientnet_b0/transfer_learning/brillo/checkpoint_last.ckpt\n",
      "Transformacion con la que se entreno:  brillo\n",
      "cuda\n",
      "Directorio donde se guardan las medidas de invarianza para  brillo :  /home/tbadaracco/servidor_facu/Invariance_Results/efficientNet_B0/transfer_learning/brillo\n",
      "Transformacion con la que se va evaluar:  Identidad\n",
      "Se definio la medida\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:48, 36.13s/it]                       1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardo el csv en /home/tbadaracco/servidor_facu/Invariance_Results/efficientNet_B0/transfer_learning/brillo/Identidad.csv\n",
      "Model Path: /home/tbadaracco/servidor_facu/models/efficientnet_b0/transfer_learning/escala/checkpoint_last.ckpt\n",
      "Transformacion con la que se entreno:  escala\n",
      "cuda\n",
      "Directorio donde se guardan las medidas de invarianza para  escala :  /home/tbadaracco/servidor_facu/Invariance_Results/efficientNet_B0/transfer_learning/escala\n",
      "Transformacion con la que se va evaluar:  Identidad\n",
      "Se definio la medida\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:48, 36.33s/it]                       1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se guardo el csv en /home/tbadaracco/servidor_facu/Invariance_Results/efficientNet_B0/transfer_learning/escala/Identidad.csv\n",
      "Model Path: /home/tbadaracco/servidor_facu/models/efficientnet_b0/transfer_learning/inversion_colores/checkpoint_last.ckpt\n",
      "Transformacion con la que se entreno:  inversion_colores\n",
      "cuda\n",
      "Directorio donde se guardan las medidas de invarianza para  inversion_colores :  /home/tbadaracco/servidor_facu/Invariance_Results/efficientNet_B0/transfer_learning/inversion_colores\n",
      "Transformacion con la que se va evaluar:  Identidad\n",
      "Se definio la medida\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[32m          \u001b[0m| 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Recorrer las carpetas\n",
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Si el directorio .ipynb_checkpoints está en la lista de directorios, elimínalo\n",
    "    if '.ipynb_checkpoints' in dirs:\n",
    "        dirs.remove('.ipynb_checkpoints')\n",
    "    print(root)\n",
    "    # Verificar si hay un archivo 'checkpoint_last.ckpt' en la lista de archivos de la carpeta actual\n",
    "    for dir in dirs:\n",
    "        dir_path = os.path.join(root, dir)\n",
    "        model_path = os.path.join(dir_path, 'checkpoint_last.ckpt')\n",
    "        print(\"Model Path:\", model_path)\n",
    "\n",
    "        # Definir el folder de resultados para cada combinación de modelo e imagen\n",
    "        results_folder_original = os.path.join(root, 'Invariance_Results')\n",
    "\n",
    "        # obtain transformation from directory\n",
    "        directorio_padre = os.path.dirname(model_path)\n",
    "        nombre_directorio = os.path.basename(directorio_padre)\n",
    "\n",
    "        print(\"Transformacion con la que se entreno: \",nombre_directorio)\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(device)\n",
    "        #results_path = Path(\"~/tm_example_pytorch/\").expanduser()\n",
    "        #results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "        # Load the model state dictionary\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "\n",
    "\n",
    "        # If the checkpoint is a state dictionary directly, use it; otherwise, look for the 'state_dict' key\n",
    "        if 'state_dict' in checkpoint:\n",
    "            model_state_dict = checkpoint['state_dict']\n",
    "        else:\n",
    "            model_state_dict = checkpoint\n",
    "\n",
    "        # Load the model state dictionary\n",
    "        model.load_state_dict(model_state_dict)\n",
    "\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "\n",
    "        results_folder = os.path.join(os.getcwd(),'Invariance_Results/efficientNet_B0/transfer_learning/' , nombre_directorio)\n",
    "        \n",
    "        image_path = os.path.join(results_folder,'imagenes')\n",
    "        print(\"Directorio donde se guardan las medidas de invarianza para \", nombre_directorio,\": \",results_folder)\n",
    "        \n",
    "\n",
    "        # Verificar si el directorio existee\n",
    "        if not os.path.exists(image_path):\n",
    "            # Si no existe, crearlo\n",
    "            os.makedirs(image_path)\n",
    "            print(f\"Se ha creado el directorio '{image_path}'.\")\n",
    "\n",
    "\n",
    "        \n",
    "        transformacion = 'Identidad'\n",
    "        print(\"Transformacion con la que se va evaluar: \",transformacion)\n",
    "        def identity_transform(x):\n",
    "            return x\n",
    "\n",
    "        transformations = [identity_transform]\n",
    "        \n",
    "        ## results path\n",
    "        #results_folder = 'Resultados de medida de invarianza'\n",
    "        csv_path = os.path.join(results_folder, transformacion + '.csv')\n",
    "        \n",
    "        # Verificar si el archivo CSV ya existe\n",
    "        if os.path.exists(csv_path):\n",
    "            print(f\"El archivo CSV '{csv_path}' ya existe. Se pasará al siguiente proceso.\")\n",
    "            continue  # Pasa al siguiente proceso sin guardar el archivo CSV\n",
    "\n",
    "\n",
    "        # Create an ActivationsModule from the vanilla model\n",
    "        def filter_stochastic(a):\n",
    "            return not str(a).startswith(\"StochasticDepth\")\n",
    "\n",
    "        activations_module = tm.pytorch.AutoActivationsModule(model,filter=filter_stochastic)\n",
    "\n",
    "\n",
    "        # Define options for computing the measure\n",
    "        options = tm.pytorch.PyTorchMeasureOptions(batch_size=2, num_workers=0,model_device=device,measure_device=device,data_device = 'cpu') #,data_device=\"cpu\"\n",
    "\n",
    "        # Define the measure and evaluate it\n",
    "        measure = tm.pytorch.NormalizedVarianceInvariance()\n",
    "\n",
    "        print('Se definio la medida')\n",
    "\n",
    "        measure_result:tm.pytorch.PyTorchMeasureResult = measure.eval(test_inv,transformations,activations_module,options)  ## lista de invarianzas de cada capa\n",
    "\n",
    "        measure_result = measure_result.numpy()\n",
    "    \n",
    "\n",
    "        vec_inv = tm.pytorch.PyTorchMeasureResult.per_layer_average(measure_result)\n",
    "\n",
    "        vec_layer = measure_result.layer_names\n",
    "\n",
    "        df_act = pd.DataFrame({'layer_name' : vec_layer,'inv_avg':vec_inv})\n",
    "\n",
    "        df_act.to_csv(csv_path,index= False)\n",
    "        print(f'Se guardo el csv en {csv_path}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42ba1dce",
   "metadata": {},
   "source": [
    "# Crea los graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b2755-336b-4d1b-86b0-547884ca02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "\n",
    "    df['layer_name'] = df['layer_name'].str.replace('/EfficientNet_1/features/','')\n",
    "    df['layer_name'] = df['layer_name'].str.replace('/EfficientNet_1/','')\n",
    "\n",
    "    sep='/'\n",
    "    s=df.layer_name.str.count(sep)\n",
    "    df_layer_split=((s.max()-s).map(lambda x : x*sep)+df.layer_name).str.split(sep,expand=True)\n",
    "\n",
    "    df_layer_split.loc[df_layer_split[4] == 'Normalize_0',0] = 'Normalization'\n",
    "\n",
    "    df_layer_split.loc[(df_layer_split[3] == 'Conv2dNormActivation_0') & (df_layer_split[0] == ''),0] = 'Sequential_0'\n",
    "    df_layer_split.loc[(df_layer_split[3] == 'Conv2dNormActivation_8') & (df_layer_split[0] == ''),0] = 'Sequential_8'\n",
    "    df_layer_split.loc[df_layer_split[3] == 'classifier',0] = 'Sequential_8'\n",
    "    df_layer_split.loc[(df_layer_split[4] == 'avgpool') & (df_layer_split[0] == ''),0] = 'Sequential_8'\n",
    "    df_layer_split.loc[(df_layer_split[3]== '') & (df_layer_split[0] == 'Sequential_8'),3] = 'pre-classifier'\n",
    "\n",
    "    #print(df_layer_split.shape)\n",
    "    df_layer_split = df_layer_split.loc[df_layer_split[0] != ''] \n",
    "    #print(df_layer_split.shape)\n",
    "\n",
    "\n",
    "    cat_layer_order = CategoricalDtype(\n",
    "        ['Normalize_0','Conv2d_0', 'BatchNorm2d_1', 'SiLU_2', 'avgpool', 'fc1','activation', 'fc2', 'scale_activation', 'Dropout_0', 'Linear_1'],\n",
    "    ordered=True\n",
    "    )\n",
    "\n",
    "    cat_layer_order_2 = CategoricalDtype(\n",
    "        ['Normalization', 'Conv2dNormActivation_0', 'Conv2dNormActivation_1', 'SqueezeExcitation_1', 'SqueezeExcitation_2', 'Conv2dNormActivation_2', 'Conv2dNormActivation_3', 'Conv2dNormActivation_8', 'pre-classifier', 'classifier'],\n",
    "        ordered=True\n",
    "    )\n",
    "\n",
    "    # Convertir columnas al tipo categórico\n",
    "    df_layer_split[4] = df_layer_split[4].astype(cat_layer_order)\n",
    "    df_layer_split[3] = df_layer_split[3].astype(cat_layer_order_2)\n",
    "    \n",
    "    df_layer_split.sort_values(by = [0,1,2,3,4], inplace = True)\n",
    "\n",
    "    df_layer_split.rename(columns={0:'Sequential'},inplace=True)\n",
    "\n",
    "    df_join = pd.concat([df.loc[:,['layer_name', 'inv_avg']], df_layer_split], axis=1)\n",
    "\n",
    "\n",
    "    df_join.sort_values(by = ['Sequential',1,2,3,4], inplace = True)\n",
    "    df_join.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    df_join['layer'] = df_join[4].str.split('_').str[0]\n",
    "    df_join['layer'] = df_join['layer'] + '_' + df_join.index.astype(str)\n",
    "    df_join = df_join.loc[~df_join.Sequential.isna()]\n",
    "    df_join.reset_index(inplace=True,drop=True)\n",
    "    #print(df_join.shape)\n",
    "    \n",
    "    return df_join\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952da3e1-a2ba-4965-b00e-b95e058bc851",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_directory = '/home/tbadaracco/Invariance_Results/efficientNet_B0/transfer_learning'\n",
    "for root, dirs, files in os.walk(main_directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\") and 'clean' not in file:\n",
    "            file_path = os.path.join(root, file)\n",
    "            print(file_path)\n",
    "            # Leer el archivo CSV\n",
    "            df = pd.read_csv(file_path)\n",
    "            #print(df.head())\n",
    "            # Limpiar el DataFrame\n",
    "            df_clean = clean_df(df)\n",
    "            # Obtener el nombre del archivo sin la extensión\n",
    "            file_name, file_ext = os.path.splitext(file)\n",
    "            # Construir el nuevo nombre de archivo con \"_clean\" añadido antes de la extensión\n",
    "            new_file_name = f\"{file_name}_clean{file_ext}\"\n",
    "            # Construir la ruta de destino para guardar el archivo CSV limpio\n",
    "            csv_path = os.path.join(root, new_file_name)\n",
    "            # Guardar el DataFrame limpio como un nuevo archivo CSV\n",
    "            df_clean.to_csv(csv_path, index=False)\n",
    "            print(f'Se guardó el archivo CSV limpio en {csv_path}')\n",
    "            #aplico el primer grafico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26afbaae-d207-42ad-abd6-e1f761a23647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grafico_completo(df_join,entrenado_transformacion,transformacion):\n",
    "    \n",
    "    #cmap = plt.cm.get_cmap('plasma', 9)    # PiYG\n",
    "    cmap = plt.colormaps['plasma'].resampled(9)\n",
    "    color = []\n",
    "    for i in range(cmap.N):\n",
    "        rgba = cmap(i)\n",
    "        # rgb2hex accepts rgb or rgba\n",
    "\n",
    "        color.append(matplotlib.colors.rgb2hex(rgba))\n",
    "\n",
    "    df_join = df_join.iloc[1:,:]\n",
    "    df_join.reset_index(inplace = True,drop=True)\n",
    "    keys = df_join['Sequential'].unique()\n",
    "    colours =  dict(zip(keys, color))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(35,8))\n",
    "    for i in range(len(df_join)-1):\n",
    "        x = df_join['layer'][i], df_join['layer'][i+1]\n",
    "        y = df_join['inv_avg'][i], df_join['inv_avg'][i+1]\n",
    "        c = colours[df_join['Sequential'][i]]\n",
    "        ax = sns.lineplot(x=x, y=y,color = c,linewidth = 5)\n",
    "        mod_layer = df_join['layer'].str.split('_').str[0]\n",
    "        ax.set(xlim=(0, 15))\n",
    "        ax.set_xticks(range(len(df_join)), labels=mod_layer)\n",
    "        ax.tick_params(axis='x', rotation=90 ,which='major', pad=15)\n",
    "        ax.set_xlabel(\"Capas\")\n",
    "        ax.set_ylabel(\"Varianza Normalizada\")\n",
    "        ax.set_title(f'Invarianza por capa EfficientNetB0 re-entrenado con {entrenado_transformacion} y evaluado en {transformacion}')\n",
    "\n",
    "    # Obtener la figura actual y guardarla en una variable\n",
    "    fig = plt.gcf()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd13e2-e856-433b-87be-003cfc7a0d2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_directory = '/home/tbadaracco/Invariance_Results/efficientNet_B0/transfer_learning'\n",
    "print(main_directory)\n",
    "## Aplico primer gráfico\n",
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Filtrar solo carpetas, ignorar archivos CSV en esta iteración\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        \n",
    "        # Recorrer los archivos dentro de cada carpeta\n",
    "        for sub_root, sub_dirs, sub_files in os.walk(dir_path):\n",
    "            for file in sub_files:\n",
    "                if file.endswith(\"_clean.csv\") and 'checkpoint' not in file:\n",
    "                    file_path = os.path.join(sub_root, file)\n",
    "\n",
    "                    # Leer el archivo clean CSV\n",
    "                    df = pd.read_csv(file_path)\n",
    "\n",
    "                    # Obtener el nombre del archivo sin la extensión\n",
    "                    file_name, file_ext = os.path.splitext(file)\n",
    "                    file_name = file_name[:-len(\"_clean\")]\n",
    "                    directorio_padre = os.path.dirname(file_path)\n",
    "                    nombre_directorio = os.path.basename(directorio_padre)\n",
    "\n",
    "                    # Verificar si el gráfico ya ha sido guardado\n",
    "                    imagenes_dir = os.path.join(sub_root, 'imagenes')\n",
    "                    imagen_path = os.path.join(imagenes_dir, f'{file_name}_plot_1.png')\n",
    "                    if os.path.exists(imagen_path):\n",
    "                        print(\"El gráfico ya existe, paso al siguiente\")\n",
    "                        continue\n",
    "\n",
    "                    # Crear gráfico\n",
    "                    fig = grafico_completo(df, nombre_directorio, file_name)\n",
    "                    fig.savefig(imagen_path)\n",
    "                    print(f'Se guardó el gráfico en {imagen_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b2842d-3ca0-44e7-9d1e-4d63c7dab749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmap = plt.colormaps['plasma'].resampled(9)    # PiYG\n",
    "color = []\n",
    "for i in range(cmap.N):\n",
    "    rgba = cmap(i)\n",
    "    # rgb2hex accepts rgb or rgba\n",
    "    color.append(matplotlib.colors.rgb2hex(rgba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a2aa5-813d-43d8-85dd-2830a676f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafico_por_estados(df_join,entrenado_transformacion,transformacion):\n",
    "    \n",
    "    df_join = df_join.iloc[1:,:]\n",
    "    df_join.reset_index(inplace = True,drop=True)\n",
    "    keys = df_join['Sequential'].unique()\n",
    "    colours =  dict(zip(keys, color))\n",
    "    #  Categorical Data\n",
    "    a = 3  # number of rows\n",
    "    b = 3  # number of columns\n",
    "    c = 1  # initialize plot counter\n",
    "\n",
    "    fig = plt.figure(figsize=(20,8))\n",
    "\n",
    "    for seq in df_join.Sequential.unique():\n",
    "        plt.subplot(a, b, c)\n",
    "        df = df_join.loc[df_join.Sequential == seq,]\n",
    "        col = colours[seq]\n",
    "        g = sns.lineplot(data = df, x='layer', y='inv_avg',color = col,linewidth = 2,marker = 'o')\n",
    "        mod_layer = df['layer'].str.split('_').str[0]\n",
    "        #g.set(xlim=(0, 15))\n",
    "        g.set_xticks(range(len(df)), labels=mod_layer)\n",
    "        g.tick_params(axis='x', rotation=90 )\n",
    "        c = c + 1\n",
    "        plt.xticks(df['layer'][::1])\n",
    "        g.set_xlabel(\"Capas\")\n",
    "        g.set_ylabel(\"Varianza Normalizada\")\n",
    "        titulo = 'Estado ' + str(c - 1)\n",
    "        plt.title(titulo)\n",
    "        titulo_general = f'Invarianza por capa con transformación re-entrenado con {entrenado_transformacion} y evaluado en {transformacion}'\n",
    "        plt.suptitle(titulo_general, fontsize=16)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f2225-9190-4951-a452-6a5c36f9e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Filtrar solo carpetas, ignorar archivos CSV en esta iteración\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        #print(dir_path)\n",
    "        for sub_root, sub_dirs, sub_files in os.walk(dir_path):\n",
    "            for file in sub_files:\n",
    "                #print(file)\n",
    "                if file.endswith(\"_clean.csv\") and 'checkpoint' not in file:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "\n",
    "                    # Leer el archivo clean CSV\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    # Obtener el nombre del archivo sin la extensión\n",
    "                    file_name, file_ext = os.path.splitext(file)\n",
    "                    file_name = file_name[:-len(\"_clean\")]\n",
    "                    directorio_padre = os.path.dirname(file_path)\n",
    "                    nombre_directorio = os.path.basename(directorio_padre)\n",
    "                    # Verificar si el gráfico ya ha sido guardado\n",
    "                    imagenes_dir = os.path.join(dir_path,'imagenes')\n",
    "                    imagen_path = os.path.join(imagenes_dir, f'{file_name}_plot_2.png')\n",
    "                    if os.path.exists(imagen_path):\n",
    "                        print(\"el grafico ya existe paso al sgte\")\n",
    "                        continue\n",
    "                        # Saltar este archivo si ya ha sido procesado\n",
    "                    #creo grafico\n",
    "                    fig = grafico_por_estados(df,nombre_directorio,file_name)\n",
    "                    fig.savefig(imagen_path)\n",
    "                    print(f'Se guardó el gráfico en {imagen_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4207c8a9-2aee-4a46-bea5-a47d5b580e59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  quito los bloques SE para analizar la varianza sin esos bloques xq no son secuenciales\n",
    "bloque_se = ['avgpool',\n",
    "'fc1',\n",
    "'activation',\n",
    "'fc2',\n",
    "'scale_activation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e569e855-acc2-4a7c-b7d1-9d13ddaa53e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafico_sinbloqueSE_completo(df_join,entrenado_transformacion,transformacion):\n",
    "    df1 = df_join.loc[~(df_join['4'].isin(bloque_se))]\n",
    "    df2 = df_join.loc[(df_join['4'].isin(bloque_se)) & (df_join.Sequential == 'Sequential_8')]\n",
    "    df = pd.concat([df1,df2],axis = 0)\n",
    "    df = df.loc[df.Sequential != 'Normalization',]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    print(df.shape)\n",
    "\n",
    "    keys = df['Sequential'].unique()\n",
    "    colours =  dict(zip(keys, color))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(35,8))\n",
    "    for i in range(len(df)-1):\n",
    "        x = df['layer'][i], df['layer'][i+1]\n",
    "        y = df['inv_avg'][i], df['inv_avg'][i+1]\n",
    "        c = colours[df['Sequential'][i]]\n",
    "        ax = sns.lineplot(x=x, y=y,color = c,linewidth = 5,marker = 'o')\n",
    "        mod_layer = df['layer'].str.split('_').str[0]\n",
    "        ax.set(xlim=(0, 15))\n",
    "        ax.set_xticks(range(len(df)), labels=mod_layer)\n",
    "        ax.tick_params(axis='x', rotation=90 ,which='major', pad=15)\n",
    "        ax.set_xlabel(\"Capas\")\n",
    "        ax.set_ylabel(\"Varianza Normalizada\")\n",
    "        ax.set_title(f'Invarianza por capa EfficientNetB0 sin bloques SE y re-entrenado con {entrenado_transformacion} y evaluado en {transformacion}')\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    return fig\n",
    "        #plt.savefig(os.path.join(image_path , 'invarianza sin bloque SE-' + transformacion + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e760c-f283-4c74-8bc5-6e1df5d7dfc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Filtrar solo carpetas, ignorar archivos CSV en esta iteración\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        \n",
    "        # Recorrer los archivos dentro de cada carpeta\n",
    "        for sub_root, sub_dirs, sub_files in os.walk(dir_path):\n",
    "            for file in sub_files:\n",
    "                #print(files)\n",
    "        \n",
    "                if file.endswith(\"_clean.csv\") and 'checkpoint' not in file:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "\n",
    "                    # Leer el archivo clean CSV\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    # Obtener el nombre del archivo sin la extensión\n",
    "                    file_name, file_ext = os.path.splitext(file)\n",
    "                    file_name = file_name[:-len(\"_clean\")]\n",
    "                    directorio_padre = os.path.dirname(file_path)\n",
    "                    nombre_directorio = os.path.basename(directorio_padre)\n",
    "                    # Verificar si el gráfico ya ha sido guardado\n",
    "                    imagenes_dir = os.path.join(dir_path,'imagenes')\n",
    "                    imagen_path = os.path.join(imagenes_dir, f'{file_name}_plot_3.png')\n",
    "                    if os.path.exists(imagen_path):\n",
    "                        print(\"el grafico ya existe paso al sgte\")\n",
    "                        continue\n",
    "                        # Saltar este archivo si ya ha sido procesado\n",
    "                    #creo grafico\n",
    "                    fig = grafico_sinbloqueSE_completo(df,nombre_directorio,file_name)\n",
    "                    fig.savefig(imagen_path)\n",
    "                    print(f'Se guardó el gráfico en {imagen_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7edfb99-f903-4e3b-945f-d640367d3886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grafico_sinbloqueSE_estado(df_join,entrenado_transformacion,transformacion):\n",
    "    df1 = df_join.loc[~(df_join['4'].isin(bloque_se))]\n",
    "    df2 = df_join.loc[(df_join['4'].isin(bloque_se)) & (df_join.Sequential == 'Sequential_8')]\n",
    "    df = pd.concat([df1,df2],axis = 0)\n",
    "    df = df.loc[df.Sequential != 'Normalization',]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    print(df.shape)\n",
    "\n",
    "\n",
    "    keys = df['Sequential'].unique()\n",
    "    colours =  dict(zip(keys, color))\n",
    "        #  Categorical Data\n",
    "    a = 3  # number of rows\n",
    "    b = 3  # number of columns\n",
    "    c = 1  # initialize plot counter\n",
    "\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "    for seq in df.Sequential.unique():\n",
    "        plt.subplot(a, b, c)\n",
    "        df_fil = df.loc[df.Sequential == seq,]\n",
    "        col = colours[seq]\n",
    "        g = sns.lineplot(data = df_fil, x='layer', y='inv_avg',color = col,linewidth = 2,marker = 'o')\n",
    "        mod_layer = df_fil['layer'].str.split('_').str[0]\n",
    "        #g.set(xlim=(0, 15))\n",
    "        g.set_xticks(range(len(df_fil)), labels=mod_layer)\n",
    "        g.tick_params(axis='x', rotation=90 )\n",
    "        c = c + 1\n",
    "        plt.xticks(df_fil['layer'][::1])\n",
    "        g.set_xlabel(\"Capas\")\n",
    "        g.set_ylabel(\"Varianza Normalizada\")\n",
    "        titulo = 'Estado ' + str(c - 1)\n",
    "        plt.title(titulo)\n",
    "        titulo_general = f'Invarianza por capa EfficienNetB0 sin bloques SE re-entrenado con transformación {entrenado_transformacion} y evaluado con {transformacion}'\n",
    "        plt.suptitle(titulo_general, fontsize=16)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9ac465-9640-43d5-b060-3a75ef9cbd2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Filtrar solo carpetas, ignorar archivos CSV en esta iteración\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        \n",
    "        # Recorrer los archivos dentro de cada carpeta\n",
    "        for sub_root, sub_dirs, sub_files in os.walk(dir_path):\n",
    "            for file in sub_files:\n",
    "                if file.endswith(\"_clean.csv\") and 'checkpoint' not in file:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "\n",
    "                    # Leer el archivo clean CSV\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    # Obtener el nombre del archivo sin la extensión\n",
    "                    file_name, file_ext = os.path.splitext(file)\n",
    "                    file_name = file_name[:-len(\"_clean\")]\n",
    "                    directorio_padre = os.path.dirname(file_path)\n",
    "                    nombre_directorio = os.path.basename(directorio_padre)\n",
    "                    # Verificar si el gráfico ya ha sido guardado\n",
    "                    imagenes_dir = os.path.join(dir_path,'imagenes')\n",
    "                    imagen_path = os.path.join(imagenes_dir, f'{file_name}_plot_4.png')\n",
    "                    fig = grafico_sinbloqueSE_estado(df,nombre_directorio,file_name)\n",
    "                    fig.savefig(imagen_path)\n",
    "                    print(f'Se guardó el gráfico en {imagen_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74afb16f-4da9-452a-a2e9-8a35606efdef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grafico_boxplot(df_join,entrenado_transformacion,transformacion):\n",
    "    df1 = df_join.loc[~(df_join['4'].isin(bloque_se))]\n",
    "    df2 = df_join.loc[(df_join['4'].isin(bloque_se)) & (df_join.Sequential == 'Sequential_8')]\n",
    "    df = pd.concat([df1,df2],axis = 0)\n",
    "    df = df.loc[df.Sequential != 'Normalization',]\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    ##boxplot\n",
    "    df['Estado'] = df['Sequential'].replace({\n",
    "        'Sequential_0': 'Estado 1',\n",
    "        'Sequential_1': 'Estado 2',\n",
    "        'Sequential_2': 'Estado 3',\n",
    "        'Sequential_3': 'Estado 4',\n",
    "        'Sequential_4': 'Estado 5',\n",
    "        'Sequential_5': 'Estado 6',\n",
    "        'Sequential_6': 'Estado 7',\n",
    "        'Sequential_7': 'Estado 8',\n",
    "        'Sequential_8': 'Estado 9'\n",
    "    })\n",
    "\n",
    "    keys = df['Sequential'].unique()\n",
    "    colours =  dict(zip(keys, color))\n",
    "    \n",
    "    # Crear una paleta de colores personalizada basada en el diccionario de colores\n",
    "    custom_palette = sns.color_palette([colours[val] for val in df['Sequential'].unique()])\n",
    "\n",
    "    # Crear un gráfico de caja utilizando seaborn con el parámetro \"hue\" y sin leyenda\n",
    "    g = sns.boxplot(data=df, x='inv_avg', y='Estado', palette=custom_palette, dodge=False)\n",
    "\n",
    "    # Establecer etiquetas de los ejes x e y\n",
    "    g.set_xlabel(\"Varianza Normalizada\")\n",
    "    g.set_ylabel(\"Estado\")\n",
    "\n",
    "    # Establecer el título del gráfico\n",
    "    titulo = f'Invarianza por capa EfficienNetB0 sin bloques SE re-entrenado con transformación {entrenado_transformacion} y evaluado con {transformacion}'\n",
    "    plt.title(titulo)\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7895b-e7c2-4abe-8f90-741d68cdbe55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Filtrar solo carpetas, ignorar archivos CSV en esta iteración\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        \n",
    "        # Recorrer los archivos dentro de cada carpeta\n",
    "        for sub_root, sub_dirs, sub_files in os.walk(dir_path):\n",
    "            for file in sub_files:\n",
    "                if file.endswith(\"_clean.csv\") and 'checkpoint' not in file:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "\n",
    "                    # Leer el archivo clean CSV\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    # Obtener el nombre del archivo sin la extensión\n",
    "                    file_name, file_ext = os.path.splitext(file)\n",
    "                    file_name = file_name[:-len(\"_clean\")]\n",
    "                    directorio_padre = os.path.dirname(file_path)\n",
    "                    nombre_directorio = os.path.basename(directorio_padre)\n",
    "                    # Verificar si el gráfico ya ha sido guardado\n",
    "                    imagenes_dir = os.path.join(dir_path,'imagenes')\n",
    "                    imagen_path = os.path.join(imagenes_dir, f'{file_name}_plot_5.png')\n",
    "                    if os.path.exists(imagen_path):\n",
    "                        print(\"el grafico ya existe paso al sgte\")\n",
    "                        continue\n",
    "                        # Saltar este archivo si ya ha sido procesado\n",
    "                    fig = grafico_boxplot(df,nombre_directorio,file_name)\n",
    "                    fig.savefig(imagen_path)\n",
    "                    print(f'Se guardó el gráfico en {imagen_path}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "376f765f",
   "metadata": {},
   "source": [
    "# Junto todos los csv para poder sacar metricas de la invarianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826b3622-0398-4154-a1f1-2d28e574975b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_complete = pd.DataFrame()\n",
    "for root, dirs, files in os.walk(main_directory):\n",
    "    # Filtrar solo carpetas, ignorar archivos CSV en esta iteración\n",
    "    for dir_name in dirs:\n",
    "        dir_path = os.path.join(root, dir_name)\n",
    "        \n",
    "        # Recorrer los archivos dentro de cada carpeta\n",
    "        for sub_root, sub_dirs, sub_files in os.walk(dir_path):\n",
    "            for file in sub_files:\n",
    "                if file.endswith(\"_clean.csv\") and 'checkpoint' not in file:\n",
    "                    file_path = os.path.join(dir_path, file)\n",
    "\n",
    "                    # Leer el archivo clean CSV\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    # Obtener el nombre del archivo sin la extensión\n",
    "                    file_name, file_ext = os.path.splitext(file)\n",
    "                    file_name = file_name[:-len(\"_clean\")]\n",
    "                    directorio_padre = os.path.dirname(file_path)\n",
    "                    nombre_directorio = os.path.basename(directorio_padre)\n",
    "                    \n",
    "                    ## agrego columnas entrenado e invarianza\n",
    "                    df['Training'] = nombre_directorio\n",
    "                    df['Eval'] = file_name\n",
    "                    ## concateno\n",
    "                    df_complete = pd.concat([df_complete,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225715bd-959a-4023-9959-5dbe446b2776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e1cd6-15b8-46f3-a62d-9b635dd78547",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_complete.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f568a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0879a2-a652-4f6a-b2a4-5836f7f2a8f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/home/tbadaracco/Invariance_Results/efficientNet_B0/transfer_learning/df_complete.csv'\n",
    "df_complete.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfde34d-0672-4c17-a686-ca48069593c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caeee56-1a16-4608-a488-6bb0f7b1358b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_complete.Training.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2135db2-e12b-4b3a-bdfd-fe6110159f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_complete.Eval.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf8c23-49e9-43eb-8859-10e2bb912278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_complete.reset_index(inplace=True,drop=True)\n",
    "df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d4a3d5-712a-4670-b4ef-a5ac7e49786e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_complete.Training.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44970afc-f52c-4700-b824-006d89286775",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# Función para extraer el sufijo numérico\n",
    "def extract_numeric_suffix(layer):\n",
    "    match = re.search(r'_(\\d+)$', layer)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "# Crear una nueva columna con el sufijo numérico\n",
    "df_complete['layer_num'] = df_complete['layer'].apply(extract_numeric_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a21d96c-3aa6-4d7a-9e8e-643e8eb6fe2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "order_transformation = CategoricalDtype(\n",
    "    ['without_transformation','brillo', 'contraste', 'escala_grises','inversion_colores', 'posterizacion','solarizacion', 'escala','proyeccion', 'rotacion', 'traslacion'],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Convertir columnas al tipo categórico\n",
    "df_complete['Training'] = df_complete['Training'].astype(order_transformation)\n",
    "df_complete['Eval'] = df_complete['Eval'].astype(order_transformation)\n",
    "df_complete.sort_values(by = ['Training','Eval','Sequential', 'layer_num'], ascending=[True, True, True, True],inplace=True)\n",
    "df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c59a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete.loc[df_complete.Sequential == 'Sequential_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f437cf2a-59f7-47b7-9ff5-223c8f91aea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_complete.groupby(['Training','Eval']).inv_avg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f228a4-7584-4789-9a95-0b5bef97052c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_complete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152267db-da78-47ca-a19e-bb7950a6a155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mean = df_complete.groupby(['Training', 'Eval','Sequential']).agg({'inv_avg':'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b7b50-26b3-4108-8919-2b9658518d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08875673-9950-4c2b-a887-64e648773d46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pivot = df_mean.pivot(index=['Training', 'Sequential'], columns=[\"Eval\"], values=\"inv_avg\")\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517a04a-0a2f-42be-8f11-e9f61cd45b68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear el mapa de colores\n",
    "plt.figure(figsize=(10, 25))\n",
    "sns.heatmap(df_pivot, annot=False, cbar=True)\n",
    "\n",
    "plt.title('Heatmap de promedio de Invarianza por Estado')\n",
    "plt.xlabel('Eval')\n",
    "plt.ylabel('Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a3e0e-caff-4036-97cf-d2d24e311529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pivot2 = df_mean.pivot_table(index=['Training'], columns='Eval', values='inv_avg', aggfunc='mean')\n",
    "df_pivot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a8165-4074-4c0b-bd6e-794cf7100d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear el mapa de colores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_pivot2, annot=True, cbar=True)\n",
    "\n",
    "plt.title('Heatmap de promedio de Invarianza por Estado')\n",
    "plt.xlabel('Eval')\n",
    "plt.ylabel('Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776a0455-445e-4bb0-86e4-791e45e031bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8213457-8ac8-42bd-b162-b6faca1ab81b",
   "metadata": {},
   "source": [
    "### Mismo analisis sin bloque SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6135a-5244-4a81-8eaf-9e76ae69c0cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  quito los bloques SE para analizar la invarianza sin esos bloques xq no son secuenciales\n",
    "bloque_se = ['avgpool',\n",
    "'fc1',\n",
    "'activation',\n",
    "'fc2',\n",
    "'scale_activation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc28fd-9d3f-40b6-a5a2-803e9f7c9ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_complete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1358a-1022-4622-bae4-0963b50cda6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_without_se = df_complete.loc[~df_complete['4'].isin(bloque_se)]\n",
    "df_without_se.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90774f05-3aa9-459a-ae71-8a94f27755a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean2 = df_without_se.groupby(['Training', 'Eval','Sequential']).agg({'inv_avg':'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ad481-3397-4bb8-b162-43954b362b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pivot3 = df_mean2.pivot(index=['Training', 'Sequential'], columns=[\"Eval\"], values=\"inv_avg\")\n",
    "df_pivot3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd756664-0814-4ab0-a0f1-b10367cf5fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear el mapa de colores\n",
    "plt.figure(figsize=(10, 25))\n",
    "sns.heatmap(df_pivot3, annot=False, cbar=True)\n",
    "\n",
    "plt.title('Heatmap de promedio de Invarianza por Estado')\n",
    "plt.xlabel('Eval')\n",
    "plt.ylabel('Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efb6b5-32d5-4148-9217-30104aa65a64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pivot4 = df_mean2.pivot_table(index=['Training'], columns='Eval', values='inv_avg', aggfunc='mean')\n",
    "df_pivot4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ffad09-ef03-4c38-8360-5620a7ddb5b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear el mapa de colores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_pivot4, annot=True, cbar=True)\n",
    "\n",
    "plt.title('Heatmap de promedio de Invarianza por Estado')\n",
    "plt.xlabel('Eval')\n",
    "plt.ylabel('Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bf9eac-572c-4a7c-9c5d-d288c4c973d6",
   "metadata": {},
   "source": [
    "### Mismo analisis de la salida de cada bloque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58700436-0fe1-42ae-9229-88cde631c701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Función para extraer el sufijo numérico\n",
    "def extract_numeric_suffix(layer):\n",
    "    match = re.search(r'_(\\d+)$', layer)\n",
    "    return int(match.group(1)) if match else -1\n",
    "\n",
    "# Crear una nueva columna con el sufijo numérico\n",
    "df_complete['layer_num'] = df_complete['layer'].apply(extract_numeric_suffix)\n",
    "\n",
    "# Ordenar el DataFrame por 'Training', 'Eval', 'Sequential' y 'layer_num'\n",
    "df_sorted = df_complete.sort_values(by=['Training', 'Eval', 'Sequential', 'layer_num'], ascending=[True, True, True, False])\n",
    "\n",
    "# Obtener la capa con el valor más grande en el sufijo dentro de cada grupo\n",
    "df_max_layer = df_sorted.groupby(['Training', 'Eval', 'Sequential']).first().reset_index()\n",
    "\n",
    "# Eliminar la columna auxiliar 'layer_num' si ya no es necesaria\n",
    "df_max_layer = df_max_layer.drop(columns=['layer_num'])\n",
    "\n",
    "# Mostrar el DataFrame con la capa de mayor valor en el sufijo por grupo\n",
    "df_max_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a45ab5-6595-4c7e-ac97-0d6ac8f2d9cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_max_layer.loc[(df_max_layer.Training == 'brillo') & (df_max_layer.Eval == 'brillo') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be10eab-b72d-4aae-ab16-61844b9c2b50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pivot5 = df_max_layer.pivot(index=['Training', 'Sequential'], columns=[\"Eval\"], values=\"inv_avg\")\n",
    "df_pivot5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32012fef-9cfe-4590-b691-e4c11ed8aaca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear el mapa de colores\n",
    "plt.figure(figsize=(10, 25))\n",
    "sns.heatmap(df_pivot5, annot=False, cbar=True)\n",
    "\n",
    "plt.title('Heatmap de Invarianza de la salida de cada Estado')\n",
    "plt.xlabel('Eval')\n",
    "plt.ylabel('Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3a962-6bac-4f82-a615-229227fb73cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_pivot6 = df_max_layer.pivot_table(index=['Training'], columns='Eval', values='inv_avg', aggfunc='mean')\n",
    "df_pivot6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d6a6eb-8768-43a5-890e-bbb2615dbf42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear el mapa de colores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_pivot6, annot=True, cbar=True)\n",
    "\n",
    "plt.title('Heatmap de promedio de Invarianza de las salidas de cada estado')\n",
    "plt.xlabel('Eval')\n",
    "plt.ylabel('Training')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f99fd7f",
   "metadata": {},
   "source": [
    "## Accuracy Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6911fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = pd.read_csv('/home/tbadaracco/models/efficientnet_b0/transfer_learning/performance_metrics_final_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc8b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385fdda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_transformation = CategoricalDtype(\n",
    "    ['without_transformation','brillo', 'contraste', 'escala_grises','inversion_colores', 'posterizacion','solarizacion', 'escala','proyeccion', 'rotacion', 'traslacion'],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Convertir columnas al tipo categórico\n",
    "df_complete['Training'] = df_complete['Training'].astype(order_transformation)\n",
    "df_complete['Eval'] = df_complete['Eval'].astype(order_transformation)\n",
    "df_complete.sort_values(by = ['Training','Eval','Sequential', 'layer_num'], ascending=[True, True, True, True],inplace=True)\n",
    "df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada8e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f62f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc_pivot = df_acc.pivot(index=['Transformation_training'], columns=[\"Transformation_eval\"], values=\"Accuracy_Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el mapa de colores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df_acc_pivot, annot=True, cbar=True)\n",
    "\n",
    "plt.title('Heatmap de Accuracy de training set')\n",
    "plt.xlabel('Eval')\n",
    "plt.ylabel('Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d21f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
