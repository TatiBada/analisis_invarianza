{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "##import libraries\n",
    "from tinyimagenet import TinyImageNet\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import torch.utils.data as data\n",
    "from torchvision.models._api import WeightsEnum\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import poutyne\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "import sys\n",
    "import random\n",
    "\n",
    "#/Users/tatibada/Documents/Tesis Maestria DM/scripts/EfficientNet/pipeline_B0_weightsnone_soloentrenamiento_v2.py\n",
    "#sys.path.append('/content/drive/MyDrive/Tesis de Ms Data Mining TBadaracco/Notebooks/')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import transformations\n"
     ]
    }
   ],
   "source": [
    "# load transformations\n",
    "import transformaciones as tr\n",
    "\n",
    "rotation_transforms = tr.rotation_transforms()\n",
    "translation_transforms = tr.translation_transforms()\n",
    "scale_transforms = tr.scale_transforms()\n",
    "perspective_transforms = tr.perspective_transforms()\n",
    "brightness_transforms = [tr.brightness_transforms(factor) for factor in tr.brightness_parameters]\n",
    "contrast_transformations = [tr.contrast_transforms(alpha) for alpha in tr.contrast_list]\n",
    "grayscale_transformations = [tr.grayscale_transforms(alpha) for alpha in tr.grey_list]\n",
    "solarize_transformations = [tr.solarize_transforms(threshold) for threshold in tr.solarization_thresholds]\n",
    "posterize_transformations = [tr.posterize_transforms(alpha) for alpha in tr.posterize_list]\n",
    "invertion_transformations = [tr.invertion_transforms(alpha) for alpha in tr.invertion_list]\n",
    "\n",
    "\n",
    "transformation_afin = [rotation_transforms,\n",
    "                       translation_transforms,\n",
    "                       scale_transforms,\n",
    "                       perspective_transforms,\n",
    "                       brightness_transforms,\n",
    "                       contrast_transformations,\n",
    "                       grayscale_transformations,\n",
    "                       solarize_transformations,\n",
    "                       posterize_transformations,\n",
    "                       invertion_transformations]\n",
    "\n",
    "\n",
    "transformaciones = ['rotacion','traslacion','escala','proyeccion','brillo','contraste','escala_grises','solarizacion','posterizacion','inversion_colores']\n",
    "\n",
    "print('import transformations')\n",
    "\n",
    "#### para salucionar error: RuntimeError: invalid hash value (expected \"7eb33cd5\", got \"23ab8bcd5bdbef61a7a43b91adcad81f622fd7f36fb4935a569828d77888c44e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## si quiero con vit b16 de pytorch\n",
    "# def get_state_dict(self, *args, **kwargs):\n",
    "#     kwargs.pop(\"check_hash\")\n",
    "#     return load_state_dict_from_url(self.url, *args, **kwargs)\n",
    "\n",
    "# WeightsEnum.get_state_dict = get_state_dict\n",
    "# #####\n",
    "\n",
    "# # Definir el modelo y checkpoint\n",
    "# weights = models.ViT_B_16_Weights.IMAGENET1K_V1\n",
    "# base_model = models.vit_b_16(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbadaracco/tb_env/lib/python3.10/site-packages/fastervit/models/faster_vit.py:193: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from timm.models import _builder\n",
    "\n",
    "_builder._update_default_kwargs = _builder._update_default_model_kwargs\n",
    "\n",
    "## fastervit\n",
    "from fastervit import create_model\n",
    "# Define fastervit-0 model with 224 x 224 resolution\n",
    "\n",
    "base_model = create_model('faster_vit_0_224', \n",
    "                          pretrained=True,\n",
    "                          model_path=\"/home/tbadaracco//faster_vit_0.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterViT(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Identity()\n",
       "    (conv_down): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (levels): ModuleList(\n",
       "    (0): FasterViTLayer(\n",
       "      (blocks): ModuleList(\n",
       "        (0): ConvBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_path): DropPath(drop_prob=0.013)\n",
       "        )\n",
       "      )\n",
       "      (downsample): Downsample(\n",
       "        (norm): LayerNorm2d((64,), eps=1e-06, elementwise_affine=True)\n",
       "        (reduction): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): FasterViTLayer(\n",
       "      (blocks): ModuleList(\n",
       "        (0): ConvBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_path): DropPath(drop_prob=0.027)\n",
       "        )\n",
       "        (1): ConvBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_path): DropPath(drop_prob=0.040)\n",
       "        )\n",
       "        (2): ConvBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act1): GELU(approximate='none')\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_path): DropPath(drop_prob=0.053)\n",
       "        )\n",
       "      )\n",
       "      (downsample): Downsample(\n",
       "        (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
       "        (reduction): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): FasterViTLayer(\n",
       "      (blocks): ModuleList(\n",
       "        (0): HAT(\n",
       "          (pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.067)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (hat_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (hat_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (hat_attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (hat_mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (hat_drop_path): DropPath(drop_prob=0.067)\n",
       "          (hat_pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (upsampler): Upsample(size=7, mode='nearest')\n",
       "        )\n",
       "        (1): HAT(\n",
       "          (pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.080)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (hat_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (hat_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (hat_attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (hat_mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (hat_drop_path): DropPath(drop_prob=0.080)\n",
       "          (hat_pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (upsampler): Upsample(size=7, mode='nearest')\n",
       "        )\n",
       "        (2): HAT(\n",
       "          (pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.093)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (hat_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (hat_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (hat_attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (hat_mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (hat_drop_path): DropPath(drop_prob=0.093)\n",
       "          (hat_pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (upsampler): Upsample(size=7, mode='nearest')\n",
       "        )\n",
       "        (3): HAT(\n",
       "          (pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.107)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (hat_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (hat_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (hat_attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (hat_mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (hat_drop_path): DropPath(drop_prob=0.107)\n",
       "          (hat_pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (upsampler): Upsample(size=7, mode='nearest')\n",
       "        )\n",
       "        (4): HAT(\n",
       "          (pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.120)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (hat_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (hat_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (hat_attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (hat_mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (hat_drop_path): DropPath(drop_prob=0.120)\n",
       "          (hat_pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (upsampler): Upsample(size=7, mode='nearest')\n",
       "        )\n",
       "        (5): HAT(\n",
       "          (pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.133)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (hat_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (hat_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (hat_attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (hat_mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (hat_drop_path): DropPath(drop_prob=0.133)\n",
       "          (hat_pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (upsampler): Upsample(size=7, mode='nearest')\n",
       "        )\n",
       "      )\n",
       "      (downsample): Downsample(\n",
       "        (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
       "        (reduction): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (global_tokenizer): TokenInitializer(\n",
       "        (pos_embed): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        (to_global_feature): Sequential(\n",
       "          (pos): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "          (pool): AvgPool2d(kernel_size=5, stride=3, padding=0)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): FasterViTLayer(\n",
       "      (blocks): ModuleList(\n",
       "        (0): HAT(\n",
       "          (pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.147)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): HAT(\n",
       "          (pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.160)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): HAT(\n",
       "          (pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.173)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): HAT(\n",
       "          (pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.187)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): HAT(\n",
       "          (pos_embed): PosEmbMLPSwinv1D(\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
       "              (cpb_mlp): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "                (1): ReLU(inplace=True)\n",
       "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop_path): DropPath(drop_prob=0.200)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (head): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Descongelar los parámetros de la capa de clasificación\n",
    "# for param in base_model.heads.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "tinyimagenet_classes = 200\n",
    "# base_model.classifier = torch.nn.Sequential(\n",
    "#     torch.nn.Dropout(p=0.2, inplace=True),\n",
    "#     torch.nn.Linear(1280, tinyimagenet_classes),\n",
    "# )\n",
    "# Reemplazar el clasificador del modelo FasterViT\n",
    "base_model.head = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True),\n",
    "    torch.nn.Linear(512, tinyimagenet_classes),  # Ajustar el tamaño según la salida de la capa anterior\n",
    ")\n",
    "\n",
    "# model = torch.nn.Sequential(\n",
    "#    #T.Normalize(TinyImageNet.mean,TinyImageNet.std),\n",
    "#     weights.transforms(),\n",
    "#     base_model,\n",
    "# )\n",
    "\n",
    "\n",
    "model = base_model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with transformation: Without_transformation\n",
      "checkpoint path: models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "checkpoint optimizer path: models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "DataLoader listo\n",
      "Epoch:  1/20 Train steps: 3125 Val steps: 313 14m45.74s loss: 2.765247 acc: 35.363000 top5: 62.534000 fscore_macro: 0.346507 val_loss: 1.895455 val_acc: 52.720000 val_top5: 79.150000 val_fscore_macro: 0.520790\n",
      "Epoch 1: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 1: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch:  2/20 Train steps: 3125 Val steps: 313 14m46.59s loss: 1.826214 acc: 54.216000 top5: 80.401000 fscore_macro: 0.539103 val_loss: 1.734774 val_acc: 56.410000 val_top5: 82.020000 val_fscore_macro: 0.563078\n",
      "Epoch 2: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 2: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch:  3/20 Train steps: 3125 Val steps: 313 14m45.89s loss: 1.511672 acc: 60.986000 top5: 85.261000 fscore_macro: 0.607946 val_loss: 1.567395 val_acc: 60.890000 val_top5: 84.250000 val_fscore_macro: 0.609416\n",
      "Epoch 3: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 3: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch:  4/20 Train steps: 3125 Val steps: 313 14m47.30s loss: 1.291910 acc: 66.001000 top5: 88.260000 fscore_macro: 0.658631 val_loss: 1.476387 val_acc: 63.410000 val_top5: 85.530000 val_fscore_macro: 0.634257\n",
      "Epoch 4: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 4: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch:  5/20 Train steps: 3125 Val steps: 313 14m46.39s loss: 1.113727 acc: 70.149000 top5: 90.761000 fscore_macro: 0.700448 val_loss: 1.477311 val_acc: 63.100000 val_top5: 85.730000 val_fscore_macro: 0.630639\n",
      "Epoch 5: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 5: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch:  6/20 Train steps: 3125 Val steps: 313 14m46.79s loss: 0.968687 acc: 73.312000 top5: 92.577000 fscore_macro: 0.732276 val_loss: 1.471208 val_acc: 64.050000 val_top5: 86.040000 val_fscore_macro: 0.640498\n",
      "Epoch 6: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 6: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch:  7/20 Train steps: 3125 Val steps: 313 14m46.35s loss: 0.845415 acc: 76.289000 top5: 94.047000 fscore_macro: 0.762364 val_loss: 1.486322 val_acc: 64.540000 val_top5: 86.280000 val_fscore_macro: 0.644485\n",
      "Epoch 7: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 7: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch:  8/20 Train steps: 3125 Val steps: 313 14m47.47s loss: 0.740568 acc: 78.882000 top5: 95.319000 fscore_macro: 0.788370 val_loss: 1.530225 val_acc: 64.770000 val_top5: 86.220000 val_fscore_macro: 0.646341\n",
      "Epoch 8: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 8: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch:  9/20 Train steps: 3125 Val steps: 313 14m46.61s loss: 0.650427 acc: 80.998000 top5: 96.265000 fscore_macro: 0.809627 val_loss: 1.526360 val_acc: 65.750000 val_top5: 86.270000 val_fscore_macro: 0.656905\n",
      "Epoch 9: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 9: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch: 10/20 Train steps: 3125 Val steps: 313 14m47.40s loss: 0.580543 acc: 82.972000 top5: 96.999000 fscore_macro: 0.829529 val_loss: 1.577109 val_acc: 65.430000 val_top5: 86.970000 val_fscore_macro: 0.653896\n",
      "Epoch 10: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 10: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch: 11/20 Train steps: 3125 Val steps: 313 14m47.27s loss: 0.519149 acc: 84.761000 top5: 97.585000 fscore_macro: 0.847451 val_loss: 1.567798 val_acc: 65.460000 val_top5: 86.540000 val_fscore_macro: 0.652946\n",
      "Epoch 11: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 11: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch: 12/20 Train steps: 3125 Val steps: 313 14m47.32s loss: 0.473338 acc: 85.800000 top5: 97.913000 fscore_macro: 0.857864 val_loss: 1.663388 val_acc: 65.310000 val_top5: 86.310000 val_fscore_macro: 0.654528\n",
      "Epoch 12: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 12: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch: 13/20 Train steps: 3125 Val steps: 313 14m46.78s loss: 0.426824 acc: 87.074000 top5: 98.307000 fscore_macro: 0.870678 val_loss: 1.664466 val_acc: 65.570000 val_top5: 87.160000 val_fscore_macro: 0.655790\n",
      "Epoch 13: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 13: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch: 14/20 Train steps: 3125 Val steps: 313 14m47.20s loss: 0.398554 acc: 87.759000 top5: 98.603000 fscore_macro: 0.877510 val_loss: 1.793365 val_acc: 65.220000 val_top5: 85.690000 val_fscore_macro: 0.653197\n",
      "Epoch 14: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 14: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch: 15/20 Train steps: 3125 Val steps: 313 14m47.20s loss: 0.369780 acc: 88.776000 top5: 98.691000 fscore_macro: 0.887689 val_loss: 1.762353 val_acc: 65.030000 val_top5: 86.160000 val_fscore_macro: 0.650064\n",
      "Epoch 15: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 15: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch: 16/20 Train steps: 3125 Val steps: 313 14m47.22s loss: 0.345937 acc: 89.428000 top5: 98.854000 fscore_macro: 0.894249 val_loss: 1.769448 val_acc: 65.810000 val_top5: 86.100000 val_fscore_macro: 0.657365\n",
      "Epoch 16: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 16: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch: 17/20 Train steps: 3125 Val steps: 313 14m47.35s loss: 0.325887 acc: 90.001000 top5: 99.001000 fscore_macro: 0.899953 val_loss: 1.872287 val_acc: 64.260000 val_top5: 85.620000 val_fscore_macro: 0.643521\n",
      "Epoch 17: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 17: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n",
      "Epoch: 18/20 Train steps: 3125 Val steps: 313 14m47.85s loss: 0.303994 acc: 90.715000 top5: 99.083000 fscore_macro: 0.907100 val_loss: 1.834110 val_acc: 66.220000 val_top5: 86.170000 val_fscore_macro: 0.660586\n",
      "Epoch 18: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_last.ckpt\n",
      "Epoch 18: saving file to models/ViT/fine_tuning_v2/Without_transformation/checkpoint_opt.ckpt\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "# Directorio principal donde se guardarán los resultados\n",
    "main_dir = 'models/ViT/fine_tuning_v2'\n",
    "\n",
    "# Crear directorio principal si no existe\n",
    "Path(main_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "class TinyImageNet(TinyImageNet):\n",
    "    def __getitem__(self, index):\n",
    "        x, y = super().__getitem__(index)\n",
    "        return x,y\n",
    "#transformaciones = ['Without_transformation']\n",
    "# Iterar sobre cada transformación\n",
    "for i, transformacion in enumerate(transformaciones):\n",
    "    print(f\"Training with transformation: {transformacion}\")\n",
    "\n",
    "    # Crear directorio para la transformación actual\n",
    "    transform_dir = os.path.join(main_dir, transformacion)\n",
    "    Path(transform_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Definir el path del checkpoint\n",
    "    checkpoint_path = os.path.join(transform_dir, 'checkpoint_last.ckpt')\n",
    "    checkpoint_opt_path = os.path.join(transform_dir, 'checkpoint_opt.ckpt') \n",
    "\n",
    "    print(f'checkpoint path: {checkpoint_path}')\n",
    "    print(f'checkpoint optimizer path: {checkpoint_opt_path}')\n",
    "\n",
    "    # Cargar o reiniciar el modelo y el checkpoint para cada transformación\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location='cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    # Carga el estado del optimizador desde el archivo\n",
    "    if os.path.exists(checkpoint_opt_path):\n",
    "        optimizer.load_state_dict(torch.load(checkpoint_opt_path, map_location='cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    # Definir el conjunto de datos con la transformación actual\n",
    "    current_transform = transformation_afin[i]\n",
    "    #print(current_transform)\n",
    "\n",
    "    random_ts = lambda x: random.choice(current_transform)(x)\n",
    "    \n",
    "    normalize_transform = T.Compose(\n",
    "        [\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.transforms.Normalize(TinyImageNet.mean,TinyImageNet.std),\n",
    "        #random_ts\n",
    "        ])\n",
    "\n",
    "    # Definir el conjunto de datos original\n",
    "    dataset_train = TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"), split=\"train\", imagenet_idx=False, transform=normalize_transform)\n",
    "    dataset_val = TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"), split=\"val\", imagenet_idx=False, transform=normalize_transform)\n",
    "\n",
    "    #print(dataset_train[0])\n",
    "    # Definir un DataLoader para cargar los datos originales por lotes\n",
    "    train_loader = data.DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "    val_loader = data.DataLoader(dataset_val, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "    print('DataLoader listo')\n",
    "\n",
    "\n",
    "    # Definir el trainer\n",
    "    trainer = poutyne.Model(\n",
    "        model,\n",
    "        optimizer,\n",
    "        'cross_entropy',\n",
    "        batch_metrics=['accuracy', poutyne.TopKAccuracy(5)],\n",
    "        epoch_metrics=['f1'],\n",
    "        device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    )\n",
    "\n",
    "    # Definir el historial y el checkpoint para cada transformación\n",
    "    history_path = os.path.join(transform_dir, 'history.csv')\n",
    "    checkpoint_path = os.path.join(transform_dir, 'checkpoint_last.ckpt')\n",
    "    best_checkpoint_path = os.path.join(transform_dir, 'tmp_best.ckpt')\n",
    "    checkpoint_opt_path = os.path.join(transform_dir, 'checkpoint_opt.ckpt')   \n",
    "\n",
    "    checkpoint = poutyne.ModelCheckpoint(checkpoint_path, monitor='val_acc', mode='max', save_best_only=False, restore_best=False, verbose=True, temporary_filename=best_checkpoint_path)\n",
    "    opt_checkpoint = poutyne.OptimizerCheckpoint(checkpoint_opt_path, monitor='val_acc', mode='max', save_best_only=False, restore_best=False, verbose=True,        temporary_filename=best_checkpoint_path)\n",
    "\n",
    "    class HistorySaver(poutyne.Callback):\n",
    "\n",
    "      def __init__(self,filepath):\n",
    "        super().__init__()\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "\n",
    "      def on_epoch_end(self, epoch, logs):\n",
    "        self.history.append(logs)\n",
    "\n",
    "        if os.path.exists(history_path):\n",
    "          df1 = pd.read_csv(history_path)\n",
    "          df = pd.DataFrame(self.history)\n",
    "          df = pd.concat([df1,df])\n",
    "          df.reset_index(drop=True,inplace=True)\n",
    "          df.drop_duplicates(inplace = True, ignore_index = True)\n",
    "          df.to_csv(self.filepath,index=False)\n",
    "        else:\n",
    "          df = pd.DataFrame(self.history)\n",
    "          df.to_csv(self.filepath,index=False)\n",
    "\n",
    "    # callback personalizado\n",
    "    history_saver = HistorySaver(history_path)\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "        df1 = pd.read_csv(history_path)\n",
    "        history_saver.history = df1.to_dict('records')\n",
    "\n",
    "    # Entrenar el modelo para cada transformación\n",
    "    #history = trainer.fit_dataset(train_loader, valid_dataset=val_loader, batch_size=8, epochs=num_epochs, callbacks=[checkpoint, opt_checkpoint,history_saver])\n",
    "\n",
    "    history = trainer.fit_generator(train_loader, val_loader, epochs=num_epochs, callbacks=[checkpoint, opt_checkpoint, history_saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
