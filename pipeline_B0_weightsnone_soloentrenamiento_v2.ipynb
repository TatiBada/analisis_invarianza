{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "##import libraries\n",
    "from tinyimagenet import TinyImageNet\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import torch.utils.data as data\n",
    "from torchvision.models._api import WeightsEnum\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import poutyne\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "import sys\n",
    "import random\n",
    "\n",
    "#/Users/tatibada/Documents/Tesis Maestria DM/scripts/EfficientNet/pipeline_B0_weightsnone_soloentrenamiento_v2.py\n",
    "#sys.path.append('/content/drive/MyDrive/Tesis de Ms Data Mining TBadaracco/Notebooks/')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import transformations\n"
     ]
    }
   ],
   "source": [
    "# load transformations\n",
    "import transformaciones as tr\n",
    "\n",
    "rotation_transforms = tr.rotation_transforms()\n",
    "translation_transforms = tr.translation_transforms()\n",
    "scale_transforms = tr.scale_transforms()\n",
    "perspective_transforms = tr.perspective_transforms()\n",
    "brightness_transforms = [tr.brightness_transforms(factor) for factor in tr.brightness_parameters]\n",
    "contrast_transformations = [tr.contrast_transforms(alpha) for alpha in tr.contrast_list]\n",
    "grayscale_transformations = [tr.grayscale_transforms(alpha) for alpha in tr.grey_list]\n",
    "solarize_transformations = [tr.solarize_transforms(threshold) for threshold in tr.solarization_thresholds]\n",
    "posterize_transformations = [tr.posterize_transforms(alpha) for alpha in tr.posterize_list]\n",
    "invertion_transformations = [tr.invertion_transforms(alpha) for alpha in tr.invertion_list]\n",
    "\n",
    "\n",
    "transformation_afin = [rotation_transforms,\n",
    "                       translation_transforms,\n",
    "                       scale_transforms,\n",
    "                       perspective_transforms,\n",
    "                       brightness_transforms,\n",
    "                       contrast_transformations,\n",
    "                       grayscale_transformations,\n",
    "                       solarize_transformations,\n",
    "                       posterize_transformations,\n",
    "                       invertion_transformations]\n",
    "\n",
    "\n",
    "transformaciones = ['rotacion','traslacion','escala','proyeccion','brillo','contraste','escala_grises','solarizacion','posterizacion','inversion_colores']\n",
    "\n",
    "print('import transformations')\n",
    "\n",
    "#### para salucionar error: RuntimeError: invalid hash value (expected \"7eb33cd5\", got \"23ab8bcd5bdbef61a7a43b91adcad81f622fd7f36fb4935a569828d77888c44e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with transformation: rotacion\n",
      "checkpoint path: models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "checkpoint optimizer path: models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "DataLoader listo\n",
      "\u001b[35mEpoch: \u001b[36m  1/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m4.36s \u001b[35mloss:\u001b[94m 2.678585\u001b[35m acc:\u001b[94m 36.192000\u001b[35m top5:\u001b[94m 64.086000\u001b[35m fscore_macro:\u001b[94m 0.351532\u001b[35m val_loss:\u001b[94m 2.905109\u001b[35m val_acc:\u001b[94m 33.860000\u001b[35m val_top5:\u001b[94m 60.860000\u001b[35m val_fscore_macro:\u001b[94m 0.320713\u001b[0m\n",
      "Epoch 1: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 1: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m  2/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.02s \u001b[35mloss:\u001b[94m 2.653659\u001b[35m acc:\u001b[94m 36.547000\u001b[35m top5:\u001b[94m 64.705000\u001b[35m fscore_macro:\u001b[94m 0.354965\u001b[35m val_loss:\u001b[94m 2.886454\u001b[35m val_acc:\u001b[94m 33.980000\u001b[35m val_top5:\u001b[94m 61.330000\u001b[35m val_fscore_macro:\u001b[94m 0.325108\u001b[0m\n",
      "Epoch 2: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 2: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m  3/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.21s \u001b[35mloss:\u001b[94m 2.634118\u001b[35m acc:\u001b[94m 36.983000\u001b[35m top5:\u001b[94m 64.982000\u001b[35m fscore_macro:\u001b[94m 0.359873\u001b[35m val_loss:\u001b[94m 2.864153\u001b[35m val_acc:\u001b[94m 35.000000\u001b[35m val_top5:\u001b[94m 61.840000\u001b[35m val_fscore_macro:\u001b[94m 0.334220\u001b[0m\n",
      "Epoch 3: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 3: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m  4/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m4.67s \u001b[35mloss:\u001b[94m 2.602271\u001b[35m acc:\u001b[94m 37.512000\u001b[35m top5:\u001b[94m 65.745000\u001b[35m fscore_macro:\u001b[94m 0.365336\u001b[35m val_loss:\u001b[94m 2.875479\u001b[35m val_acc:\u001b[94m 34.100000\u001b[35m val_top5:\u001b[94m 61.560000\u001b[35m val_fscore_macro:\u001b[94m 0.325747\u001b[0m\n",
      "Epoch 4: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 4: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m  5/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m4.93s \u001b[35mloss:\u001b[94m 2.581444\u001b[35m acc:\u001b[94m 37.757000\u001b[35m top5:\u001b[94m 66.080000\u001b[35m fscore_macro:\u001b[94m 0.367715\u001b[35m val_loss:\u001b[94m 2.848256\u001b[35m val_acc:\u001b[94m 34.270000\u001b[35m val_top5:\u001b[94m 61.840000\u001b[35m val_fscore_macro:\u001b[94m 0.327377\u001b[0m\n",
      "Epoch 5: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 5: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m  6/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.26s \u001b[35mloss:\u001b[94m 2.559501\u001b[35m acc:\u001b[94m 38.177000\u001b[35m top5:\u001b[94m 66.620000\u001b[35m fscore_macro:\u001b[94m 0.372201\u001b[35m val_loss:\u001b[94m 2.875063\u001b[35m val_acc:\u001b[94m 34.520000\u001b[35m val_top5:\u001b[94m 61.770000\u001b[35m val_fscore_macro:\u001b[94m 0.329204\u001b[0m\n",
      "Epoch 6: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 6: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m  7/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.03s \u001b[35mloss:\u001b[94m 2.530791\u001b[35m acc:\u001b[94m 38.921000\u001b[35m top5:\u001b[94m 67.129000\u001b[35m fscore_macro:\u001b[94m 0.379948\u001b[35m val_loss:\u001b[94m 2.842754\u001b[35m val_acc:\u001b[94m 35.410000\u001b[35m val_top5:\u001b[94m 61.880000\u001b[35m val_fscore_macro:\u001b[94m 0.338169\u001b[0m\n",
      "Epoch 7: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 7: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m  8/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.22s \u001b[35mloss:\u001b[94m 2.508349\u001b[35m acc:\u001b[94m 39.360000\u001b[35m top5:\u001b[94m 67.693000\u001b[35m fscore_macro:\u001b[94m 0.384312\u001b[35m val_loss:\u001b[94m 2.843026\u001b[35m val_acc:\u001b[94m 35.540000\u001b[35m val_top5:\u001b[94m 62.000000\u001b[35m val_fscore_macro:\u001b[94m 0.340947\u001b[0m\n",
      "Epoch 8: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 8: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m  9/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.53s \u001b[35mloss:\u001b[94m 2.489626\u001b[35m acc:\u001b[94m 39.567000\u001b[35m top5:\u001b[94m 67.816000\u001b[35m fscore_macro:\u001b[94m 0.386794\u001b[35m val_loss:\u001b[94m 2.839626\u001b[35m val_acc:\u001b[94m 35.350000\u001b[35m val_top5:\u001b[94m 62.140000\u001b[35m val_fscore_macro:\u001b[94m 0.337196\u001b[0m\n",
      "Epoch 9: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 9: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 10/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.46s \u001b[35mloss:\u001b[94m 2.468642\u001b[35m acc:\u001b[94m 39.820000\u001b[35m top5:\u001b[94m 68.212000\u001b[35m fscore_macro:\u001b[94m 0.389370\u001b[35m val_loss:\u001b[94m 2.848657\u001b[35m val_acc:\u001b[94m 34.570000\u001b[35m val_top5:\u001b[94m 62.120000\u001b[35m val_fscore_macro:\u001b[94m 0.334133\u001b[0m\n",
      "Epoch 10: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 10: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 11/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m4.88s \u001b[35mloss:\u001b[94m 2.450055\u001b[35m acc:\u001b[94m 40.293000\u001b[35m top5:\u001b[94m 68.547000\u001b[35m fscore_macro:\u001b[94m 0.394387\u001b[35m val_loss:\u001b[94m 2.857184\u001b[35m val_acc:\u001b[94m 35.000000\u001b[35m val_top5:\u001b[94m 62.560000\u001b[35m val_fscore_macro:\u001b[94m 0.338212\u001b[0m\n",
      "Epoch 11: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 11: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 12/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.40s \u001b[35mloss:\u001b[94m 2.425321\u001b[35m acc:\u001b[94m 40.675000\u001b[35m top5:\u001b[94m 69.096000\u001b[35m fscore_macro:\u001b[94m 0.398358\u001b[35m val_loss:\u001b[94m 2.838620\u001b[35m val_acc:\u001b[94m 35.650000\u001b[35m val_top5:\u001b[94m 62.010000\u001b[35m val_fscore_macro:\u001b[94m 0.340730\u001b[0m\n",
      "Epoch 12: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 12: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 13/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.39s \u001b[35mloss:\u001b[94m 2.400950\u001b[35m acc:\u001b[94m 41.207000\u001b[35m top5:\u001b[94m 69.654000\u001b[35m fscore_macro:\u001b[94m 0.403758\u001b[35m val_loss:\u001b[94m 2.832573\u001b[35m val_acc:\u001b[94m 35.830000\u001b[35m val_top5:\u001b[94m 62.850000\u001b[35m val_fscore_macro:\u001b[94m 0.343569\u001b[0m\n",
      "Epoch 13: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 13: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 14/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.20s \u001b[35mloss:\u001b[94m 2.380426\u001b[35m acc:\u001b[94m 41.561000\u001b[35m top5:\u001b[94m 70.114000\u001b[35m fscore_macro:\u001b[94m 0.407499\u001b[35m val_loss:\u001b[94m 2.830717\u001b[35m val_acc:\u001b[94m 35.970000\u001b[35m val_top5:\u001b[94m 62.910000\u001b[35m val_fscore_macro:\u001b[94m 0.345809\u001b[0m\n",
      "Epoch 14: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 14: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 15/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.54s \u001b[35mloss:\u001b[94m 2.357474\u001b[35m acc:\u001b[94m 42.064000\u001b[35m top5:\u001b[94m 70.397000\u001b[35m fscore_macro:\u001b[94m 0.412643\u001b[35m val_loss:\u001b[94m 2.862520\u001b[35m val_acc:\u001b[94m 35.510000\u001b[35m val_top5:\u001b[94m 62.260000\u001b[35m val_fscore_macro:\u001b[94m 0.339832\u001b[0m\n",
      "Epoch 15: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 15: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 16/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.77s \u001b[35mloss:\u001b[94m 2.337526\u001b[35m acc:\u001b[94m 42.520000\u001b[35m top5:\u001b[94m 70.921000\u001b[35m fscore_macro:\u001b[94m 0.417237\u001b[35m val_loss:\u001b[94m 2.841727\u001b[35m val_acc:\u001b[94m 35.840000\u001b[35m val_top5:\u001b[94m 62.920000\u001b[35m val_fscore_macro:\u001b[94m 0.347333\u001b[0m\n",
      "Epoch 16: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 16: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 17/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.16s \u001b[35mloss:\u001b[94m 2.314739\u001b[35m acc:\u001b[94m 42.948000\u001b[35m top5:\u001b[94m 71.273000\u001b[35m fscore_macro:\u001b[94m 0.421576\u001b[35m val_loss:\u001b[94m 2.836326\u001b[35m val_acc:\u001b[94m 36.300000\u001b[35m val_top5:\u001b[94m 62.780000\u001b[35m val_fscore_macro:\u001b[94m 0.349983\u001b[0m\n",
      "Epoch 17: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 17: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 18/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.16s \u001b[35mloss:\u001b[94m 2.297946\u001b[35m acc:\u001b[94m 43.265000\u001b[35m top5:\u001b[94m 71.428000\u001b[35m fscore_macro:\u001b[94m 0.425225\u001b[35m val_loss:\u001b[94m 2.836379\u001b[35m val_acc:\u001b[94m 36.030000\u001b[35m val_top5:\u001b[94m 62.930000\u001b[35m val_fscore_macro:\u001b[94m 0.348996\u001b[0m\n",
      "Epoch 18: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 18: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 19/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.57s \u001b[35mloss:\u001b[94m 2.281374\u001b[35m acc:\u001b[94m 43.218000\u001b[35m top5:\u001b[94m 72.060000\u001b[35m fscore_macro:\u001b[94m 0.424942\u001b[35m val_loss:\u001b[94m 2.878006\u001b[35m val_acc:\u001b[94m 36.010000\u001b[35m val_top5:\u001b[94m 62.730000\u001b[35m val_fscore_macro:\u001b[94m 0.347554\u001b[0m\n",
      "Epoch 19: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 19: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 20/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.43s \u001b[35mloss:\u001b[94m 2.261331\u001b[35m acc:\u001b[94m 43.740000\u001b[35m top5:\u001b[94m 72.306000\u001b[35m fscore_macro:\u001b[94m 0.430211\u001b[35m val_loss:\u001b[94m 2.847685\u001b[35m val_acc:\u001b[94m 36.330000\u001b[35m val_top5:\u001b[94m 62.640000\u001b[35m val_fscore_macro:\u001b[94m 0.347337\u001b[0m\n",
      "Epoch 20: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 20: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 21/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.01s \u001b[35mloss:\u001b[94m 2.236489\u001b[35m acc:\u001b[94m 44.299000\u001b[35m top5:\u001b[94m 72.807000\u001b[35m fscore_macro:\u001b[94m 0.435954\u001b[35m val_loss:\u001b[94m 2.869563\u001b[35m val_acc:\u001b[94m 36.190000\u001b[35m val_top5:\u001b[94m 62.580000\u001b[35m val_fscore_macro:\u001b[94m 0.346966\u001b[0m\n",
      "Epoch 21: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 21: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 22/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.47s \u001b[35mloss:\u001b[94m 2.219968\u001b[35m acc:\u001b[94m 44.669000\u001b[35m top5:\u001b[94m 73.189000\u001b[35m fscore_macro:\u001b[94m 0.439919\u001b[35m val_loss:\u001b[94m 2.832155\u001b[35m val_acc:\u001b[94m 36.580000\u001b[35m val_top5:\u001b[94m 63.490000\u001b[35m val_fscore_macro:\u001b[94m 0.355888\u001b[0m\n",
      "Epoch 22: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 22: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 23/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.43s \u001b[35mloss:\u001b[94m 2.197176\u001b[35m acc:\u001b[94m 45.295000\u001b[35m top5:\u001b[94m 73.444000\u001b[35m fscore_macro:\u001b[94m 0.446171\u001b[35m val_loss:\u001b[94m 2.884171\u001b[35m val_acc:\u001b[94m 36.180000\u001b[35m val_top5:\u001b[94m 62.390000\u001b[35m val_fscore_macro:\u001b[94m 0.345712\u001b[0m\n",
      "Epoch 23: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 23: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 24/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.77s \u001b[35mloss:\u001b[94m 2.179105\u001b[35m acc:\u001b[94m 45.603000\u001b[35m top5:\u001b[94m 73.981000\u001b[35m fscore_macro:\u001b[94m 0.449429\u001b[35m val_loss:\u001b[94m 2.840493\u001b[35m val_acc:\u001b[94m 36.370000\u001b[35m val_top5:\u001b[94m 63.520000\u001b[35m val_fscore_macro:\u001b[94m 0.352875\u001b[0m\n",
      "Epoch 24: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 24: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 25/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.60s \u001b[35mloss:\u001b[94m 2.157794\u001b[35m acc:\u001b[94m 45.943000\u001b[35m top5:\u001b[94m 74.242000\u001b[35m fscore_macro:\u001b[94m 0.453221\u001b[35m val_loss:\u001b[94m 2.871452\u001b[35m val_acc:\u001b[94m 36.770000\u001b[35m val_top5:\u001b[94m 63.170000\u001b[35m val_fscore_macro:\u001b[94m 0.356256\u001b[0m\n",
      "Epoch 25: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 25: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 26/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.30s \u001b[35mloss:\u001b[94m 2.144584\u001b[35m acc:\u001b[94m 46.365000\u001b[35m top5:\u001b[94m 74.517000\u001b[35m fscore_macro:\u001b[94m 0.457366\u001b[35m val_loss:\u001b[94m 2.835524\u001b[35m val_acc:\u001b[94m 35.980000\u001b[35m val_top5:\u001b[94m 63.210000\u001b[35m val_fscore_macro:\u001b[94m 0.349713\u001b[0m\n",
      "Epoch 26: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 26: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 27/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.44s \u001b[35mloss:\u001b[94m 2.126101\u001b[35m acc:\u001b[94m 46.510000\u001b[35m top5:\u001b[94m 74.912000\u001b[35m fscore_macro:\u001b[94m 0.458905\u001b[35m val_loss:\u001b[94m 2.843808\u001b[35m val_acc:\u001b[94m 36.770000\u001b[35m val_top5:\u001b[94m 63.110000\u001b[35m val_fscore_macro:\u001b[94m 0.356110\u001b[0m\n",
      "Epoch 27: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 27: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 28/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.65s \u001b[35mloss:\u001b[94m 2.099776\u001b[35m acc:\u001b[94m 47.110000\u001b[35m top5:\u001b[94m 75.442000\u001b[35m fscore_macro:\u001b[94m 0.465101\u001b[35m val_loss:\u001b[94m 2.864257\u001b[35m val_acc:\u001b[94m 36.880000\u001b[35m val_top5:\u001b[94m 63.240000\u001b[35m val_fscore_macro:\u001b[94m 0.358366\u001b[0m\n",
      "Epoch 28: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 28: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 29/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.61s \u001b[35mloss:\u001b[94m 2.085491\u001b[35m acc:\u001b[94m 47.277000\u001b[35m top5:\u001b[94m 75.584000\u001b[35m fscore_macro:\u001b[94m 0.467029\u001b[35m val_loss:\u001b[94m 2.870657\u001b[35m val_acc:\u001b[94m 36.480000\u001b[35m val_top5:\u001b[94m 63.160000\u001b[35m val_fscore_macro:\u001b[94m 0.352359\u001b[0m\n",
      "Epoch 29: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 29: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 30/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.57s \u001b[35mloss:\u001b[94m 2.066435\u001b[35m acc:\u001b[94m 47.780000\u001b[35m top5:\u001b[94m 76.051000\u001b[35m fscore_macro:\u001b[94m 0.472022\u001b[35m val_loss:\u001b[94m 2.879696\u001b[35m val_acc:\u001b[94m 36.590000\u001b[35m val_top5:\u001b[94m 63.500000\u001b[35m val_fscore_macro:\u001b[94m 0.356118\u001b[0m\n",
      "Epoch 30: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 30: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 31/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.44s \u001b[35mloss:\u001b[94m 2.043207\u001b[35m acc:\u001b[94m 48.139000\u001b[35m top5:\u001b[94m 76.323000\u001b[35m fscore_macro:\u001b[94m 0.475777\u001b[35m val_loss:\u001b[94m 2.857821\u001b[35m val_acc:\u001b[94m 36.840000\u001b[35m val_top5:\u001b[94m 63.170000\u001b[35m val_fscore_macro:\u001b[94m 0.355600\u001b[0m\n",
      "Epoch 31: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 31: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 32/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.68s \u001b[35mloss:\u001b[94m 2.025304\u001b[35m acc:\u001b[94m 48.511000\u001b[35m top5:\u001b[94m 76.786000\u001b[35m fscore_macro:\u001b[94m 0.479692\u001b[35m val_loss:\u001b[94m 2.883163\u001b[35m val_acc:\u001b[94m 36.640000\u001b[35m val_top5:\u001b[94m 63.310000\u001b[35m val_fscore_macro:\u001b[94m 0.355681\u001b[0m\n",
      "Epoch 32: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 32: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 33/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.64s \u001b[35mloss:\u001b[94m 2.007551\u001b[35m acc:\u001b[94m 48.887000\u001b[35m top5:\u001b[94m 76.987000\u001b[35m fscore_macro:\u001b[94m 0.483259\u001b[35m val_loss:\u001b[94m 2.948738\u001b[35m val_acc:\u001b[94m 36.350000\u001b[35m val_top5:\u001b[94m 62.580000\u001b[35m val_fscore_macro:\u001b[94m 0.351564\u001b[0m\n",
      "Epoch 33: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 33: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 34/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.71s \u001b[35mloss:\u001b[94m 1.994074\u001b[35m acc:\u001b[94m 48.936000\u001b[35m top5:\u001b[94m 77.384000\u001b[35m fscore_macro:\u001b[94m 0.484097\u001b[35m val_loss:\u001b[94m 2.850005\u001b[35m val_acc:\u001b[94m 37.230000\u001b[35m val_top5:\u001b[94m 63.820000\u001b[35m val_fscore_macro:\u001b[94m 0.361970\u001b[0m\n",
      "Epoch 34: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 34: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 35/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.84s \u001b[35mloss:\u001b[94m 1.972570\u001b[35m acc:\u001b[94m 49.572000\u001b[35m top5:\u001b[94m 77.660000\u001b[35m fscore_macro:\u001b[94m 0.490528\u001b[35m val_loss:\u001b[94m 2.913469\u001b[35m val_acc:\u001b[94m 36.620000\u001b[35m val_top5:\u001b[94m 62.900000\u001b[35m val_fscore_macro:\u001b[94m 0.352782\u001b[0m\n",
      "Epoch 35: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 35: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 36/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.56s \u001b[35mloss:\u001b[94m 1.952328\u001b[35m acc:\u001b[94m 50.096000\u001b[35m top5:\u001b[94m 78.069000\u001b[35m fscore_macro:\u001b[94m 0.495885\u001b[35m val_loss:\u001b[94m 2.876482\u001b[35m val_acc:\u001b[94m 36.840000\u001b[35m val_top5:\u001b[94m 63.700000\u001b[35m val_fscore_macro:\u001b[94m 0.356526\u001b[0m\n",
      "Epoch 36: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 36: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 37/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.02s \u001b[35mloss:\u001b[94m 1.935679\u001b[35m acc:\u001b[94m 50.291000\u001b[35m top5:\u001b[94m 78.465000\u001b[35m fscore_macro:\u001b[94m 0.497847\u001b[35m val_loss:\u001b[94m 2.911728\u001b[35m val_acc:\u001b[94m 36.470000\u001b[35m val_top5:\u001b[94m 63.620000\u001b[35m val_fscore_macro:\u001b[94m 0.354460\u001b[0m\n",
      "Epoch 37: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 37: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 38/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.41s \u001b[35mloss:\u001b[94m 1.919287\u001b[35m acc:\u001b[94m 50.632000\u001b[35m top5:\u001b[94m 78.780000\u001b[35m fscore_macro:\u001b[94m 0.501586\u001b[35m val_loss:\u001b[94m 2.932527\u001b[35m val_acc:\u001b[94m 36.570000\u001b[35m val_top5:\u001b[94m 63.090000\u001b[35m val_fscore_macro:\u001b[94m 0.353989\u001b[0m\n",
      "Epoch 38: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 38: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 39/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.37s \u001b[35mloss:\u001b[94m 1.900048\u001b[35m acc:\u001b[94m 51.181000\u001b[35m top5:\u001b[94m 79.079000\u001b[35m fscore_macro:\u001b[94m 0.506997\u001b[35m val_loss:\u001b[94m 2.940111\u001b[35m val_acc:\u001b[94m 36.580000\u001b[35m val_top5:\u001b[94m 63.370000\u001b[35m val_fscore_macro:\u001b[94m 0.354656\u001b[0m\n",
      "Epoch 39: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 39: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 40/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.43s \u001b[35mloss:\u001b[94m 1.878680\u001b[35m acc:\u001b[94m 51.573000\u001b[35m top5:\u001b[94m 79.385000\u001b[35m fscore_macro:\u001b[94m 0.511143\u001b[35m val_loss:\u001b[94m 2.935494\u001b[35m val_acc:\u001b[94m 37.290000\u001b[35m val_top5:\u001b[94m 63.660000\u001b[35m val_fscore_macro:\u001b[94m 0.363943\u001b[0m\n",
      "Epoch 40: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 40: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 41/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.58s \u001b[35mloss:\u001b[94m 1.870234\u001b[35m acc:\u001b[94m 51.695000\u001b[35m top5:\u001b[94m 79.657000\u001b[35m fscore_macro:\u001b[94m 0.512591\u001b[35m val_loss:\u001b[94m 2.962402\u001b[35m val_acc:\u001b[94m 36.980000\u001b[35m val_top5:\u001b[94m 63.090000\u001b[35m val_fscore_macro:\u001b[94m 0.358384\u001b[0m\n",
      "Epoch 41: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 41: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 42/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.79s \u001b[35mloss:\u001b[94m 1.844613\u001b[35m acc:\u001b[94m 51.983000\u001b[35m top5:\u001b[94m 80.083000\u001b[35m fscore_macro:\u001b[94m 0.515486\u001b[35m val_loss:\u001b[94m 2.960119\u001b[35m val_acc:\u001b[94m 36.800000\u001b[35m val_top5:\u001b[94m 62.690000\u001b[35m val_fscore_macro:\u001b[94m 0.358201\u001b[0m\n",
      "Epoch 42: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 42: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 43/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.50s \u001b[35mloss:\u001b[94m 1.832614\u001b[35m acc:\u001b[94m 52.332000\u001b[35m top5:\u001b[94m 80.372000\u001b[35m fscore_macro:\u001b[94m 0.519056\u001b[35m val_loss:\u001b[94m 2.935021\u001b[35m val_acc:\u001b[94m 37.200000\u001b[35m val_top5:\u001b[94m 62.920000\u001b[35m val_fscore_macro:\u001b[94m 0.362836\u001b[0m\n",
      "Epoch 43: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 43: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 44/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.90s \u001b[35mloss:\u001b[94m 1.814686\u001b[35m acc:\u001b[94m 52.685000\u001b[35m top5:\u001b[94m 80.671000\u001b[35m fscore_macro:\u001b[94m 0.522674\u001b[35m val_loss:\u001b[94m 2.979624\u001b[35m val_acc:\u001b[94m 37.010000\u001b[35m val_top5:\u001b[94m 62.990000\u001b[35m val_fscore_macro:\u001b[94m 0.361943\u001b[0m\n",
      "Epoch 44: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 44: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 45/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.93s \u001b[35mloss:\u001b[94m 1.797457\u001b[35m acc:\u001b[94m 53.118000\u001b[35m top5:\u001b[94m 80.917000\u001b[35m fscore_macro:\u001b[94m 0.527049\u001b[35m val_loss:\u001b[94m 2.984259\u001b[35m val_acc:\u001b[94m 36.750000\u001b[35m val_top5:\u001b[94m 63.110000\u001b[35m val_fscore_macro:\u001b[94m 0.357851\u001b[0m\n",
      "Epoch 45: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 45: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 46/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.90s \u001b[35mloss:\u001b[94m 1.774436\u001b[35m acc:\u001b[94m 53.630000\u001b[35m top5:\u001b[94m 81.239000\u001b[35m fscore_macro:\u001b[94m 0.532340\u001b[35m val_loss:\u001b[94m 2.995882\u001b[35m val_acc:\u001b[94m 36.420000\u001b[35m val_top5:\u001b[94m 62.950000\u001b[35m val_fscore_macro:\u001b[94m 0.353243\u001b[0m\n",
      "Epoch 46: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 46: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 47/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.78s \u001b[35mloss:\u001b[94m 1.761565\u001b[35m acc:\u001b[94m 54.013000\u001b[35m top5:\u001b[94m 81.667000\u001b[35m fscore_macro:\u001b[94m 0.536229\u001b[35m val_loss:\u001b[94m 2.993448\u001b[35m val_acc:\u001b[94m 36.610000\u001b[35m val_top5:\u001b[94m 63.240000\u001b[35m val_fscore_macro:\u001b[94m 0.358434\u001b[0m\n",
      "Epoch 47: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 47: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 48/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.33s \u001b[35mloss:\u001b[94m 1.750740\u001b[35m acc:\u001b[94m 54.033000\u001b[35m top5:\u001b[94m 81.736000\u001b[35m fscore_macro:\u001b[94m 0.536645\u001b[35m val_loss:\u001b[94m 2.958838\u001b[35m val_acc:\u001b[94m 37.340000\u001b[35m val_top5:\u001b[94m 63.550000\u001b[35m val_fscore_macro:\u001b[94m 0.363483\u001b[0m\n",
      "Epoch 48: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 48: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 49/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.22s \u001b[35mloss:\u001b[94m 1.729371\u001b[35m acc:\u001b[94m 54.570000\u001b[35m top5:\u001b[94m 81.960000\u001b[35m fscore_macro:\u001b[94m 0.542133\u001b[35m val_loss:\u001b[94m 3.003378\u001b[35m val_acc:\u001b[94m 36.720000\u001b[35m val_top5:\u001b[94m 63.080000\u001b[35m val_fscore_macro:\u001b[94m 0.355961\u001b[0m\n",
      "Epoch 49: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 49: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 50/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.48s \u001b[35mloss:\u001b[94m 1.715691\u001b[35m acc:\u001b[94m 54.830000\u001b[35m top5:\u001b[94m 82.306000\u001b[35m fscore_macro:\u001b[94m 0.544668\u001b[35m val_loss:\u001b[94m 3.027463\u001b[35m val_acc:\u001b[94m 36.870000\u001b[35m val_top5:\u001b[94m 62.800000\u001b[35m val_fscore_macro:\u001b[94m 0.358758\u001b[0m\n",
      "Epoch 50: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 50: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 51/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.59s \u001b[35mloss:\u001b[94m 1.698921\u001b[35m acc:\u001b[94m 55.224000\u001b[35m top5:\u001b[94m 82.553000\u001b[35m fscore_macro:\u001b[94m 0.548614\u001b[35m val_loss:\u001b[94m 3.042883\u001b[35m val_acc:\u001b[94m 36.700000\u001b[35m val_top5:\u001b[94m 62.200000\u001b[35m val_fscore_macro:\u001b[94m 0.356670\u001b[0m\n",
      "Epoch 51: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 51: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 52/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.20s \u001b[35mloss:\u001b[94m 1.672716\u001b[35m acc:\u001b[94m 55.859000\u001b[35m top5:\u001b[94m 82.995000\u001b[35m fscore_macro:\u001b[94m 0.555195\u001b[35m val_loss:\u001b[94m 2.991122\u001b[35m val_acc:\u001b[94m 37.440000\u001b[35m val_top5:\u001b[94m 63.000000\u001b[35m val_fscore_macro:\u001b[94m 0.364431\u001b[0m\n",
      "Epoch 52: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 52: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 53/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.36s \u001b[35mloss:\u001b[94m 1.665595\u001b[35m acc:\u001b[94m 55.860000\u001b[35m top5:\u001b[94m 83.127000\u001b[35m fscore_macro:\u001b[94m 0.555184\u001b[35m val_loss:\u001b[94m 3.012816\u001b[35m val_acc:\u001b[94m 37.060000\u001b[35m val_top5:\u001b[94m 63.040000\u001b[35m val_fscore_macro:\u001b[94m 0.362078\u001b[0m\n",
      "Epoch 53: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 53: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 54/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.98s \u001b[35mloss:\u001b[94m 1.642053\u001b[35m acc:\u001b[94m 56.418000\u001b[35m top5:\u001b[94m 83.590000\u001b[35m fscore_macro:\u001b[94m 0.561077\u001b[35m val_loss:\u001b[94m 3.073672\u001b[35m val_acc:\u001b[94m 37.330000\u001b[35m val_top5:\u001b[94m 62.710000\u001b[35m val_fscore_macro:\u001b[94m 0.363272\u001b[0m\n",
      "Epoch 54: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 54: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 55/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.05s \u001b[35mloss:\u001b[94m 1.629120\u001b[35m acc:\u001b[94m 56.710000\u001b[35m top5:\u001b[94m 83.843000\u001b[35m fscore_macro:\u001b[94m 0.563919\u001b[35m val_loss:\u001b[94m 3.073547\u001b[35m val_acc:\u001b[94m 37.060000\u001b[35m val_top5:\u001b[94m 62.510000\u001b[35m val_fscore_macro:\u001b[94m 0.361519\u001b[0m\n",
      "Epoch 55: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 55: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 56/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.15s \u001b[35mloss:\u001b[94m 1.620059\u001b[35m acc:\u001b[94m 56.922000\u001b[35m top5:\u001b[94m 84.060000\u001b[35m fscore_macro:\u001b[94m 0.566155\u001b[35m val_loss:\u001b[94m 3.060897\u001b[35m val_acc:\u001b[94m 37.050000\u001b[35m val_top5:\u001b[94m 63.150000\u001b[35m val_fscore_macro:\u001b[94m 0.362239\u001b[0m\n",
      "Epoch 56: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 56: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 57/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.98s \u001b[35mloss:\u001b[94m 1.604969\u001b[35m acc:\u001b[94m 57.178000\u001b[35m top5:\u001b[94m 84.399000\u001b[35m fscore_macro:\u001b[94m 0.568847\u001b[35m val_loss:\u001b[94m 3.018500\u001b[35m val_acc:\u001b[94m 37.350000\u001b[35m val_top5:\u001b[94m 63.170000\u001b[35m val_fscore_macro:\u001b[94m 0.365040\u001b[0m\n",
      "Epoch 57: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 57: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 58/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.44s \u001b[35mloss:\u001b[94m 1.585940\u001b[35m acc:\u001b[94m 57.598000\u001b[35m top5:\u001b[94m 84.400000\u001b[35m fscore_macro:\u001b[94m 0.572962\u001b[35m val_loss:\u001b[94m 3.043024\u001b[35m val_acc:\u001b[94m 36.630000\u001b[35m val_top5:\u001b[94m 63.540000\u001b[35m val_fscore_macro:\u001b[94m 0.357166\u001b[0m\n",
      "Epoch 58: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 58: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 59/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.86s \u001b[35mloss:\u001b[94m 1.573815\u001b[35m acc:\u001b[94m 57.889000\u001b[35m top5:\u001b[94m 84.761000\u001b[35m fscore_macro:\u001b[94m 0.576069\u001b[35m val_loss:\u001b[94m 3.077101\u001b[35m val_acc:\u001b[94m 37.110000\u001b[35m val_top5:\u001b[94m 62.920000\u001b[35m val_fscore_macro:\u001b[94m 0.361475\u001b[0m\n",
      "Epoch 59: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 59: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 60/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m5.71s \u001b[35mloss:\u001b[94m 1.551630\u001b[35m acc:\u001b[94m 58.492000\u001b[35m top5:\u001b[94m 85.048000\u001b[35m fscore_macro:\u001b[94m 0.582197\u001b[35m val_loss:\u001b[94m 3.086771\u001b[35m val_acc:\u001b[94m 36.940000\u001b[35m val_top5:\u001b[94m 62.940000\u001b[35m val_fscore_macro:\u001b[94m 0.362594\u001b[0m\n",
      "Epoch 60: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 60: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 61/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.14s \u001b[35mloss:\u001b[94m 1.549694\u001b[35m acc:\u001b[94m 58.549000\u001b[35m top5:\u001b[94m 85.085000\u001b[35m fscore_macro:\u001b[94m 0.583005\u001b[35m val_loss:\u001b[94m 3.075991\u001b[35m val_acc:\u001b[94m 37.210000\u001b[35m val_top5:\u001b[94m 62.860000\u001b[35m val_fscore_macro:\u001b[94m 0.364150\u001b[0m\n",
      "Epoch 61: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 61: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 62/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.53s \u001b[35mloss:\u001b[94m 1.522868\u001b[35m acc:\u001b[94m 59.095000\u001b[35m top5:\u001b[94m 85.585000\u001b[35m fscore_macro:\u001b[94m 0.588214\u001b[35m val_loss:\u001b[94m 3.074757\u001b[35m val_acc:\u001b[94m 37.270000\u001b[35m val_top5:\u001b[94m 62.940000\u001b[35m val_fscore_macro:\u001b[94m 0.364581\u001b[0m\n",
      "Epoch 62: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 62: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 63/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.02s \u001b[35mloss:\u001b[94m 1.513431\u001b[35m acc:\u001b[94m 59.129000\u001b[35m top5:\u001b[94m 85.726000\u001b[35m fscore_macro:\u001b[94m 0.588841\u001b[35m val_loss:\u001b[94m 3.092842\u001b[35m val_acc:\u001b[94m 37.150000\u001b[35m val_top5:\u001b[94m 63.100000\u001b[35m val_fscore_macro:\u001b[94m 0.363462\u001b[0m\n",
      "Epoch 63: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 63: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 64/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.47s \u001b[35mloss:\u001b[94m 1.505627\u001b[35m acc:\u001b[94m 59.335000\u001b[35m top5:\u001b[94m 85.909000\u001b[35m fscore_macro:\u001b[94m 0.590881\u001b[35m val_loss:\u001b[94m 3.101461\u001b[35m val_acc:\u001b[94m 36.920000\u001b[35m val_top5:\u001b[94m 62.670000\u001b[35m val_fscore_macro:\u001b[94m 0.360329\u001b[0m\n",
      "Epoch 64: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 64: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 65/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.26s \u001b[35mloss:\u001b[94m 1.480345\u001b[35m acc:\u001b[94m 60.003000\u001b[35m top5:\u001b[94m 86.314000\u001b[35m fscore_macro:\u001b[94m 0.597692\u001b[35m val_loss:\u001b[94m 3.103041\u001b[35m val_acc:\u001b[94m 37.120000\u001b[35m val_top5:\u001b[94m 62.620000\u001b[35m val_fscore_macro:\u001b[94m 0.363713\u001b[0m\n",
      "Epoch 65: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 65: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 66/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.24s \u001b[35mloss:\u001b[94m 1.474140\u001b[35m acc:\u001b[94m 60.047000\u001b[35m top5:\u001b[94m 86.441000\u001b[35m fscore_macro:\u001b[94m 0.598216\u001b[35m val_loss:\u001b[94m 3.127181\u001b[35m val_acc:\u001b[94m 36.780000\u001b[35m val_top5:\u001b[94m 62.650000\u001b[35m val_fscore_macro:\u001b[94m 0.359710\u001b[0m\n",
      "Epoch 66: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 66: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 67/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.22s \u001b[35mloss:\u001b[94m 1.451298\u001b[35m acc:\u001b[94m 60.648000\u001b[35m top5:\u001b[94m 86.831000\u001b[35m fscore_macro:\u001b[94m 0.604243\u001b[35m val_loss:\u001b[94m 3.113187\u001b[35m val_acc:\u001b[94m 36.510000\u001b[35m val_top5:\u001b[94m 62.410000\u001b[35m val_fscore_macro:\u001b[94m 0.354766\u001b[0m\n",
      "Epoch 67: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 67: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 68/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m6.39s \u001b[35mloss:\u001b[94m 1.442600\u001b[35m acc:\u001b[94m 60.645000\u001b[35m top5:\u001b[94m 87.002000\u001b[35m fscore_macro:\u001b[94m 0.604113\u001b[35m val_loss:\u001b[94m 3.178910\u001b[35m val_acc:\u001b[94m 36.240000\u001b[35m val_top5:\u001b[94m 62.270000\u001b[35m val_fscore_macro:\u001b[94m 0.352850\u001b[0m\n",
      "Epoch 68: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 68: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 69/100 \u001b[35mTrain steps: \u001b[36m12500 \u001b[35mVal steps: \u001b[36m1250 \u001b[32m11m7.03s \u001b[35mloss:\u001b[94m 1.422443\u001b[35m acc:\u001b[94m 61.337000\u001b[35m top5:\u001b[94m 87.270000\u001b[35m fscore_macro:\u001b[94m 0.611329\u001b[35m val_loss:\u001b[94m 3.151209\u001b[35m val_acc:\u001b[94m 36.920000\u001b[35m val_top5:\u001b[94m 62.620000\u001b[35m val_fscore_macro:\u001b[94m 0.361761\u001b[0m\n",
      "Epoch 69: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_last.ckpt\n",
      "Epoch 69: saving file to models/efficientnet_b0/weights_none/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m 70/100 \u001b[35mStep: \u001b[36m10587/12500 \u001b[35m 84.70% |\u001b[35m████████████████▉   \u001b[35m|\u001b[35mETA: \u001b[32m1m39.35s \u001b[35mloss:\u001b[94m 2.743573\u001b[35m acc:\u001b[94m 25.000000\u001b[35m top5:\u001b[94m 50.000000   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tbadaracco/pipeline_B0_weightsnone_soloentrenamiento_v2.py\u001b[0m in \u001b[0;36mline 150\n\u001b[1;32m    <a href='file:///home/tbadaracco/pipeline_B0_weightsnone_soloentrenamiento_v2.py?line=205'>206</a>\u001b[0m     history_saver\u001b[39m.\u001b[39mhistory \u001b[39m=\u001b[39m df1\u001b[39m.\u001b[39mto_dict(\u001b[39m'\u001b[39m\u001b[39mrecords\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///home/tbadaracco/pipeline_B0_weightsnone_soloentrenamiento_v2.py?line=207'>208</a>\u001b[0m \u001b[39m# Entrenar el modelo para cada transformación\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/tbadaracco/pipeline_B0_weightsnone_soloentrenamiento_v2.py?line=208'>209</a>\u001b[0m \u001b[39m#history = trainer.fit_dataset(train_loader, valid_dataset=val_loader, batch_size=8, epochs=num_epochs, callbacks=[checkpoint, opt_checkpoint,history_saver])\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/tbadaracco/pipeline_B0_weightsnone_soloentrenamiento_v2.py?line=210'>211</a>\u001b[0m history \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mfit_generator(train_loader, val_loader, epochs\u001b[39m=\u001b[39;49mnum_epochs, callbacks\u001b[39m=\u001b[39;49m[checkpoint, opt_checkpoint, history_saver])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/poutyne/framework/model.py:610\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, train_generator, valid_generator, epochs, steps_per_epoch, validation_steps, batches_per_step, initial_epoch, verbose, progress_options, callbacks)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=607'>608</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_generator_n_batches_per_step(epoch_iterator, callback_list, batches_per_step)\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=608'>609</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=609'>610</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_generator_one_batch_per_step(epoch_iterator, callback_list)\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=611'>612</a>\u001b[0m \u001b[39mreturn\u001b[39;00m epoch_iterator\u001b[39m.\u001b[39mepoch_logs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/poutyne/framework/model.py:681\u001b[0m, in \u001b[0;36mModel._fit_generator_one_batch_per_step\u001b[0;34m(self, epoch_iterator, callback_list)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=678'>679</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_training_mode(\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=679'>680</a>\u001b[0m     \u001b[39mfor\u001b[39;00m step, (x, y) \u001b[39min\u001b[39;00m train_step_iterator:\n\u001b[0;32m--> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=680'>681</a>\u001b[0m         step\u001b[39m.\u001b[39mloss, step\u001b[39m.\u001b[39mbatch_metrics, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_batch(x, y, callback\u001b[39m=\u001b[39;49mcallback_list, step\u001b[39m=\u001b[39;49mstep\u001b[39m.\u001b[39;49mnumber)\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=681'>682</a>\u001b[0m         step\u001b[39m.\u001b[39msize \u001b[39m=\u001b[39m get_batch_size(x, y)\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=683'>684</a>\u001b[0m train_step_iterator\u001b[39m.\u001b[39mloss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_loss()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/poutyne/framework/model.py:693\u001b[0m, in \u001b[0;36mModel._fit_batch\u001b[0;34m(self, x, y, callback, step, return_pred, convert_to_numpy)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=689'>690</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit_batch\u001b[39m(\u001b[39mself\u001b[39m, x, y, \u001b[39m*\u001b[39m, callback\u001b[39m=\u001b[39mCallback(), step\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, return_pred\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, convert_to_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=690'>691</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=692'>693</a>\u001b[0m     loss_tensor, batch_metrics, pred_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_loss_and_metrics(\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=693'>694</a>\u001b[0m         x, y, return_loss_tensor\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, return_pred\u001b[39m=\u001b[39;49mreturn_pred, convert_to_numpy\u001b[39m=\u001b[39;49mconvert_to_numpy\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=694'>695</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=696'>697</a>\u001b[0m     loss_tensor\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=697'>698</a>\u001b[0m     callback\u001b[39m.\u001b[39mon_backward_end(step)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/poutyne/framework/model.py:1477\u001b[0m, in \u001b[0;36mModel._compute_loss_and_metrics\u001b[0;34m(self, x, y, return_loss_tensor, return_pred, convert_to_numpy)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=1474'>1475</a>\u001b[0m     pred_y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mparallel\u001b[39m.\u001b[39mdata_parallel(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork, x, [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mother_device)\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=1475'>1476</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=1476'>1477</a>\u001b[0m     pred_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork(\u001b[39m*\u001b[39;49mx)\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=1477'>1478</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_function(pred_y, y)\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/poutyne/framework/model.py?line=1478'>1479</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_loss_tensor:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1530'>1531</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1531'>1532</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1535'>1536</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1536'>1537</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1537'>1538</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1538'>1539</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1539'>1540</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1540'>1541</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1542'>1543</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1543'>1544</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/models/efficientnet.py:343\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=341'>342</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=342'>343</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/models/efficientnet.py:333\u001b[0m, in \u001b[0;36mEfficientNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=331'>332</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=332'>333</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=334'>335</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=335'>336</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1530'>1531</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1531'>1532</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1535'>1536</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1536'>1537</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1537'>1538</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1538'>1539</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1539'>1540</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1540'>1541</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1542'>1543</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1543'>1544</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=214'>215</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=215'>216</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=216'>217</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=217'>218</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1530'>1531</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1531'>1532</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1535'>1536</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1536'>1537</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1537'>1538</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1538'>1539</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1539'>1540</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1540'>1541</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1542'>1543</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1543'>1544</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=214'>215</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=215'>216</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=216'>217</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=217'>218</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1530'>1531</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1531'>1532</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1535'>1536</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1536'>1537</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1537'>1538</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1538'>1539</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1539'>1540</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1540'>1541</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1542'>1543</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1543'>1544</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/models/efficientnet.py:164\u001b[0m, in \u001b[0;36mMBConv.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=162'>163</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=163'>164</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=164'>165</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_res_connect:\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torchvision/models/efficientnet.py?line=165'>166</a>\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstochastic_depth(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1530'>1531</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1531'>1532</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1535'>1536</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1536'>1537</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1537'>1538</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1538'>1539</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1539'>1540</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1540'>1541</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1542'>1543</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1543'>1544</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=214'>215</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=215'>216</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=216'>217</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=217'>218</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1530'>1531</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1531'>1532</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1535'>1536</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1536'>1537</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1537'>1538</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1538'>1539</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1539'>1540</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1540'>1541</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1542'>1543</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1543'>1544</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=214'>215</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=215'>216</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=216'>217</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/container.py?line=217'>218</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m             tracing_state\u001b[39m.\u001b[39mpop_scope()\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m-> <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1527'>1528</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrapped_call_impl\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/tbadaracco/.local/lib/python3.10/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_state_dict(self, *args, **kwargs):\n",
    "    kwargs.pop(\"check_hash\")\n",
    "    return load_state_dict_from_url(self.url, *args, **kwargs)\n",
    "\n",
    "WeightsEnum.get_state_dict = get_state_dict\n",
    "#####\n",
    "\n",
    "# Definir el modelo y checkpoint\n",
    "weights = None #models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "base_model = models.efficientnet_b0(weights=weights)\n",
    "\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "tinyimagenet_classes = 200\n",
    "base_model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True),\n",
    "    torch.nn.Linear(1280, tinyimagenet_classes),\n",
    ")\n",
    "\n",
    "#model = torch.nn.Sequential(\n",
    "   #T.Normalize(TinyImageNet.mean,TinyImageNet.std),\n",
    "    #weights.transforms(),\n",
    " #   base_model,\n",
    "#)\n",
    "\n",
    "\n",
    "model = base_model.to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# Directorio principal donde se guardarán los resultados\n",
    "main_dir = 'models/efficientnet_b0/weights_none'\n",
    "\n",
    "# Crear directorio principal si no existe\n",
    "Path(main_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "class TinyImageNet(TinyImageNet):\n",
    "    def __getitem__(self, index):\n",
    "        x, y = super().__getitem__(index)\n",
    "        return x,y\n",
    "\n",
    "# Iterar sobre cada transformación\n",
    "for i, transformacion in enumerate(transformaciones):\n",
    "    print(f\"Training with transformation: {transformacion}\")\n",
    "\n",
    "    # Crear directorio para la transformación actual\n",
    "    transform_dir = os.path.join(main_dir, transformacion)\n",
    "    Path(transform_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Definir el path del checkpoint\n",
    "    checkpoint_path = os.path.join(transform_dir, 'checkpoint_last.ckpt')\n",
    "    checkpoint_opt_path = os.path.join(transform_dir, 'checkpoint_opt.ckpt') \n",
    "\n",
    "    print(f'checkpoint path: {checkpoint_path}')\n",
    "    print(f'checkpoint optimizer path: {checkpoint_opt_path}')\n",
    "\n",
    "    # Cargar o reiniciar el modelo y el checkpoint para cada transformación\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location='cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    # Carga el estado del optimizador desde el archivo\n",
    "    if os.path.exists(checkpoint_opt_path):\n",
    "        optimizer.load_state_dict(torch.load(checkpoint_opt_path, map_location='cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    # Definir el conjunto de datos con la transformación actual\n",
    "    current_transform = transformation_afin[i]\n",
    "    #print(current_transform)\n",
    "\n",
    "    random_ts = lambda x: random.choice(current_transform)(x)\n",
    "    \n",
    "    normalize_transform = T.Compose(\n",
    "        [\n",
    "        T.ToTensor(),\n",
    "        #torchvision.transforms.Normalize(TinyImageNet.mean,TinyImageNet.std),\n",
    "        random_ts\n",
    "        ])\n",
    "\n",
    "    # Definir el conjunto de datos original\n",
    "    dataset_train = TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"), split=\"train\", imagenet_idx=False, transform=normalize_transform)\n",
    "    dataset_val = TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"), split=\"val\", imagenet_idx=False, transform=normalize_transform)\n",
    "\n",
    "    #print(dataset_train[0])\n",
    "    # Definir un DataLoader para cargar los datos originales por lotes\n",
    "    train_loader = data.DataLoader(dataset_train, batch_size=8, shuffle=True)\n",
    "    val_loader = data.DataLoader(dataset_val, batch_size=8, shuffle=True)\n",
    "\n",
    "    #for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    #    print(inputs.shape)  # Imprime la forma de los datos de entrada\n",
    "    #    print(targets.shape)  # Imprime la forma de las etiquetas\n",
    "    #    break  # Solo imprime el primer lote para evitar demasiada salida\n",
    "\n",
    "    print('DataLoader listo')\n",
    "\n",
    "\n",
    "    # Definir el trainer\n",
    "    trainer = poutyne.Model(\n",
    "        model,\n",
    "        optimizer,\n",
    "        'cross_entropy',\n",
    "        batch_metrics=['accuracy', poutyne.TopKAccuracy(5)],\n",
    "        epoch_metrics=['f1'],\n",
    "        device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    )\n",
    "\n",
    "    # Definir el historial y el checkpoint para cada transformación\n",
    "    history_path = os.path.join(transform_dir, 'history.csv')\n",
    "    checkpoint_path = os.path.join(transform_dir, 'checkpoint_last.ckpt')\n",
    "    best_checkpoint_path = os.path.join(transform_dir, 'tmp_best.ckpt')\n",
    "    checkpoint_opt_path = os.path.join(transform_dir, 'checkpoint_opt.ckpt')   \n",
    "\n",
    "    checkpoint = poutyne.ModelCheckpoint(checkpoint_path, monitor='val_acc', mode='max', save_best_only=False, restore_best=False, verbose=True, temporary_filename=best_checkpoint_path)\n",
    "    opt_checkpoint = poutyne.OptimizerCheckpoint(checkpoint_opt_path, monitor='val_acc', mode='max', save_best_only=False, restore_best=False, verbose=True,        temporary_filename=best_checkpoint_path)\n",
    "\n",
    "    class HistorySaver(poutyne.Callback):\n",
    "\n",
    "      def __init__(self,filepath):\n",
    "        super().__init__()\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "\n",
    "      def on_epoch_end(self, epoch, logs):\n",
    "        self.history.append(logs)\n",
    "\n",
    "        if os.path.exists(history_path):\n",
    "          df1 = pd.read_csv(history_path)\n",
    "          df = pd.DataFrame(self.history)\n",
    "          df = pd.concat([df1,df])\n",
    "          df.reset_index(drop=True,inplace=True)\n",
    "          df.drop_duplicates(inplace = True, ignore_index = True)\n",
    "          df.to_csv(self.filepath,index=False)\n",
    "        else:\n",
    "          df = pd.DataFrame(self.history)\n",
    "          df.to_csv(self.filepath,index=False)\n",
    "\n",
    "    # callback personalizado\n",
    "    history_saver = HistorySaver(history_path)\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "        df1 = pd.read_csv(history_path)\n",
    "        history_saver.history = df1.to_dict('records')\n",
    "\n",
    "    # Entrenar el modelo para cada transformación\n",
    "    #history = trainer.fit_dataset(train_loader, valid_dataset=val_loader, batch_size=8, epochs=num_epochs, callbacks=[checkpoint, opt_checkpoint,history_saver])\n",
    "\n",
    "    history = trainer.fit_generator(train_loader, val_loader, epochs=num_epochs, callbacks=[checkpoint, opt_checkpoint, history_saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=200, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with transformation: traslacion\n",
      "checkpoint path: models/efficientnet_b0/weights_none/traslacion/checkpoint_last.ckpt\n",
      "checkpoint optimizer path: models/efficientnet_b0/weights_none/traslacion/checkpoint_opt.ckpt\n",
      "DataLoader listo\n",
      "\u001b[35mEpoch: \u001b[36m  1/100 \u001b[35mStep: \u001b[36m  501/12500 \u001b[35m  4.01% |\u001b[35m▊                   \u001b[35m|\u001b[35mETA: \u001b[32m9m32.50s \u001b[35mloss:\u001b[94m 4.979143\u001b[35m acc:\u001b[94m 0.000000\u001b[35m top5:\u001b[94m 0.000000  "
     ]
    }
   ],
   "source": [
    "def get_state_dict(self, *args, **kwargs):\n",
    "    kwargs.pop(\"check_hash\")\n",
    "    return load_state_dict_from_url(self.url, *args, **kwargs)\n",
    "\n",
    "WeightsEnum.get_state_dict = get_state_dict\n",
    "#####\n",
    "\n",
    "# Definir el modelo y checkpoint\n",
    "weights = None #models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "base_model = models.efficientnet_b0(weights=weights)\n",
    "\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "tinyimagenet_classes = 200\n",
    "base_model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True),\n",
    "    torch.nn.Linear(1280, tinyimagenet_classes),\n",
    ")\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "   T.Normalize(TinyImageNet.mean,TinyImageNet.std),\n",
    "    #weights.transforms(),\n",
    "    base_model,\n",
    ")\n",
    "\n",
    "\n",
    "model = base_model.to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "# Directorio principal donde se guardarán los resultados\n",
    "main_dir = 'models/efficientnet_b0/weights_none'\n",
    "\n",
    "# Crear directorio principal si no existe\n",
    "Path(main_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "class TinyImageNet(TinyImageNet):\n",
    "    def __getitem__(self, index):\n",
    "        x, y = super().__getitem__(index)\n",
    "        return x,y\n",
    "\n",
    "# Iterar sobre cada transformación\n",
    "for i, transformacion in enumerate(transformaciones[1:]):\n",
    "    print(f\"Training with transformation: {transformacion}\")\n",
    "\n",
    "    # Crear directorio para la transformación actual\n",
    "    transform_dir = os.path.join(main_dir, transformacion)\n",
    "    Path(transform_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Definir el path del checkpoint\n",
    "    checkpoint_path = os.path.join(transform_dir, 'checkpoint_last.ckpt')\n",
    "    checkpoint_opt_path = os.path.join(transform_dir, 'checkpoint_opt.ckpt') \n",
    "\n",
    "    print(f'checkpoint path: {checkpoint_path}')\n",
    "    print(f'checkpoint optimizer path: {checkpoint_opt_path}')\n",
    "\n",
    "    # Cargar o reiniciar el modelo y el checkpoint para cada transformación\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location='cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    # Carga el estado del optimizador desde el archivo\n",
    "    if os.path.exists(checkpoint_opt_path):\n",
    "        optimizer.load_state_dict(torch.load(checkpoint_opt_path, map_location='cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    # Definir el conjunto de datos con la transformación actual\n",
    "    current_transform = transformation_afin[i]\n",
    "    #print(current_transform)\n",
    "\n",
    "    random_ts = lambda x: random.choice(current_transform)(x)\n",
    "    \n",
    "    normalize_transform = T.Compose(\n",
    "        [\n",
    "        T.ToTensor(),\n",
    "        #torchvision.transforms.Normalize(TinyImageNet.mean,TinyImageNet.std),\n",
    "        random_ts\n",
    "        ])\n",
    "\n",
    "    # Definir el conjunto de datos original\n",
    "    dataset_train = TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"), split=\"train\", imagenet_idx=False, transform=normalize_transform)\n",
    "    dataset_val = TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"), split=\"val\", imagenet_idx=False, transform=normalize_transform)\n",
    "\n",
    "    #print(dataset_train[0])\n",
    "    # Definir un DataLoader para cargar los datos originales por lotes\n",
    "    train_loader = data.DataLoader(dataset_train, batch_size=8, shuffle=True)\n",
    "    val_loader = data.DataLoader(dataset_val, batch_size=8, shuffle=True)\n",
    "\n",
    "    #for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    #    print(inputs.shape)  # Imprime la forma de los datos de entrada\n",
    "    #    print(targets.shape)  # Imprime la forma de las etiquetas\n",
    "    #    break  # Solo imprime el primer lote para evitar demasiada salida\n",
    "\n",
    "    print('DataLoader listo')\n",
    "\n",
    "\n",
    "    # Definir el trainer\n",
    "    trainer = poutyne.Model(\n",
    "        model,\n",
    "        optimizer,\n",
    "        'cross_entropy',\n",
    "        batch_metrics=['accuracy', poutyne.TopKAccuracy(5)],\n",
    "        epoch_metrics=['f1'],\n",
    "        device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    )\n",
    "\n",
    "    # Definir el historial y el checkpoint para cada transformación\n",
    "    history_path = os.path.join(transform_dir, 'history.csv')\n",
    "    checkpoint_path = os.path.join(transform_dir, 'checkpoint_last.ckpt')\n",
    "    best_checkpoint_path = os.path.join(transform_dir, 'tmp_best.ckpt')\n",
    "    checkpoint_opt_path = os.path.join(transform_dir, 'checkpoint_opt.ckpt')   \n",
    "\n",
    "    checkpoint = poutyne.ModelCheckpoint(checkpoint_path, monitor='val_acc', mode='max', save_best_only=False, restore_best=False, verbose=True, temporary_filename=best_checkpoint_path)\n",
    "    opt_checkpoint = poutyne.OptimizerCheckpoint(checkpoint_opt_path, monitor='val_acc', mode='max', save_best_only=False, restore_best=False, verbose=True,        temporary_filename=best_checkpoint_path)\n",
    "\n",
    "    class HistorySaver(poutyne.Callback):\n",
    "\n",
    "      def __init__(self,filepath):\n",
    "        super().__init__()\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "\n",
    "      def on_epoch_end(self, epoch, logs):\n",
    "        self.history.append(logs)\n",
    "\n",
    "        if os.path.exists(history_path):\n",
    "          df1 = pd.read_csv(history_path)\n",
    "          df = pd.DataFrame(self.history)\n",
    "          df = pd.concat([df1,df])\n",
    "          df.reset_index(drop=True,inplace=True)\n",
    "          df.drop_duplicates(inplace = True, ignore_index = True)\n",
    "          df.to_csv(self.filepath,index=False)\n",
    "        else:\n",
    "          df = pd.DataFrame(self.history)\n",
    "          df.to_csv(self.filepath,index=False)\n",
    "\n",
    "    # callback personalizado\n",
    "    history_saver = HistorySaver(history_path)\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "        df1 = pd.read_csv(history_path)\n",
    "        history_saver.history = df1.to_dict('records')\n",
    "\n",
    "    # Entrenar el modelo para cada transformación\n",
    "    #history = trainer.fit_dataset(train_loader, valid_dataset=val_loader, batch_size=8, epochs=num_epochs, callbacks=[checkpoint, opt_checkpoint,history_saver])\n",
    "\n",
    "    history = trainer.fit_generator(train_loader, val_loader, epochs=num_epochs, callbacks=[checkpoint, opt_checkpoint, history_saver])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
