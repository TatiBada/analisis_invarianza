{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "##import libraries\n",
    "from tinyimagenet import TinyImageNet\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import torch.utils.data as data\n",
    "from torchvision.models._api import WeightsEnum\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import poutyne\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "import sys\n",
    "import random\n",
    "\n",
    "#/Users/tatibada/Documents/Tesis Maestria DM/scripts/EfficientNet/pipeline_B0_weightsnone_soloentrenamiento_v2.py\n",
    "#sys.path.append('/content/drive/MyDrive/Tesis de Ms Data Mining TBadaracco/Notebooks/')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import transformations\n"
     ]
    }
   ],
   "source": [
    "# load transformations\n",
    "import transformaciones as tr\n",
    "\n",
    "rotation_transforms = tr.rotation_transforms()\n",
    "translation_transforms = tr.translation_transforms()\n",
    "scale_transforms = tr.scale_transforms()\n",
    "perspective_transforms = tr.perspective_transforms()\n",
    "brightness_transforms = [tr.brightness_transforms(factor) for factor in tr.brightness_parameters]\n",
    "contrast_transformations = [tr.contrast_transforms(alpha) for alpha in tr.contrast_list]\n",
    "grayscale_transformations = [tr.grayscale_transforms(alpha) for alpha in tr.grey_list]\n",
    "solarize_transformations = [tr.solarize_transforms(threshold) for threshold in tr.solarization_thresholds]\n",
    "posterize_transformations = [tr.posterize_transforms(alpha) for alpha in tr.posterize_list]\n",
    "invertion_transformations = [tr.invertion_transforms(alpha) for alpha in tr.invertion_list]\n",
    "\n",
    "\n",
    "transformation_afin = [rotation_transforms,\n",
    "                       translation_transforms,\n",
    "                       scale_transforms,\n",
    "                       perspective_transforms,\n",
    "                       brightness_transforms,\n",
    "                       contrast_transformations,\n",
    "                       grayscale_transformations,\n",
    "                       solarize_transformations,\n",
    "                       posterize_transformations,\n",
    "                       invertion_transformations]\n",
    "\n",
    "\n",
    "transformaciones = ['rotacion','traslacion','escala','proyeccion','brillo','contraste','escala_grises','solarizacion','posterizacion','inversion_colores']\n",
    "\n",
    "print('import transformations')\n",
    "\n",
    "#### para salucionar error: RuntimeError: invalid hash value (expected \"7eb33cd5\", got \"23ab8bcd5bdbef61a7a43b91adcad81f622fd7f36fb4935a569828d77888c44e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_dict(self, *args, **kwargs):\n",
    "    kwargs.pop(\"check_hash\")\n",
    "    return load_state_dict_from_url(self.url, *args, **kwargs)\n",
    "\n",
    "WeightsEnum.get_state_dict = get_state_dict\n",
    "#####\n",
    "\n",
    "# Definir el modelo y checkpoint\n",
    "weights = models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",
    "base_model = models.efficientnet_b0(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Descongelar los parámetros del último bloque de \"features\" (bloque 8)\n",
    "for param in base_model.features[6:9].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Descongelar los parámetros de la capa de clasificación\n",
    "for param in base_model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "tinyimagenet_classes = 200\n",
    "base_model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(p=0.2, inplace=True),\n",
    "    torch.nn.Linear(1280, tinyimagenet_classes),\n",
    ")\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "   #T.Normalize(TinyImageNet.mean,TinyImageNet.std),\n",
    "    weights.transforms(),\n",
    "    base_model,\n",
    ")\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ImageClassification(\n",
       "      crop_size=[224]\n",
       "      resize_size=[256]\n",
       "      mean=[0.485, 0.456, 0.406]\n",
       "      std=[0.229, 0.224, 0.225]\n",
       "      interpolation=InterpolationMode.BICUBIC\n",
       "  )\n",
       "  (1): EfficientNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (8): Conv2dNormActivation(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.2, inplace=True)\n",
       "      (1): Linear(in_features=1280, out_features=200, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with transformation: rotacion\n",
      "checkpoint path: models/efficientnet_b0/transfer_learning/rotacion/checkpoint_last.ckpt\n",
      "checkpoint optimizer path: models/efficientnet_b0/transfer_learning/rotacion/checkpoint_opt.ckpt\n",
      "DataLoader listo\n",
      "\u001b[35mEpoch: \u001b[36m1/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m24.21s \u001b[35mloss:\u001b[94m 1.229929\u001b[35m acc:\u001b[94m 66.787000\u001b[35m top5:\u001b[94m 89.062000\u001b[35m fscore_macro:\u001b[94m 0.666517\u001b[35m val_loss:\u001b[94m 2.064833\u001b[35m val_acc:\u001b[94m 54.590000\u001b[35m val_top5:\u001b[94m 78.300000\u001b[35m val_fscore_macro:\u001b[94m 0.543100\u001b[0m\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/rotacion/checkpoint_last.ckpt\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m2/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m23.85s \u001b[35mloss:\u001b[94m 1.180930\u001b[35m acc:\u001b[94m 67.781000\u001b[35m top5:\u001b[94m 89.783000\u001b[35m fscore_macro:\u001b[94m 0.676508\u001b[35m val_loss:\u001b[94m 2.089438\u001b[35m val_acc:\u001b[94m 54.240000\u001b[35m val_top5:\u001b[94m 78.780000\u001b[35m val_fscore_macro:\u001b[94m 0.539469\u001b[0m\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/rotacion/checkpoint_last.ckpt\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m3/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m24.44s \u001b[35mloss:\u001b[94m 1.147370\u001b[35m acc:\u001b[94m 68.771000\u001b[35m top5:\u001b[94m 90.164000\u001b[35m fscore_macro:\u001b[94m 0.686446\u001b[35m val_loss:\u001b[94m 2.098122\u001b[35m val_acc:\u001b[94m 54.100000\u001b[35m val_top5:\u001b[94m 78.020000\u001b[35m val_fscore_macro:\u001b[94m 0.538564\u001b[0m\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/rotacion/checkpoint_last.ckpt\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m4/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m25.27s \u001b[35mloss:\u001b[94m 1.111815\u001b[35m acc:\u001b[94m 69.456000\u001b[35m top5:\u001b[94m 90.695000\u001b[35m fscore_macro:\u001b[94m 0.693492\u001b[35m val_loss:\u001b[94m 2.122549\u001b[35m val_acc:\u001b[94m 53.960000\u001b[35m val_top5:\u001b[94m 78.150000\u001b[35m val_fscore_macro:\u001b[94m 0.538047\u001b[0m\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/rotacion/checkpoint_last.ckpt\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/rotacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m5/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m25.60s \u001b[35mloss:\u001b[94m 1.072946\u001b[35m acc:\u001b[94m 70.218000\u001b[35m top5:\u001b[94m 91.366000\u001b[35m fscore_macro:\u001b[94m 0.701183\u001b[35m val_loss:\u001b[94m 2.164954\u001b[35m val_acc:\u001b[94m 53.760000\u001b[35m val_top5:\u001b[94m 77.890000\u001b[35m val_fscore_macro:\u001b[94m 0.535824\u001b[0m\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/rotacion/checkpoint_last.ckpt\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/rotacion/checkpoint_opt.ckpt\n",
      "Training with transformation: traslacion\n",
      "checkpoint path: models/efficientnet_b0/transfer_learning/traslacion/checkpoint_last.ckpt\n",
      "checkpoint optimizer path: models/efficientnet_b0/transfer_learning/traslacion/checkpoint_opt.ckpt\n",
      "DataLoader listo\n",
      "\u001b[35mEpoch: \u001b[36m1/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m30.03s \u001b[35mloss:\u001b[94m 0.856985\u001b[35m acc:\u001b[94m 75.931000\u001b[35m top5:\u001b[94m 93.828000\u001b[35m fscore_macro:\u001b[94m 0.758868\u001b[35m val_loss:\u001b[94m 2.083958\u001b[35m val_acc:\u001b[94m 56.860000\u001b[35m val_top5:\u001b[94m 79.660000\u001b[35m val_fscore_macro:\u001b[94m 0.565889\u001b[0m\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/traslacion/checkpoint_last.ckpt\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/traslacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m2/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m26.17s \u001b[35mloss:\u001b[94m 0.829174\u001b[35m acc:\u001b[94m 76.615000\u001b[35m top5:\u001b[94m 94.084000\u001b[35m fscore_macro:\u001b[94m 0.765697\u001b[35m val_loss:\u001b[94m 2.080094\u001b[35m val_acc:\u001b[94m 56.780000\u001b[35m val_top5:\u001b[94m 79.890000\u001b[35m val_fscore_macro:\u001b[94m 0.566237\u001b[0m\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/traslacion/checkpoint_last.ckpt\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/traslacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m3/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m25.48s \u001b[35mloss:\u001b[94m 0.813750\u001b[35m acc:\u001b[94m 77.032000\u001b[35m top5:\u001b[94m 94.342000\u001b[35m fscore_macro:\u001b[94m 0.769975\u001b[35m val_loss:\u001b[94m 2.101099\u001b[35m val_acc:\u001b[94m 57.180000\u001b[35m val_top5:\u001b[94m 79.940000\u001b[35m val_fscore_macro:\u001b[94m 0.570262\u001b[0m\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/traslacion/checkpoint_last.ckpt\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/traslacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m4/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m30.01s \u001b[35mloss:\u001b[94m 0.791810\u001b[35m acc:\u001b[94m 77.620000\u001b[35m top5:\u001b[94m 94.506000\u001b[35m fscore_macro:\u001b[94m 0.775861\u001b[35m val_loss:\u001b[94m 2.104806\u001b[35m val_acc:\u001b[94m 57.200000\u001b[35m val_top5:\u001b[94m 80.510000\u001b[35m val_fscore_macro:\u001b[94m 0.571649\u001b[0m\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/traslacion/checkpoint_last.ckpt\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/traslacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m5/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m24.92s \u001b[35mloss:\u001b[94m 0.772711\u001b[35m acc:\u001b[94m 77.940000\u001b[35m top5:\u001b[94m 94.757000\u001b[35m fscore_macro:\u001b[94m 0.779097\u001b[35m val_loss:\u001b[94m 2.150176\u001b[35m val_acc:\u001b[94m 56.610000\u001b[35m val_top5:\u001b[94m 79.790000\u001b[35m val_fscore_macro:\u001b[94m 0.564536\u001b[0m\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/traslacion/checkpoint_last.ckpt\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/traslacion/checkpoint_opt.ckpt\n",
      "Training with transformation: escala\n",
      "checkpoint path: models/efficientnet_b0/transfer_learning/escala/checkpoint_last.ckpt\n",
      "checkpoint optimizer path: models/efficientnet_b0/transfer_learning/escala/checkpoint_opt.ckpt\n",
      "DataLoader listo\n",
      "\u001b[35mEpoch: \u001b[36m1/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m24.65s \u001b[35mloss:\u001b[94m 0.776729\u001b[35m acc:\u001b[94m 78.050000\u001b[35m top5:\u001b[94m 94.615000\u001b[35m fscore_macro:\u001b[94m 0.780159\u001b[35m val_loss:\u001b[94m 2.094767\u001b[35m val_acc:\u001b[94m 57.670000\u001b[35m val_top5:\u001b[94m 80.460000\u001b[35m val_fscore_macro:\u001b[94m 0.574587\u001b[0m\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/escala/checkpoint_last.ckpt\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/escala/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m2/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m24.75s \u001b[35mloss:\u001b[94m 0.770573\u001b[35m acc:\u001b[94m 78.199000\u001b[35m top5:\u001b[94m 94.721000\u001b[35m fscore_macro:\u001b[94m 0.781731\u001b[35m val_loss:\u001b[94m 2.109965\u001b[35m val_acc:\u001b[94m 57.130000\u001b[35m val_top5:\u001b[94m 80.380000\u001b[35m val_fscore_macro:\u001b[94m 0.570688\u001b[0m\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/escala/checkpoint_last.ckpt\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/escala/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m3/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m26.18s \u001b[35mloss:\u001b[94m 0.746898\u001b[35m acc:\u001b[94m 78.582000\u001b[35m top5:\u001b[94m 95.032000\u001b[35m fscore_macro:\u001b[94m 0.785521\u001b[35m val_loss:\u001b[94m 2.160795\u001b[35m val_acc:\u001b[94m 57.490000\u001b[35m val_top5:\u001b[94m 80.090000\u001b[35m val_fscore_macro:\u001b[94m 0.572246\u001b[0m\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/escala/checkpoint_last.ckpt\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/escala/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m4/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m26.46s \u001b[35mloss:\u001b[94m 0.741836\u001b[35m acc:\u001b[94m 78.908000\u001b[35m top5:\u001b[94m 95.064000\u001b[35m fscore_macro:\u001b[94m 0.788821\u001b[35m val_loss:\u001b[94m 2.153499\u001b[35m val_acc:\u001b[94m 57.340000\u001b[35m val_top5:\u001b[94m 80.300000\u001b[35m val_fscore_macro:\u001b[94m 0.571170\u001b[0m\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/escala/checkpoint_last.ckpt\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/escala/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m5/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m26.59s \u001b[35mloss:\u001b[94m 0.729145\u001b[35m acc:\u001b[94m 79.200000\u001b[35m top5:\u001b[94m 95.195000\u001b[35m fscore_macro:\u001b[94m 0.791760\u001b[35m val_loss:\u001b[94m 2.157704\u001b[35m val_acc:\u001b[94m 57.590000\u001b[35m val_top5:\u001b[94m 80.420000\u001b[35m val_fscore_macro:\u001b[94m 0.574384\u001b[0m\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/escala/checkpoint_last.ckpt\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/escala/checkpoint_opt.ckpt\n",
      "Training with transformation: proyeccion\n",
      "checkpoint path: models/efficientnet_b0/transfer_learning/proyeccion/checkpoint_last.ckpt\n",
      "checkpoint optimizer path: models/efficientnet_b0/transfer_learning/proyeccion/checkpoint_opt.ckpt\n",
      "DataLoader listo\n",
      "\u001b[35mEpoch: \u001b[36m1/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m12m0.10s \u001b[35mloss:\u001b[94m 1.032582\u001b[35m acc:\u001b[94m 72.507000\u001b[35m top5:\u001b[94m 90.292000\u001b[35m fscore_macro:\u001b[94m 0.724404\u001b[35m val_loss:\u001b[94m 2.381622\u001b[35m val_acc:\u001b[94m 51.410000\u001b[35m val_top5:\u001b[94m 75.280000\u001b[35m val_fscore_macro:\u001b[94m 0.513173\u001b[0m\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/proyeccion/checkpoint_last.ckpt\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/proyeccion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m2/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m59.91s \u001b[35mloss:\u001b[94m 1.016797\u001b[35m acc:\u001b[94m 72.829000\u001b[35m top5:\u001b[94m 90.503000\u001b[35m fscore_macro:\u001b[94m 0.727733\u001b[35m val_loss:\u001b[94m 2.447609\u001b[35m val_acc:\u001b[94m 51.570000\u001b[35m val_top5:\u001b[94m 75.250000\u001b[35m val_fscore_macro:\u001b[94m 0.512459\u001b[0m\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/proyeccion/checkpoint_last.ckpt\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/proyeccion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m3/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m59.94s \u001b[35mloss:\u001b[94m 1.012492\u001b[35m acc:\u001b[94m 72.911000\u001b[35m top5:\u001b[94m 90.614000\u001b[35m fscore_macro:\u001b[94m 0.728473\u001b[35m val_loss:\u001b[94m 2.392516\u001b[35m val_acc:\u001b[94m 51.330000\u001b[35m val_top5:\u001b[94m 75.590000\u001b[35m val_fscore_macro:\u001b[94m 0.510131\u001b[0m\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/proyeccion/checkpoint_last.ckpt\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/proyeccion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m4/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m59.96s \u001b[35mloss:\u001b[94m 0.980427\u001b[35m acc:\u001b[94m 73.680000\u001b[35m top5:\u001b[94m 91.015000\u001b[35m fscore_macro:\u001b[94m 0.736251\u001b[35m val_loss:\u001b[94m 2.464153\u001b[35m val_acc:\u001b[94m 51.520000\u001b[35m val_top5:\u001b[94m 74.990000\u001b[35m val_fscore_macro:\u001b[94m 0.510927\u001b[0m\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/proyeccion/checkpoint_last.ckpt\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/proyeccion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m5/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m59.83s \u001b[35mloss:\u001b[94m 0.970932\u001b[35m acc:\u001b[94m 73.960000\u001b[35m top5:\u001b[94m 91.005000\u001b[35m fscore_macro:\u001b[94m 0.739062\u001b[35m val_loss:\u001b[94m 2.454961\u001b[35m val_acc:\u001b[94m 52.370000\u001b[35m val_top5:\u001b[94m 75.500000\u001b[35m val_fscore_macro:\u001b[94m 0.519716\u001b[0m\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/proyeccion/checkpoint_last.ckpt\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/proyeccion/checkpoint_opt.ckpt\n",
      "Training with transformation: brillo\n",
      "checkpoint path: models/efficientnet_b0/transfer_learning/brillo/checkpoint_last.ckpt\n",
      "checkpoint optimizer path: models/efficientnet_b0/transfer_learning/brillo/checkpoint_opt.ckpt\n",
      "DataLoader listo\n",
      "\u001b[35mEpoch: \u001b[36m1/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m3.26s \u001b[35mloss:\u001b[94m 0.215391\u001b[35m acc:\u001b[94m 93.420000\u001b[35m top5:\u001b[94m 99.384000\u001b[35m fscore_macro:\u001b[94m 0.934189\u001b[35m val_loss:\u001b[94m 2.335537\u001b[35m val_acc:\u001b[94m 61.530000\u001b[35m val_top5:\u001b[94m 83.240000\u001b[35m val_fscore_macro:\u001b[94m 0.612928\u001b[0m\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/brillo/checkpoint_last.ckpt\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/brillo/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m2/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m3.70s \u001b[35mloss:\u001b[94m 0.206946\u001b[35m acc:\u001b[94m 93.644000\u001b[35m top5:\u001b[94m 99.474000\u001b[35m fscore_macro:\u001b[94m 0.936435\u001b[35m val_loss:\u001b[94m 2.304471\u001b[35m val_acc:\u001b[94m 61.280000\u001b[35m val_top5:\u001b[94m 82.710000\u001b[35m val_fscore_macro:\u001b[94m 0.610665\u001b[0m\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/brillo/checkpoint_last.ckpt\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/brillo/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m3/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m3.67s \u001b[35mloss:\u001b[94m 0.206504\u001b[35m acc:\u001b[94m 93.687000\u001b[35m top5:\u001b[94m 99.442000\u001b[35m fscore_macro:\u001b[94m 0.936863\u001b[35m val_loss:\u001b[94m 2.345717\u001b[35m val_acc:\u001b[94m 60.760000\u001b[35m val_top5:\u001b[94m 82.800000\u001b[35m val_fscore_macro:\u001b[94m 0.606075\u001b[0m\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/brillo/checkpoint_last.ckpt\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/brillo/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m4/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m3.69s \u001b[35mloss:\u001b[94m 0.196096\u001b[35m acc:\u001b[94m 94.010000\u001b[35m top5:\u001b[94m 99.470000\u001b[35m fscore_macro:\u001b[94m 0.940093\u001b[35m val_loss:\u001b[94m 2.373194\u001b[35m val_acc:\u001b[94m 61.380000\u001b[35m val_top5:\u001b[94m 82.530000\u001b[35m val_fscore_macro:\u001b[94m 0.612314\u001b[0m\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/brillo/checkpoint_last.ckpt\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/brillo/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m5/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m3.69s \u001b[35mloss:\u001b[94m 0.196316\u001b[35m acc:\u001b[94m 93.998000\u001b[35m top5:\u001b[94m 99.454000\u001b[35m fscore_macro:\u001b[94m 0.939962\u001b[35m val_loss:\u001b[94m 2.338025\u001b[35m val_acc:\u001b[94m 61.330000\u001b[35m val_top5:\u001b[94m 82.620000\u001b[35m val_fscore_macro:\u001b[94m 0.611758\u001b[0m\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/brillo/checkpoint_last.ckpt\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/brillo/checkpoint_opt.ckpt\n",
      "Training with transformation: contraste\n",
      "checkpoint path: models/efficientnet_b0/transfer_learning/contraste/checkpoint_last.ckpt\n",
      "checkpoint optimizer path: models/efficientnet_b0/transfer_learning/contraste/checkpoint_opt.ckpt\n",
      "DataLoader listo\n",
      "\u001b[35mEpoch: \u001b[36m1/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m16.43s \u001b[35mloss:\u001b[94m 0.310451\u001b[35m acc:\u001b[94m 90.736000\u001b[35m top5:\u001b[94m 98.727000\u001b[35m fscore_macro:\u001b[94m 0.907354\u001b[35m val_loss:\u001b[94m 2.344490\u001b[35m val_acc:\u001b[94m 59.340000\u001b[35m val_top5:\u001b[94m 81.270000\u001b[35m val_fscore_macro:\u001b[94m 0.591063\u001b[0m\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/contraste/checkpoint_last.ckpt\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/contraste/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m2/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m15.76s \u001b[35mloss:\u001b[94m 0.301860\u001b[35m acc:\u001b[94m 90.965000\u001b[35m top5:\u001b[94m 98.737000\u001b[35m fscore_macro:\u001b[94m 0.909633\u001b[35m val_loss:\u001b[94m 2.370443\u001b[35m val_acc:\u001b[94m 59.820000\u001b[35m val_top5:\u001b[94m 81.470000\u001b[35m val_fscore_macro:\u001b[94m 0.595695\u001b[0m\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/contraste/checkpoint_last.ckpt\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/contraste/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m3/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m15.79s \u001b[35mloss:\u001b[94m 0.296565\u001b[35m acc:\u001b[94m 91.088000\u001b[35m top5:\u001b[94m 98.843000\u001b[35m fscore_macro:\u001b[94m 0.910849\u001b[35m val_loss:\u001b[94m 2.386495\u001b[35m val_acc:\u001b[94m 59.390000\u001b[35m val_top5:\u001b[94m 81.500000\u001b[35m val_fscore_macro:\u001b[94m 0.592030\u001b[0m\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/contraste/checkpoint_last.ckpt\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/contraste/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m4/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m15.61s \u001b[35mloss:\u001b[94m 0.287254\u001b[35m acc:\u001b[94m 91.447000\u001b[35m top5:\u001b[94m 98.850000\u001b[35m fscore_macro:\u001b[94m 0.914481\u001b[35m val_loss:\u001b[94m 2.367372\u001b[35m val_acc:\u001b[94m 59.890000\u001b[35m val_top5:\u001b[94m 81.490000\u001b[35m val_fscore_macro:\u001b[94m 0.595996\u001b[0m\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/contraste/checkpoint_last.ckpt\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/contraste/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m5/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m15.53s \u001b[35mloss:\u001b[94m 0.280469\u001b[35m acc:\u001b[94m 91.514000\u001b[35m top5:\u001b[94m 98.943000\u001b[35m fscore_macro:\u001b[94m 0.915122\u001b[35m val_loss:\u001b[94m 2.413622\u001b[35m val_acc:\u001b[94m 59.750000\u001b[35m val_top5:\u001b[94m 81.030000\u001b[35m val_fscore_macro:\u001b[94m 0.596422\u001b[0m\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/contraste/checkpoint_last.ckpt\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/contraste/checkpoint_opt.ckpt\n",
      "Training with transformation: escala_grises\n",
      "checkpoint path: models/efficientnet_b0/transfer_learning/escala_grises/checkpoint_last.ckpt\n",
      "checkpoint optimizer path: models/efficientnet_b0/transfer_learning/escala_grises/checkpoint_opt.ckpt\n",
      "DataLoader listo\n",
      "\u001b[35mEpoch: \u001b[36m1/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m10.80s \u001b[35mloss:\u001b[94m 0.153911\u001b[35m acc:\u001b[94m 95.340000\u001b[35m top5:\u001b[94m 99.606000\u001b[35m fscore_macro:\u001b[94m 0.953388\u001b[35m val_loss:\u001b[94m 2.418035\u001b[35m val_acc:\u001b[94m 61.510000\u001b[35m val_top5:\u001b[94m 82.770000\u001b[35m val_fscore_macro:\u001b[94m 0.614078\u001b[0m\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/escala_grises/checkpoint_last.ckpt\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/escala_grises/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m2/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m11.02s \u001b[35mloss:\u001b[94m 0.150164\u001b[35m acc:\u001b[94m 95.430000\u001b[35m top5:\u001b[94m 99.631000\u001b[35m fscore_macro:\u001b[94m 0.954302\u001b[35m val_loss:\u001b[94m 2.433842\u001b[35m val_acc:\u001b[94m 61.850000\u001b[35m val_top5:\u001b[94m 82.860000\u001b[35m val_fscore_macro:\u001b[94m 0.617162\u001b[0m\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/escala_grises/checkpoint_last.ckpt\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/escala_grises/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m3/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m10.57s \u001b[35mloss:\u001b[94m 0.145919\u001b[35m acc:\u001b[94m 95.450000\u001b[35m top5:\u001b[94m 99.650000\u001b[35m fscore_macro:\u001b[94m 0.954494\u001b[35m val_loss:\u001b[94m 2.493185\u001b[35m val_acc:\u001b[94m 61.330000\u001b[35m val_top5:\u001b[94m 82.380000\u001b[35m val_fscore_macro:\u001b[94m 0.611347\u001b[0m\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/escala_grises/checkpoint_last.ckpt\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/escala_grises/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m4/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m10.94s \u001b[35mloss:\u001b[94m 0.145241\u001b[35m acc:\u001b[94m 95.526000\u001b[35m top5:\u001b[94m 99.645000\u001b[35m fscore_macro:\u001b[94m 0.955260\u001b[35m val_loss:\u001b[94m 2.432763\u001b[35m val_acc:\u001b[94m 61.490000\u001b[35m val_top5:\u001b[94m 82.830000\u001b[35m val_fscore_macro:\u001b[94m 0.612909\u001b[0m\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/escala_grises/checkpoint_last.ckpt\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/escala_grises/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m5/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m10.42s \u001b[35mloss:\u001b[94m 0.139291\u001b[35m acc:\u001b[94m 95.748000\u001b[35m top5:\u001b[94m 99.675000\u001b[35m fscore_macro:\u001b[94m 0.957478\u001b[35m val_loss:\u001b[94m 2.448369\u001b[35m val_acc:\u001b[94m 61.620000\u001b[35m val_top5:\u001b[94m 83.060000\u001b[35m val_fscore_macro:\u001b[94m 0.613937\u001b[0m\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/escala_grises/checkpoint_last.ckpt\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/escala_grises/checkpoint_opt.ckpt\n",
      "Training with transformation: solarizacion\n",
      "checkpoint path: models/efficientnet_b0/transfer_learning/solarizacion/checkpoint_last.ckpt\n",
      "checkpoint optimizer path: models/efficientnet_b0/transfer_learning/solarizacion/checkpoint_opt.ckpt\n",
      "DataLoader listo\n",
      "\u001b[35mEpoch: \u001b[36m1/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m6.79s \u001b[35mloss:\u001b[94m 3.275662\u001b[35m acc:\u001b[94m 27.796000\u001b[35m top5:\u001b[94m 51.002000\u001b[35m fscore_macro:\u001b[94m 0.271928\u001b[35m val_loss:\u001b[94m 3.605707\u001b[35m val_acc:\u001b[94m 23.930000\u001b[35m val_top5:\u001b[94m 44.990000\u001b[35m val_fscore_macro:\u001b[94m 0.236327\u001b[0m\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/solarizacion/checkpoint_last.ckpt\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/solarizacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m2/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m7.10s \u001b[35mloss:\u001b[94m 3.241412\u001b[35m acc:\u001b[94m 28.450000\u001b[35m top5:\u001b[94m 51.633000\u001b[35m fscore_macro:\u001b[94m 0.278683\u001b[35m val_loss:\u001b[94m 3.393545\u001b[35m val_acc:\u001b[94m 26.640000\u001b[35m val_top5:\u001b[94m 49.730000\u001b[35m val_fscore_macro:\u001b[94m 0.258866\u001b[0m\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/solarizacion/checkpoint_last.ckpt\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/solarizacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m3/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m7.14s \u001b[35mloss:\u001b[94m 3.211172\u001b[35m acc:\u001b[94m 28.965000\u001b[35m top5:\u001b[94m 52.439000\u001b[35m fscore_macro:\u001b[94m 0.283926\u001b[35m val_loss:\u001b[94m 3.451566\u001b[35m val_acc:\u001b[94m 25.930000\u001b[35m val_top5:\u001b[94m 48.450000\u001b[35m val_fscore_macro:\u001b[94m 0.254738\u001b[0m\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/solarizacion/checkpoint_last.ckpt\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/solarizacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m4/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m6.77s \u001b[35mloss:\u001b[94m 3.179984\u001b[35m acc:\u001b[94m 29.342000\u001b[35m top5:\u001b[94m 52.996000\u001b[35m fscore_macro:\u001b[94m 0.288011\u001b[35m val_loss:\u001b[94m 3.635659\u001b[35m val_acc:\u001b[94m 23.380000\u001b[35m val_top5:\u001b[94m 44.880000\u001b[35m val_fscore_macro:\u001b[94m 0.233372\u001b[0m\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/solarizacion/checkpoint_last.ckpt\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/solarizacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m5/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m6.73s \u001b[35mloss:\u001b[94m 3.148352\u001b[35m acc:\u001b[94m 29.890000\u001b[35m top5:\u001b[94m 53.647000\u001b[35m fscore_macro:\u001b[94m 0.293130\u001b[35m val_loss:\u001b[94m 3.393003\u001b[35m val_acc:\u001b[94m 26.740000\u001b[35m val_top5:\u001b[94m 50.300000\u001b[35m val_fscore_macro:\u001b[94m 0.260641\u001b[0m\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/solarizacion/checkpoint_last.ckpt\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/solarizacion/checkpoint_opt.ckpt\n",
      "Training with transformation: posterizacion\n",
      "checkpoint path: models/efficientnet_b0/transfer_learning/posterizacion/checkpoint_last.ckpt\n",
      "checkpoint optimizer path: models/efficientnet_b0/transfer_learning/posterizacion/checkpoint_opt.ckpt\n",
      "DataLoader listo\n",
      "\u001b[35mEpoch: \u001b[36m1/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m10.02s \u001b[35mloss:\u001b[94m 0.096828\u001b[35m acc:\u001b[94m 96.949000\u001b[35m top5:\u001b[94m 99.865000\u001b[35m fscore_macro:\u001b[94m 0.969489\u001b[35m val_loss:\u001b[94m 2.363093\u001b[35m val_acc:\u001b[94m 63.360000\u001b[35m val_top5:\u001b[94m 83.640000\u001b[35m val_fscore_macro:\u001b[94m 0.631560\u001b[0m\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/posterizacion/checkpoint_last.ckpt\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/posterizacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m2/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m10.19s \u001b[35mloss:\u001b[94m 0.091878\u001b[35m acc:\u001b[94m 97.119000\u001b[35m top5:\u001b[94m 99.860000\u001b[35m fscore_macro:\u001b[94m 0.971186\u001b[35m val_loss:\u001b[94m 2.366621\u001b[35m val_acc:\u001b[94m 63.150000\u001b[35m val_top5:\u001b[94m 83.950000\u001b[35m val_fscore_macro:\u001b[94m 0.630511\u001b[0m\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/posterizacion/checkpoint_last.ckpt\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/posterizacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m3/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m10.20s \u001b[35mloss:\u001b[94m 0.090026\u001b[35m acc:\u001b[94m 97.215000\u001b[35m top5:\u001b[94m 99.857000\u001b[35m fscore_macro:\u001b[94m 0.972145\u001b[35m val_loss:\u001b[94m 2.394194\u001b[35m val_acc:\u001b[94m 63.080000\u001b[35m val_top5:\u001b[94m 83.990000\u001b[35m val_fscore_macro:\u001b[94m 0.629507\u001b[0m\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/posterizacion/checkpoint_last.ckpt\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/posterizacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m4/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m10.25s \u001b[35mloss:\u001b[94m 0.088066\u001b[35m acc:\u001b[94m 97.219000\u001b[35m top5:\u001b[94m 99.872000\u001b[35m fscore_macro:\u001b[94m 0.972188\u001b[35m val_loss:\u001b[94m 2.404022\u001b[35m val_acc:\u001b[94m 63.160000\u001b[35m val_top5:\u001b[94m 83.860000\u001b[35m val_fscore_macro:\u001b[94m 0.629212\u001b[0m\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/posterizacion/checkpoint_last.ckpt\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/posterizacion/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m5/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m11m10.10s \u001b[35mloss:\u001b[94m 0.088221\u001b[35m acc:\u001b[94m 97.252000\u001b[35m top5:\u001b[94m 99.866000\u001b[35m fscore_macro:\u001b[94m 0.972521\u001b[35m val_loss:\u001b[94m 2.451483\u001b[35m val_acc:\u001b[94m 62.870000\u001b[35m val_top5:\u001b[94m 83.650000\u001b[35m val_fscore_macro:\u001b[94m 0.626617\u001b[0m\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/posterizacion/checkpoint_last.ckpt\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/posterizacion/checkpoint_opt.ckpt\n",
      "Training with transformation: inversion_colores\n",
      "checkpoint path: models/efficientnet_b0/transfer_learning/inversion_colores/checkpoint_last.ckpt\n",
      "checkpoint optimizer path: models/efficientnet_b0/transfer_learning/inversion_colores/checkpoint_opt.ckpt\n",
      "DataLoader listo\n",
      "\u001b[35mEpoch: \u001b[36m1/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m12m41.94s \u001b[35mloss:\u001b[94m 0.155273\u001b[35m acc:\u001b[94m 95.202000\u001b[35m top5:\u001b[94m 99.660000\u001b[35m fscore_macro:\u001b[94m 0.952012\u001b[35m val_loss:\u001b[94m 2.630312\u001b[35m val_acc:\u001b[94m 59.710000\u001b[35m val_top5:\u001b[94m 80.680000\u001b[35m val_fscore_macro:\u001b[94m 0.595851\u001b[0m\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/inversion_colores/checkpoint_last.ckpt\n",
      "Epoch 1: saving file to models/efficientnet_b0/transfer_learning/inversion_colores/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m2/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m12m47.81s \u001b[35mloss:\u001b[94m 0.152542\u001b[35m acc:\u001b[94m 95.279000\u001b[35m top5:\u001b[94m 99.652000\u001b[35m fscore_macro:\u001b[94m 0.952778\u001b[35m val_loss:\u001b[94m 2.637909\u001b[35m val_acc:\u001b[94m 59.310000\u001b[35m val_top5:\u001b[94m 80.880000\u001b[35m val_fscore_macro:\u001b[94m 0.590745\u001b[0m\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/inversion_colores/checkpoint_last.ckpt\n",
      "Epoch 2: saving file to models/efficientnet_b0/transfer_learning/inversion_colores/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m3/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m12m46.55s \u001b[35mloss:\u001b[94m 0.144573\u001b[35m acc:\u001b[94m 95.509000\u001b[35m top5:\u001b[94m 99.675000\u001b[35m fscore_macro:\u001b[94m 0.955086\u001b[35m val_loss:\u001b[94m 2.691788\u001b[35m val_acc:\u001b[94m 58.960000\u001b[35m val_top5:\u001b[94m 80.870000\u001b[35m val_fscore_macro:\u001b[94m 0.587700\u001b[0m\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/inversion_colores/checkpoint_last.ckpt\n",
      "Epoch 3: saving file to models/efficientnet_b0/transfer_learning/inversion_colores/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m4/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m12m46.41s \u001b[35mloss:\u001b[94m 0.145525\u001b[35m acc:\u001b[94m 95.473000\u001b[35m top5:\u001b[94m 99.670000\u001b[35m fscore_macro:\u001b[94m 0.954732\u001b[35m val_loss:\u001b[94m 2.670098\u001b[35m val_acc:\u001b[94m 58.970000\u001b[35m val_top5:\u001b[94m 80.720000\u001b[35m val_fscore_macro:\u001b[94m 0.587391\u001b[0m\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/inversion_colores/checkpoint_last.ckpt\n",
      "Epoch 4: saving file to models/efficientnet_b0/transfer_learning/inversion_colores/checkpoint_opt.ckpt\n",
      "\u001b[35mEpoch: \u001b[36m5/5 \u001b[35mTrain steps: \u001b[36m3125 \u001b[35mVal steps: \u001b[36m313 \u001b[32m12m48.55s \u001b[35mloss:\u001b[94m 0.138895\u001b[35m acc:\u001b[94m 95.717000\u001b[35m top5:\u001b[94m 99.681000\u001b[35m fscore_macro:\u001b[94m 0.957162\u001b[35m val_loss:\u001b[94m 2.661913\u001b[35m val_acc:\u001b[94m 59.160000\u001b[35m val_top5:\u001b[94m 80.990000\u001b[35m val_fscore_macro:\u001b[94m 0.590834\u001b[0m\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/inversion_colores/checkpoint_last.ckpt\n",
      "Epoch 5: saving file to models/efficientnet_b0/transfer_learning/inversion_colores/checkpoint_opt.ckpt\n"
     ]
    }
   ],
   "source": [
    "parameters_to_optimize = [\n",
    "   \n",
    "    {'params': base_model.classifier.parameters(), 'lr': 0.001},\n",
    "    \n",
    "    {'params': base_model.features[6:9].parameters(), 'lr': 0.0005} \n",
    "]\n",
    "\n",
    "optimizer = optim.Adam(parameters_to_optimize)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "# Directorio principal donde se guardarán los resultados\n",
    "main_dir = 'models/efficientnet_b0/transfer_learning'\n",
    "\n",
    "# Crear directorio principal si no existe\n",
    "Path(main_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "class TinyImageNet(TinyImageNet):\n",
    "    def __getitem__(self, index):\n",
    "        x, y = super().__getitem__(index)\n",
    "        return x,y\n",
    "#transformaciones = ['Without_transformation']\n",
    "# Iterar sobre cada transformación\n",
    "for i, transformacion in enumerate(transformaciones):\n",
    "    print(f\"Training with transformation: {transformacion}\")\n",
    "\n",
    "    # Crear directorio para la transformación actual\n",
    "    transform_dir = os.path.join(main_dir, transformacion)\n",
    "    Path(transform_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Definir el path del checkpoint\n",
    "    checkpoint_path = os.path.join(transform_dir, 'checkpoint_last.ckpt')\n",
    "    checkpoint_opt_path = os.path.join(transform_dir, 'checkpoint_opt.ckpt') \n",
    "\n",
    "    print(f'checkpoint path: {checkpoint_path}')\n",
    "    print(f'checkpoint optimizer path: {checkpoint_opt_path}')\n",
    "\n",
    "    # Cargar o reiniciar el modelo y el checkpoint para cada transformación\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location='cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    # Carga el estado del optimizador desde el archivo\n",
    "    if os.path.exists(checkpoint_opt_path):\n",
    "        optimizer.load_state_dict(torch.load(checkpoint_opt_path, map_location='cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    # Definir el conjunto de datos con la transformación actual\n",
    "    current_transform = transformation_afin[i]\n",
    "    #print(current_transform)\n",
    "\n",
    "    random_ts = lambda x: random.choice(current_transform)(x)\n",
    "    \n",
    "    normalize_transform = T.Compose(\n",
    "        [\n",
    "        # T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        #T.transforms.Normalize(TinyImageNet.mean,TinyImageNet.std),\n",
    "        random_ts\n",
    "        ])\n",
    "\n",
    "    # Definir el conjunto de datos original\n",
    "    dataset_train = TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"), split=\"train\", imagenet_idx=False, transform=normalize_transform)\n",
    "    dataset_val = TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"), split=\"val\", imagenet_idx=False, transform=normalize_transform)\n",
    "\n",
    "    #print(dataset_train[0])\n",
    "    # Definir un DataLoader para cargar los datos originales por lotes\n",
    "    train_loader = data.DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "    val_loader = data.DataLoader(dataset_val, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "    print('DataLoader listo')\n",
    "\n",
    "\n",
    "    # Definir el trainer\n",
    "    trainer = poutyne.Model(\n",
    "        model,\n",
    "        optimizer,\n",
    "        'cross_entropy',\n",
    "        batch_metrics=['accuracy', poutyne.TopKAccuracy(5)],\n",
    "        epoch_metrics=['f1'],\n",
    "        device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    )\n",
    "\n",
    "    # Definir el historial y el checkpoint para cada transformación\n",
    "    history_path = os.path.join(transform_dir, 'history.csv')\n",
    "    checkpoint_path = os.path.join(transform_dir, 'checkpoint_last.ckpt')\n",
    "    best_checkpoint_path = os.path.join(transform_dir, 'tmp_best.ckpt')\n",
    "    checkpoint_opt_path = os.path.join(transform_dir, 'checkpoint_opt.ckpt')   \n",
    "\n",
    "    checkpoint = poutyne.ModelCheckpoint(checkpoint_path, monitor='val_acc', mode='max', save_best_only=False, restore_best=False, verbose=True, temporary_filename=best_checkpoint_path)\n",
    "    opt_checkpoint = poutyne.OptimizerCheckpoint(checkpoint_opt_path, monitor='val_acc', mode='max', save_best_only=False, restore_best=False, verbose=True,        temporary_filename=best_checkpoint_path)\n",
    "\n",
    "    class HistorySaver(poutyne.Callback):\n",
    "\n",
    "      def __init__(self,filepath):\n",
    "        super().__init__()\n",
    "        self.filepath = filepath\n",
    "        self.history = []\n",
    "\n",
    "      def on_epoch_end(self, epoch, logs):\n",
    "        self.history.append(logs)\n",
    "\n",
    "        if os.path.exists(history_path):\n",
    "          df1 = pd.read_csv(history_path)\n",
    "          df = pd.DataFrame(self.history)\n",
    "          df = pd.concat([df1,df])\n",
    "          df.reset_index(drop=True,inplace=True)\n",
    "          df.drop_duplicates(inplace = True, ignore_index = True)\n",
    "          df.to_csv(self.filepath,index=False)\n",
    "        else:\n",
    "          df = pd.DataFrame(self.history)\n",
    "          df.to_csv(self.filepath,index=False)\n",
    "\n",
    "    # callback personalizado\n",
    "    history_saver = HistorySaver(history_path)\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "        df1 = pd.read_csv(history_path)\n",
    "        history_saver.history = df1.to_dict('records')\n",
    "\n",
    "    # Entrenar el modelo para cada transformación\n",
    "    #history = trainer.fit_dataset(train_loader, valid_dataset=val_loader, batch_size=8, epochs=num_epochs, callbacks=[checkpoint, opt_checkpoint,history_saver])\n",
    "\n",
    "    history = trainer.fit_generator(train_loader, val_loader, epochs=num_epochs, callbacks=[checkpoint, opt_checkpoint, history_saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
